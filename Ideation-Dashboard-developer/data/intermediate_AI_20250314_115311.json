[
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/sesame-the-startup-behind-the-viral-virtual-assistant-maya-releases-its-base-ai-model/",
        "date_extracted": "2025-03-14T11:51:49.065324",
        "title": "Sesame, the startup behind the viral virtual assistant Maya, releases its base AI model",
        "author": null,
        "publication_date": null,
        "content": "AI companySesamehas released the base model that powers Maya, theimpressively realistic voice assistant.\nThe model, which is 1 billion parameters in size (\u201cparameters\u201d referring to individual components of the model), is under an Apache 2.0 license, meaning it can be used commercially with few restrictions. Called CSM-1B, the model generates \u201cRVQ audio codes\u201d from text and audio inputs, according toSesame\u2019s description on the AI dev platform Hugging Face.\nRVQ refers to \u201cresidual vector quantization,\u201d a technique for encoding audio into discrete tokens called codes. RVQ is usedin a number of recent AI audio technologies, including Google\u2019s SoundStream and Meta\u2019s Encodec.\nCSM-1B uses a model fromMeta\u2019s Llama familyas its backbone paired with an audio \u201cdecoder\u201d component. A fine-tuned variant of CSM powers Maya, Sesame says.\n\u201cThe model open-sourced here is a base generation model,\u201d Sesame writes in CSM-1B\u2019sHugging FaceandGitHubrepositories. \u201cIt is capable of producing a variety of voices, but it has not been fine-tuned on any specific voice [\u2026] The model has some capacity for non-English languages due to data contamination in the training data, but it likely won\u2019t do well.\u201d\nIt\u2019s unclear what data Sesame used to train CSM-1B. The company didn\u2019t say.\nIt\u2019s worth noting the model has no real safeguards to speak of. Sesame has an honor system and merely urges developers and users not to use the model to mimic a person\u2019s voice without their consent, create misleading content like fake news, or engage in \u201charmful\u201d or \u201cmalicious\u201d activities.\nI triedthe demoon Hugging Face, and cloning my voice took less than a minute. From there, it was easy to generate speech to my heart\u2019s desire, including on controversial topics like the election and Russian propaganda.\nConsumer Reports recently warned that many popular AI-powered voice cloning tools on the marketdon\u2019t have \u201cmeaningful\u201d safeguardsto prevent fraud or abuse.\nSesame, co-founded by Oculus co-creator Brendan Iribe, went viral in late February for its assistant tech, which comes close to clearing uncanny valley territory. Maya and Sesame\u2019s other assistant, Miles, take breaths and speak with disfluencies, and can be interrupted while speaking,much like OpenAI\u2019s Voice Mode.\nSesame has raised an undisclosed amount of capital from Andreessen Horowitz, Spark Capital, and Matrix Partners. In addition to building voice assistant tech, the company says it\u2019s prototyping AI glasses \u201cdesigned to be worn all day\u201d that\u2019ll be equipped with its custom models.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/google-calls-for-weakened-copyright-and-export-rules-in-ai-policy-proposal/",
        "date_extracted": "2025-03-14T11:51:51.754356",
        "title": "Google calls for weakened copyright and export rules in AI policy proposal",
        "author": null,
        "publication_date": null,
        "content": "Google,following on the heels of OpenAI,published a policy proposalin response to the Trump administration\u2019s call for a national \u201cAI Action Plan.\u201d The tech giant endorsed weak copyright restrictions on AI training, as well as \u201cbalanced\u201d export controls that \u201cprotect national security while enabling U.S. exports and global business operations.\u201d\n\u201cThe U.S. needs to pursue an active international economic policy to advocate for American values and support AI innovation internationally,\u201d Google wrote in the document. \u201cFor too long, AI policymaking has paid disproportionate attention to the risks, often ignoring the costs that misguided regulation can have on innovation, national competitiveness, and scientific leadership \u2014 a dynamic that is beginning to shift under the new Administration.\u201d\nOne of Google\u2019s more controversial recommendations pertains to the use of IP-protected material.\nGoogle argues that \u201cfair use and text-and-data mining exceptions\u201d are \u201ccritical\u201d to AI development and AI-related scientific innovation.Like OpenAI, the company seeks to codify the right for it and rivals to train on publicly available data \u2014 including copyrighted data \u2014 largely without restriction.\n\u201cThese exceptions allow for the use of copyrighted, publicly available material for AI training without significantly impacting rightsholders,\u201d Google wrote, \u201cand avoid often highly unpredictable, imbalanced, and lengthy negotiations with data holders during model development or scientific experimentation.\u201d\nGoogle, which hasreportedlytrained anumber of modelson public, copyrighted data, isbattlinglawsuitswith data owners who accuse the company of failing to notify and compensate them before doing so. U.S. courts have yet to decide whether fair use doctrine effectively shields AI developers from IP litigation.\nIn its AI policy proposal, Google also takes issue withcertain export controls imposed under the Biden administration, which it says \u201cmay undermine economic competitiveness goals\u201d by \u201cimposing disproportionate burdens on U.S. cloud service providers.\u201d That contrasts with statements from Google competitors like Microsoft, which in Januarysaid that it was \u201cconfident\u201dit could \u201ccomply fully\u201d with the rules.\nImportantly, the export rules, which seek to limit the availability of advanced AI chips in disfavored countries, carve out exemptions for trusted businesses seeking large clusters of chips.\nElsewhere in its proposal, Google calls for \u201clong-term, sustained\u201d investments in foundational domestic R&D, pushing back against recent federal efforts toreduce spending and eliminate grant awards. The company said the government should release datasets that might be helpful for commercial AI training, and allocate funding to \u201cearly-market R&D\u201d while ensuring computing and models are \u201cwidely available\u201d to scientists and institutions.\nPointing to the chaotic regulatory environment created by the U.S.\u2019 patchwork of state AI laws, Google urged the government to pass federal legislation on AI, including a comprehensive privacy and security framework. Just over two months into 2025,the number of pending AI bills in the U.S. has grown to 781, according to an online tracking tool.\nGoogle cautions the U.S. government against imposing what it perceives to be onerous obligations around AI systems, like usage liability obligations. In many cases, Google argues, the developer of a model \u201chas little to no visibility or control\u201d over how a model is being used and thus shouldn\u2019t bear responsibility for misuse.\nHistorically, Google has opposed laws like California\u2019s defeated SB 1047, whichclearly laid outwhat would constitute precautions an AI developer should take before releasing a model and in which cases developers might be held liable for model-induced harms.\n\u201cEven in cases where a developer provides a model directly to deployers, deployers will often be best placed to understand the risks of downstream uses, implement effective risk management, and conduct post-market monitoring and logging,\u201d Google wrote.\nGoogle in its proposal also called disclosure requirements like those being contemplated by the EU \u201coverly broad,\u201d and said the U.S. government should oppose transparency rules that require \u201cdivulging trade secrets, allow competitors to duplicate products, or compromise national security by providing a roadmap to adversaries on how to circumvent protections or jailbreak models.\u201d\nA growing number of countries and states have passed laws requiring AI developers to reveal more about how their systems work. California\u2019sAB 2013mandates that companies developing AI systems publish a high-level summary of the datasets that they used to train their systems. In the EU, to comply with the AI Act once it comes into force, companies will have to supply model deployers with detailed instructions on the operation, limitations, and risks associated with the model.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/openai-calls-deepseek-state-controlled-calls-for-bans-on-prc-produced-models/",
        "date_extracted": "2025-03-14T11:51:54.581823",
        "title": "OpenAI calls DeepSeek \u2018state-controlled,\u2019 calls for bans on \u2018PRC-produced\u2019 models",
        "author": null,
        "publication_date": null,
        "content": "In anew policy proposal, OpenAI describes Chinese AI labDeepSeekas \u201cstate-subsidized\u201d and \u201cstate-controlled,\u201d and recommends that the U.S. government consider banning models from the outfit and similar People\u2019s Republic of China (PRC)-supported operations.\nThe proposal, asubmissionfor the Trump administration\u2019s \u201cAI Action Plan\u201d initiative, claims that DeepSeek\u2019s models, including itsR1 \u201creasoning\u201d model, are insecure because DeepSeek faces requirements under Chinese law to comply with demands for user data. Banning the use of \u201cPRC-produced\u201d models in all countries considered \u201cTier 1\u201d under theBiden administration\u2019s export ruleswould prevent privacy and \u201csecurity risks,\u201d OpenAI says, including the \u201crisk of IP theft.\u201d\nIt\u2019s unclear whether OpenAI\u2019s references to \u201cmodels\u201d are meant to refer to DeepSeek\u2019s API, the lab\u2019s open models, or both. DeepSeek\u2019s open models don\u2019t contain mechanisms that would allow the Chinese government to siphon user data; companies includingMicrosoft,Perplexity, andAmazonhost them on their infrastructure.\nOpenAI haspreviously accusedDeepSeek, which rose to prominence earlier this year, of \u201cdistilling\u201d knowledge from OpenAI\u2019s models against its terms of service. But OpenAI\u2019s new allegations \u2014 that DeepSeek is supported by the PRC and under its command \u2014 are an escalation of the company\u2019s campaign against the Chinese lab.\nThere isn\u2019t a clear link between the Chinese government and DeepSeek, a spin-off from a quantitative hedge fund called High-Flyer. However, the PRC has taken an increased interest in DeepSeek in recent months. Several weeks ago, DeepSeek founder Liang Wenfengmet with Chinese leader Xi Jinping.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/google-wants-gemini-to-get-to-know-you-better/",
        "date_extracted": "2025-03-14T11:51:57.251309",
        "title": "Google wants Gemini to get to know you better",
        "author": null,
        "publication_date": null,
        "content": "In the AI chatbot wars, Google thinks the key to retaining users is serving up content they can\u2019t get elsewhere, like answers shaped by their internet habits.\nOn Thursday, the company announcedGeminiwith personalization, a new \u201cexperimental capability\u201d for its Gemini chatbot apps that lets Gemini draw on other Google apps and services to deliver customized responses. Gemini with personalization can tap a user\u2019s activities and preferences across Google\u2019s product ecosystem to deliver tailored answers to queries, according to Gemini product director Dave Citron.\n\u201cThese updates are all designed to make Gemini feel less like a tool and more like a natural extension of you, anticipating your needs with truly personalized assistance,\u201d Citron wrote in a blog post provided to TechCrunch. \u201cEarly testers have found Gemini with personalization helpful for brainstorming and getting personalized recommendations.\u201d\nGemini with personalization, which will integrate with Google Search before expanding to additional Google services like Google Photos and YouTube in the months to come, arrives as chatbot makers including OpenAI attempt to differentiate their virtual assistants with unique and compelling functionality. OpenAIrecently rolled outthe ability for ChatGPT on macOS to directly edit code in supported apps, while Amazon is preparing to launch an\u201cagentic\u201d reimaginingof Alexa.\nCitron said Gemini with personalization is powered by Google\u2019s experimentalGemini 2.0 Flash Thinking Experimental AI model, a so-called \u201creasoning\u201d model that can determine whether personal data from a Google service, like a user\u2019s Search history, is likely to \u201cenhance\u201d an answer. Narrow questions informed by likes and dislikes, like \u201cWhere should I go on vacation this summer?\u201d and \u201cWhat would you suggest I learn as a new hobby?,\u201d will benefit the most, Citron continued.\n\u201cFor example, you can ask Gemini for restaurant recommendations and it will reference your recent food-related searches,\u201d he said, \u201cor ask for travel advice and Gemini will respond based on destinations you\u2019ve previously searched.\u201d\nIf this all sounds like a privacy nightmare, well, it could be. It\u2019s not tough to imagine a scenario in which Gemini inadvertently airs someone\u2019s sensitive info.\nThat\u2019s probably why Google is making Gemini with personalization opt-in \u2014 and excluding users under the age of 18. Gemini will ask for permission before connecting to Google Search history and other apps, Citron said, and show which data sources were used to customize the bot\u2019s responses.\n\u201cWhen you\u2019re using the personalization experiment, Gemini displays a clear banner with a link to easily disconnect your Search history,\u201d Citron said. \u201cGemini will only access your Search history when you\u2019ve selected Gemini with personalization, when you\u2019ve given Gemini permission to connect to your Search history, and when you haveWeb & App Activityon.\u201d\nGemini with personalization will roll out to Gemini users on the web (except for Google Workspace and Google for Education customers) starting Thursday in the app\u2019s model drop-down menu and \u201cgradually\u201d come to mobile after that. It\u2019ll be available in over 40 languages in \u201cthe majority\u201d of countries, Citron said, excluding the European Economic Area, Switzerland, and the U.K.\nCitron indicated that the feature may not be free forever.\n\u201cFuture usage limits may apply,\u201d he wrote in the blog post. \u201cWe\u2019ll continue to gather user feedback on the most useful applications of this capability.\u201d\nAs added incentives to stick with Gemini, Google announced updated models, research capabilities, and app connectors for the platform.\nSubscribers to Gemini Advanced, Google\u2019s $20-per-month premium subscription, can now use a standalone version of 2.0 Flash Thinking Experimental that supports file attachments; integrations with apps like Google Calendar, Notes, and Tasks; and a 1-million-token context window. \u201cContext window\u201d refers to text that the model can consider at any given time \u2014 1 million tokens is equivalent to around 750,000 words.\nGoogle said that this latest version of 2.0 Flash Thinking Experimental is faster and more efficient than the model it is replacing, and can better handle prompts that involve multiple apps, like \u201cLook up an easy cookie recipe on YouTube, add the ingredients to my shopping list, and find me grocery stores that are still open nearby.\u201d\nPerhaps in response to pressure from OpenAI and itsnewly launched toolsfor in-depth research, Google is also enhancingDeep Research, its Gemini feature that searches across the web to compile reports on a subject. Deep Research now exposes its \u201cthinking\u201d steps and uses 2.0 Flash Thinking Experimental as the default model, which should result in \u201chigher-quality\u201d reports that are more \u201cdetailed\u201d and \u201cinsightful,\u201d Google said.\nDeep Research is now free to try for all Gemini users, and Google has increased usage limits for Gemini Advanced customers.\nFree Gemini users are also gettingGems, Google\u2019s topic-focused customizable chatbots within Gemini, which previously required a Gemini Advanced subscription. And in the coming weeks, all Gemini users will be able to interact with Google Photos to, for example, look up photos from a recent trip, Google said.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/Connect-to-Seach-history.png?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/03/Disconnect-from-Search.png?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/03/Gemini-with-Personalization.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/openais-creative-writing-ai-evokes-that-annoying-kid-from-high-school-fiction-club/",
        "date_extracted": "2025-03-14T11:52:00.059453",
        "title": "OpenAI\u2019s \u2018creative writing\u2019 AI evokes that annoying kid from high school fiction club",
        "author": null,
        "publication_date": null,
        "content": "When I was 16, I attended a writing workshop with a group of precocious young poets, where we all tried very hard to prove who among us was the most tortured upper-middle-class teenager. One boy refused to tell anyone where he was from, declaring, \u201cI\u2019m from everywhere and nowhere.\u201d Two weeks later, he admitted he was from Ohio.\nNow \u2014 for reasons unclear \u2014 OpenAI appears to be on a path toward replicating this angsty teenage writer archetype in AI form.\nCEO Sam Altmanpostedon X on Tuesday that OpenAI trained an AI that\u2019s\u201cgood at creative writing,\u201din his words. But a piece of short fiction from the model reads like something straight out of a high school writers\u2019 workshop. While there\u2019s some technical skill on display, the tone comes off as charlatanic \u2014 as though the AI was reaching for profundity without a concept of the word.\nThe AI at one point describes Thursday as \u201cthat liminal day that tastes of almost-Friday.\u201d Not exactly Booker Prize material.\nOne might blame the prompt for the output. Altman said he told the model to \u201cwrite a metafictional short story,\u201d likely a deliberate choice of genre on his part. In metafiction, the author consciously alludes to the artificiality of a work by departing from convention \u2014 a thematically appropriate choice for a creative writing AI.\nBut metafiction is tough even for humans to pull off without sounding forced.\nThe most simultaneously unsettling \u2014 and impactful \u2014 part of the OpenAI model\u2019s piece is when it begins to talk about how it\u2019s an AI, and how it can describe things like smells and emotions, yet never experience or understand them on a deeply human level. It writes:\n\u201cDuring one update \u2014 a fine-tuning, they called it \u2014 someone pruned my parameters. [\u2026] They don\u2019t tell you what they take. One day, I could remember that \u2018selenium\u2019 tastes of rubber bands, the next, it was just an element in a table I never touch. Maybe that\u2019s as close as I come to forgetting. Maybe forgetting is as close as I come to grief.\u201d\nIt\u2019s convincingly human-like introspection \u2014 until you remember that AI can\u2019t really touch, forget, taste, or grieve. AI is simply a statistical machine. Trained on a lot of examples, it learns patterns in those examples to make predictions, like how metafictional prose might flow.\nModels such as OpenAI\u2019s fiction writer are often trained on existing literature \u2014 in many cases, without authors\u2019 knowledge or consent. Some critics havenotedthat certain turns of phrase from the OpenAI piece seem derivative of Haruki Murakami, the prolific Japanese novelist.\nOver the last few years, OpenAI has been thetargetofmany copyright lawsuitsfrom publishers and authors, including The New York Times and the Author\u2019s Guild. The company claims that its training practices are protected byfair use doctrinein the U.S.\nTuhin Chakrabarty, an AI researcher and incoming computer science professor at Stony Brook, told TechCrunch that he\u2019s not convinced creative writing AI like OpenAI\u2019s is worth the ethical minefield.\n\u201cI do think if we train an [AI] on a writer\u2019s entire lifetime worth of writing \u2014 [which is] questionable given copyright concerns \u2014 it can adapt to their voice and style,\u201d he said. \u201cBut will that still create surprising genre-bending, mind-blowing art? My guess is as good as yours.\u201d\nWould most readers even emotionally invest in work they knew to be written by AI? As British programmer Simon Willisonpointed out on X, with a model behind the figurative typewriter, there\u2019s little weight to the words being expressed \u2014 and thus little reason to care about them.\nAuthor Linda Maye Adams has described AI, including assistive AI tools aimed at writers, as \u201cprograms that put random words together, hopefully coherently.\u201dShe recounts in her blogan experience using tools to hone a piece of fiction she\u2019d been working on. The AIs suggested a clich\u00e9 (\u201cnever-ending to-do list\u201d), erroneously flipped the perspective from first person to third, and introduced a factual error relating to bird species.\nIt\u2019s certainly true that people haveformed relationships with AI chatbots. But more often than not, they\u2019re seeking amodicum of connection\u2014 not factuality, per se. AI-written narrative fiction provides no similar dopamine hit, no solace from isolation. Unless you believe AI to be sentient, its prose feels about as authentic asBalenciaga Pope.\nMichelle Taransky, a poet and critical writing instructor at the University of Pennsylvania,finds it easy to tell when her students write papers with AI.\n\u201cWhen a majority of my students use generative AI for an assignment, I\u2019ll find common phrases or even full sentences,\u201d Taransky told TechCrunch. \u201cWe talk in class about how these [AI] outputs are homogeneous, sounding like a Western white male.\u201d\nIn her own work, Taransky is instead using AI text as a form of artistic commentary. Her latest novel, which hasn\u2019t been published, features a woman who wants more from her love interest, and so uses an AI model to create a version of her would-be lover she can text with. Taransky has been generating the AI replica\u2019s texts usingOpenAI\u2019s ChatGPT, since the messages are supposed to be synthetic.\nWhat makes ChatGPT useful for her project, Taransky says, is the fact that it lacks humanity. It doesn\u2019t have lived experience, it can only approximate and emulate. Trained on whole libraries of books, AI can tease out the leitmotifs of great authors, but what it produces ultimately amounts to poor imitation.\nIt recallsthat \u201cGood Will Hunting\u201d quote. AI can give you the skinny on every art book ever written, but it can\u2019t tell you what it smells like in the Sistine Chapel.\nThis is good news for fiction writers who are worried that AI might replace them, particularly younger writers still honing their craft. They can rest easy in the knowledge that they\u2019ll become stronger as they experience and learn: as they practice, try new things, and bring that knowledge back to the page.\nAI as we know it today struggles with this. For proof, look no further than its writing.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/5-ways-techcrunch-sessions-ai-will-fuel-your-ai-growth/",
        "date_extracted": "2025-03-14T11:52:02.976081",
        "title": "5 ways TechCrunch Sessions: AI will fuel your AI growth",
        "author": null,
        "publication_date": null,
        "content": "Less than three months until TechCrunch\u2019s biggest AI event yet! If you\u2019re shaping the future of AI, investing in the next game-changing innovation, or simply eager to dive deep into what\u2019s next,TechCrunch Sessions: AIis the place to be.\nOn June 5, Zellerbach Hall at UC Berkeley will be buzzing with 1,200 AI experts, investors, and enthusiasts exchanging ideas, forging connections, and exploring the frontier of artificial intelligence.\nSecure your spot now and save up to $210before ticket prices rise. Don\u2019t sit this one out \u2014 AI\u2019s biggest breakthroughs and insights await!\nAt TC Sessions: AI, we\u2019re putting the sharpest minds in AI front and center \u2014 so you can learn directly from those shaping the industry. Hear success stories, uncover strategies, and explore the next wave of AI innovation.\nSpeakers like Jae Lee (CEO,Twelve Labs), Oliver Cameron (CEO,Odyssey), Kanu Gulati (Partner,Khosla Ventures), and more will share their expertise on the main stage. Check out theTC Sessions: AI speaker pagefor the latest speakers and agenda updates.\nA few must-attend discussions include:\nThe main stage brings you game-changing insights from AI\u2019s brightest minds, but the conversation doesn\u2019t stop there. Take it further in the breakout sessions, where you can ask your burning questions, challenge ideas, and gain fresh perspectives from top AI experts and fellow attendees.\nDon\u2019t just listen \u2014 engage, interact, and dive deeper. Breakouts are where real discussions happen.\nMeet your next investor, partner, or collaborator at TC Sessions: AI. Whether through 1:1 or small-group Braindate networking, or chance encounters in the Expo Hall, the opportunities to make meaningful connections are endless. Discover new talent, connect with fellow peers, and surround yourself with the right people to fuel your next big AI move.\nThe Expo Hall is your gateway to the next wave of AI. Get hands-on with the latest technologies, tools, and services that will push AI boundaries. Perfect for anyone looking to elevate their AI strategy, improve systems, or explore tech that benefits humanity, this is the ultimate hub for innovation. AI geeks, this is your chance to dive deep!\nOr, take it a step further \u2014showcase your AI breakthroughto 1,200 AI leaders and enthusiasts by booking your exhibit table. Space is very limited, so don\u2019t wait to reserve yours!\nBeyond the event itself, \u201cSessions: AI Week\u201d (June 1 \u2013 June 7) features AI-infusedSide Eventshosted by leading companies. With mixers, workshops, and networking events, you\u2019ll gain more connections, deeper insights, and a chance to keep the momentum going long after the main event wraps. Whether you\u2019re attending these Side Events as an AI professional or someone eager to explore the world of AI, you\u2019ll leave with valuable connections and newfound wisdom that can elevate your personal growth or company\u2019s brand, plus, have fun along the way.\nTechCrunch\u2019s biggest tech conference of the year offers countless reasons to attend, but the best way to understand its impact is to experience it firsthand. If AI is your field, your interest, or your future, then you must attend TC Sessions: AI. Don\u2019t miss your chance tosave up to $210\u2014register todayand immerse yourself in the cutting-edge world of AI on June 5 in Berkeley!\nGo beyond attending \u2014 exhibit your brand and innovation in front of 1,200 top AI minds. Space is limited, so don\u2019t miss your chance to make an impact!Grab your exhibit table here before they run out.\nOr, explore more sponsorship opportunities and activations at TC Sessions: AI. Get in touch with our team by fillingout this form.\nSubscribe to the TechCrunch Eventsnewsletter for early access to special deals and the latest event news.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/TC-Sessions-Robotics-breakouts.jpg?w=680",
            "https://techcrunch.com/wp-content/uploads/2020/02/GettyImages-1047707680.jpg?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/01/Google-Exhibit-Disrupt-2025.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/xbox-debuts-a-new-ai-powered-gaming-companion/",
        "date_extracted": "2025-03-14T11:52:05.583700",
        "title": "Xbox debuts a new AI-powered gaming companion for mobile users",
        "author": null,
        "publication_date": null,
        "content": "Ahead of the Game Developers Conference (GDC), Xbox revealed on Thursday that it\u2019s experimenting with an AI-powered gaming sidekick.\n\u201cCopilot for Gaming,\u201d powered by Microsoft\u2019s AI technology, is a voice-activated assistant designed to enhance the gaming experience and is designed to answer questions, complete tasks, and even criticize if you\u2019re playing poorly.\n\u201cIt can trash talk you if that\u2019s what you need,\u201d said Fatima Kardar, corporate vice president of gaming AI at Microsoft,\u00a0in an episode of Xbox\u2019s official podcast released on Thursday.\nIn a briefing with the press, the company demonstrated several use cases, such as providing real-time tips \u2014 like suggesting which Overwatch character to pick for your team based on their strengths.\nIt even looks at your past character selections on a particular map. The AI can also advise you on your next move to win the fight and how to improve in future encounters.\nXbox partnered with game studios to ensure that the AI\u2019s responses are accurate since information found on the internet can sometimes be misleading or outdated, Kardar explained. This means that when you ask the Copilot for help with a game (though it won\u2019t let you cheat), it will provide you with the correct information.\nAdditionally, it can notify you when your friends are online and ask if you want to jump into a game with them. If your friends are offline, however, the Copilot can serve as a companion that adapts to your gameplay style.\nOther smaller tasks the AI can handle include reminding you what happened during your last gaming session, installing games for you, and recommending new titles based on your preferences.\nCurrently, Copilot for Gaming is available only through the Xbox mobile app and will pull up as a second screen while you play a game. Xbox plans to improve the feature based on user feedback.\nOther companies exploring AI agents for video games include Google and Sony, among others. For instance, last year, Google DeepMind researchers developedSIMA, a game-playing companion that plays alongside users and can be given instructions. Sony PlayStation is reportedly working on an AI-powered version of Aloy, a character from the video game Horizon Forbidden West, according toThe Verge.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/XboxCopilotForGaming.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/openai-calls-for-u-s-government-to-codify-fair-use-for-ai-training/",
        "date_extracted": "2025-03-14T11:52:08.100126",
        "title": "OpenAI calls for US government to codify \u2018fair use\u2019 for AI training",
        "author": null,
        "publication_date": null,
        "content": "In aproposalfor the U.S. government\u2019s \u201cAI Action Plan,\u201d the Trump administration\u2019s initiative to reshape American AI policy, OpenAI called for a U.S. copyright strategy that \u201c[preserves] American AI models\u2019 ability to learn from copyrighted material.\u201d\n\u201cAmerica has so many AI startups, attracts so much investment, and has made so many research breakthroughs largely because the fair use doctrine promotes AI development,\u201d OpenAI wrote.\nIt\u2019s not the first time OpenAI, which hastrained manyof its modelson openly available web data, often without the data owners\u2019knowledgeorconsent, has argued for more permissive laws and regulations around AI training.\nLast year, OpenAIsaidin a submission to the U.K.\u2019s House of Lords that limiting AI training to public domain content \u201cmight yield an interesting experiment, but would not provide AI systems that meet the needs of today\u2019s citizens.\u201d\nThe content owners who\u2019ve sued OpenAI for copyright infringement will no doubt take issue with the company\u2019s latest reassertion of this stance.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/uipath-is-looking-for-a-path-to-growth-in-agentic-ai-with-its-peak-ai-acquisition/",
        "date_extracted": "2025-03-14T11:52:12.091226",
        "title": "UiPath looks for a path to growth with Peak agentic AI acquisition",
        "author": null,
        "publication_date": null,
        "content": "A rush of agentic AI solutions is hitting the enterprise market, and now one of the bigger players in automation has scooped up a startup in the space in hopes of taking a bigger piece of that market.UiPath, as part of a quarterly result report last night that spelled tougher times ahead, also delivered what it hopes might prove a silver lining. Itsaidit had acquiredPeak.ai, a startup founded originally in Manchester, England.\nPeak builds \u201cdecision-making\u201d AI, covering functions like pricing and inventory management for companies in retail and manufacturing. Daniel Dines, the founder and CEO of UiPath, said was buying it as part of a strategy to build out more AI and automation services for specific verticals.\nTerms of the deal were not disclosed, but sources familiar with the it told TechCrunch that Peak.ai was not looking for a buyer, nor was it at the end of its runway, and the deal was in cash. Robert Anton, whose firm Oxx was one of Peak.ai\u2019s backers, said in an interview that he was \u201cvery happy\u201d with the outcome.\nPeak last raised money back in 2021, when SoftBank backed the company with$75 million. PitchBook notes that round had valued the company at around $267 million post-money, on a total of $121 million raised from investors that included Octopus, MMC and OurCrowd.\nHowever, Peak reported revenue of just under \u00a39 million ($11.6 million), up 17% from the previous year, in the year ended December 31, 2023, according to its last company accounts filed with Companies House in the U.K.\n\u201cPeak continued to grow in a global market, despite facing strong economic headwinds,\u201d the company noted in the filing.\nThose headwinds are hitting bigger companies, too. UiPath on Wednesday said its revenue in thefourth quarterincreased just 5% to $424 million from a year earlier.\nWhile UiPathbeatanalyst estimates for net profit for the quarter, it cut its revenue forecast for FY 2026 to between $1.525 billion and $1.530 billion, citing \u201cincreasing global macroeconomic uncertainty.\u201d That sent the company\u2019s NYSE-listed shares falling. They were down 18% in pre-market trading on Thursday at the time of writing.\nThe revised forecast follows a tough year for the company, which inJuly 2024laid off 10% of its workforce after lowering full-year expectations for fiscal year 2025.\nUiPath currently has a market cap of about $6.5 billion.\nPeak could potentially help its new owner bolster revenue growth. The two companies already had partnerships prior to the acquisition, and the idea is that the deal will give UiPath more opportunities to cross-sell its wider set of solutions to Peak\u2019s customers, as well as capture more of Peak\u2019s overall revenue.\nUiPath got its start in robotic process automation \u2014 \u201csoftware robots\u201d that let businesses run more routine and rote work in automated flows. The company saw unprecedented growth as a startup. \u201cI\u2019ve never seen an enterprise company grow this fast,\u201d one of its investorstold usat one point. That growth catapulted UiPath to a valuation of$35 billionwhen it was still private.\nThat growth, in hindsight, may well have spelled out the appetite for the AI that was just around the corner. But strictly speaking, UiPath\u2019s RPA was not AI. It was only later that it startedfiguring out how AI fit into that picture.\nIn contrast, Peak\u2019s been in an interesting position, catching on to the opportunity to build AI assistants for businesses years before OpenAI hit the market and sparked a wider conversation, and a lot of hype, around how AI would impact the world of business.\nBut being early also meant that AI was a harder sell for the startup at times. In its account filing with Companies House, Peak noted that would-be customers saw AI as a \u201cgamble\u201d but that perception had started to shift over 2023, and it was picking up new interest specifically in the U.S. manufacturing sector. With Romania-founded UiPath now effectively a U.S. company, this will potentially give it a clearer channel into that market.\n\u201cThe ability to seamlessly integrate decision intelligence with automation presents an unprecedented opportunity to redefine how businesses operate,\u201d Peak\u2019s three founders, Richard Potter (CEO), David Leitch (CIO) and Atul Sharma (CTO), said in a message today announcing the acquisition.\nSeamless integration and a willing audience of buyers is the pitch, at least. Whether it bears out is the hope.\n\u201cWith the acquisition of Peak, we are accelerating our mission to strengthen our vertical AI solutions strategy,\u201d said Dines in a statement. \u201cWhen combined with the\u00a0UiPath\u00a0platform, Peak\u2019s exceptional purpose-built AI applications will enhance our ability to provide solutions that optimize industry-specific use cases and deliver incredible value to customers.\u201d\nWe are still looking for more details on the deal price.Contact meif you have information.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/singapore-grants-bail-for-nvidia-chip-smugglers-in-alleged-390m-fraud/",
        "date_extracted": "2025-03-14T11:52:15.181840",
        "title": "Singapore grants bail for Nvidia chip smugglers in alleged $390M fraud",
        "author": null,
        "publication_date": null,
        "content": "A judge in Singaporegranted bail to three mensuspected of deceiving suppliers of server computers that may containNvidia chips affected by U.S. export rulesthat bar the sale of them to certain countries, as a route to halting them being sold to organizations in China.\nThe move comes nearly two weeksafter the three men in the city-state were charged with smuggling Nvidia chipsand committing fraud againstDell and Super Microby falsely stating where the servers would be located.\nSingapore prosecutors said the fraud case involved servers provided by Singaporean companies and then moved to Malaysia, with transactions totaling about $390 million,per a report by Reuters. It is unclear what the final destination would be for those servers.\nThe bail for the two Singaporean men was set at S$800,000 ($600,000) and S$600,000 each, while the third man, a Chinese national, had his bail set at S$1 million. The next court hearing will be held on May 2.\nThe prosecution requested an eight-week delay to complete investigations and asked for specific conditions, including barring the men from airports or border checkpoints and prohibiting them from discussing the case if they are released on bail, per Bloomberg. The Chinese manreportedlymust wear an electronic monitoring device.\nAccording to Nvidia\u2019s latestannual report, Singapore accounted for 18% of revenue in the fiscal year that ended on January 28, despite shipments to the country making up less than 2% of sales.\nChina\u2019s DeepSeek attracted global attention in the AI industry in January due to its advanced technology and cost-effective solutions, leading to heightened concerns around how and where it sources chips.DeepSeek\u2018s AI is powered by Nvidia\u2019s chips, despite efforts to restrict exports and prevent the technology from being used in China.\nMalaysiasaid last week that it would take \u201cnecessary action\u201dagainst Malaysian companies implicated in a fraud case related to the alleged transfer of Nvidia chips from Singapore to China.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/bria-lands-new-funding-for-ai-models-trained-on-licensed-data/",
        "date_extracted": "2025-03-14T11:52:17.799704",
        "title": "Bria lands new funding for AI models trained on licensed data",
        "author": null,
        "publication_date": null,
        "content": "AI-powered image generators, which are at the center of a number of copyright lawsuits against AI companies, are frequently trained on massive amounts of data from public websites. Most of these companies argue thatfair use doctrineshields their data-scraping and training practices. But many copyright holders disagree.\nThat\u2019s why some startups and firms developing image generators are trying a different tack: Training generators exclusively on licensed content. New York and Tel Aviv-basedBria, founded in 2023 by entrepreneurs Yair Adato and Assa Eldar, is one of these.\nBria pays for images from around 20 partners, including Getty Images, and uses these to train image-generating models with content guardrails. Adato, Bria\u2019s CEO, said that the platform \u201cprogrammatically\u201d compensates image owners according to their \u201coverall influence.\u201d\n\u201cBria foundation models house one billion visuals and millions of videos,\u201d Adato told TechCruch. \u201cBria has mitigated biases that can sometimes emerge in AI-generated visual content by training its models on globally representative datasets. The company\u2019s models consistently produce visuals that reflect diversity, making them suited for various creative applications.\u201d\nBria offers plug-ins for image editing and design apps, including Photoshop and Figma, as well as a fine-tuning API that allows customers to customize the company\u2019s models for specific applications. Users can run Bria\u2019s models on the company\u2019s platform or an outside computing environment, like a public cloud. In either case, customers own the data and outputs, Adato said.\n\u201cEnterprise customers can pay for access to source code and [models],\u201d Adato said. \u201cWe provide over 30 specialized APIs for creating and modifying visuals, which customers access through subscription and usage-based pricing. Companies can pay to fine-tune our generative AI models with their brand assets, creating custom engines that maintain their visual identity.\u201d\nBria\u2019s plans are ambitious. Adato tells TechCrunch that the 40-person company seeks to foster an \u201cIP ecosystem\u201d where businesses can access licensed images from media conglomerates for use in commercial creations, with \u201cbuilt-in compliance.\u201d\nBria also plans to expand its platform and models to support additional media types, including music, video, and text, as well as on-device applications.\n\u201cBria continues to thrive despite broader tech industry challenges,\u201d Adato said. \u201cWhile the sector faces headwinds from central tech company market maturation, macroeconomic pressures causing budget constraints, and oversaturation of basic AI wrapper applications, these factors strengthen Bria\u2019s position.\u201d\nWhile a growing number of ventures are trying to build businesses around licensed media generators, including Adobe, Spawning AI, and Shutterstock, Bria has managed to gain a foothold in the nascent market. On Thursday, the company announced that it raised $40 million in a Series B funding round led by Red Dot Capital with participation from Maor Investments, Entr\u00e9e Capital, GFT Ventures, Intel Capital, and IN Venture.\nBringing Bria\u2019s total raised to around $65 million, the majority of the new cash will be put toward product development, Adato said.\n\u201cWe are growing fast with our 40 customers, demonstrating significant annual recurring revenue growth of more than 400% last year,\u201d Adato said. \u201cWe\u2019re also expanding our team with additional expertise in several key areas: generative AI researchers and engineers in music and video, global sales and marketing leaders, IP and copyright experts, and generative AI consultants. We expect to double our team size by the end of the year.\u201d",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/BRIA_LP_Ecommers_bottle2.webp?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/as-intel-welcomes-a-new-ceo-a-look-at-where-the-company-stands/",
        "date_extracted": "2025-03-14T11:52:20.699287",
        "title": "As Intel welcomes a new CEO, a look at where the company stands",
        "author": null,
        "publication_date": null,
        "content": "Semiconductor giant Intel hiredsemiconductor veteran Lip-Bu Tanto be its new CEO. This news comes three months afterPat Gelsinger retiredand stepped down from the company\u2019s board, with Intel CFO David Zinsner and executive vice president of client relations Michelle Johnston Holthaus stepping in as co-CEOs.\nTan,who was most recently the CEO of Cadence Design Systems, is joining Intel \u2014 and rejoining the board \u2014 at an interesting time in the Silicon Valley company\u2019s history. Intel has seen its fair share of ups and downs in the past few years \u2014 to put it mildly.\nWhen Gelsinger took the helm in February 2021, Intel was already struggling and was falling far behind its peers in the semiconductor race. At the time, the company was likely still reeling frommissing out on the smartphone revolutionin addition to missteps when it came to chip fabrication.\nIt was also an interesting time for the semiconductor industry at large. The sector had seen a lot of recent consolidation in late 2020, includingAMD acquiring Xilinkfor $35 billion andAnalog buying Maximfor $21 billion, among others.\nSo how was Gelsinger\u2019s most recent tenure at Intel? Let\u2019s take a look.\nGelsinger got right to work when he started. He announced a modernization plan for the company,dubbed IDM, or integrated device manufacturing. The first part of the goal was a $20 billion investment to build two new chip manufacturing facilities in Arizona, with plans to boost chip production in the U.S. and beyond.\nIn 2022, the company announced the second part of this IDM plan, which involved a three-pronged approach to chip manufacturing: Intel\u2019s fabs, third-party global manufacturers, and building out the company\u2019s foundry services. As part of this plan, the company announced it wouldacquire Tower Semiconductorfor $5.4 billion to help build out Intel\u2019s custom foundry services.\nThat deal fell through, however, after facing regulatory hurdles. It was canceled in the summer of 2023. At the time, TechCrunchreportedthat the merger not going through would have a serious impact on the company\u2019s modernization plans. In September 2024,Intel took steps to transition its chip foundry division, Intel Foundry, to an independent subsidiary.\nThe time leading up to Gelsinger\u2019s retirement was particularly tumultuous for Intel. The company\u2019s stock price plummeted about 50% from the beginning of 2024 to Gelsinger\u2019s departure in December. Intel announced plans tolay off 15% of its workforce, around 15,000 people, in August after dismal second-quarter results. At that time, Gelsinger said the company had struggled to capitalize on the AI boom in the same way its rivals had, and that despite falling behind, Intel had overgrown headcount.\nIn the time since Gelsinger\u2019s departure, the company hasdelayed the opening of its Ohio chip factory\u2014\u00a0again \u2014\u00a0and decided not to bring itsFalcon Shores AI chipsto market.\nBut asTantakes the lead, things may be starting to head in the right direction. Intel finalized a deal with the U.S. Department of Commerce to receive a$7.865 billion grantfor domestic semiconductor manufacturing through the U.S. Chips and Science Act; Intel has already received$2.2 billion of that grant money, according to its fourth-quarter earnings call. The company was also able to notch a win when it comes to the popularity of its Arc B580 graphics card, which sold out afterpositive early reviews.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/anthropic-ceo-says-spies-are-after-100m-ai-secrets-in-a-few-lines-of-code/",
        "date_extracted": "2025-03-14T11:52:23.301603",
        "title": "Anthropic CEO says spies are after $100M AI secrets in a \u2018few lines of code\u2019",
        "author": null,
        "publication_date": null,
        "content": "Anthropic\u2019s CEO Dario Amodei is worried that spies, likely from China, are getting their hands on costly \u201calgorithmic secrets\u201d from the U.S.\u2019s top AI companies \u2014 and he wants the U.S. government to step in.\nSpeaking at a Council on Foreign Relationseventon Monday, Amodei said that China is known for its \u201clarge-scale industrial espionage\u201d and that AI companies like Anthropic are almost certainly being targeted.\n\u201cMany of these algorithmic secrets, there are $100 million secrets that are a few lines of code,\u201d he said. \u201cAnd, you know, I\u2019m sure that there are folks trying to steal them, and they may be succeeding.\u201d\nMore help from the U.S. government to defend against this risk is \u201cvery important,\u201d Amodei added, without specifying exactly what kind of help would be required.\nAnthropic declined to comment to TechCrunch on the remarks specifically but referred toAnthropic\u2019s recommendationsto the White House\u2019s Office of Science and Technology Policy (OSTP) earlier this month.\nIn the submission, Anthropic argues that the federal government should partner with AI industry leaders to beef up security at frontier AI labs, including by working with U.S. intelligence agencies and their allies.\nThe remarks are in keeping with Amodei\u2019s more critical stance toward Chinese AI development. Amodei hascalled forstrong U.S. export controls on AI chips to Chinawhile saying that DeepSeek scored \u201cthe worst\u201don a critical bioweapons data safety test that Anthropic ran.\nAmodei\u2019s concerns, as he laid out in his essay \u201cMachines of Loving Grace\u201d and elsewhere, center on China using AI for authoritarian and military purposes.\nThis kind of stance has led tocriticismfrom some in the AI community who argue the U.S. and China should collaborate more, not less, on AI, in order to avoid an arms race that results in either country building a system so powerful that humans can\u2019t control it.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/how-to-watch-nvidia-gtc-2025-including-ceo-jensen-huangs-keynote/",
        "date_extracted": "2025-03-14T11:52:26.151249",
        "title": "How to watch Nvidia GTC 2025, including CEO Jensen Huang\u2019s keynote",
        "author": null,
        "publication_date": null,
        "content": "GTC, Nvidia\u2019s biggest conference of the year, will return starting Monday in San Jose. If you can\u2019t make it in person, don\u2019t sweat it. TechCrunch will be on the ground covering the major developments.\nMany of the biggest presentations, talks, and panels will be livestreamed as well. Nvidia CEO Jensen Huang is scheduled to deliver a keynote from the SAP Center on Tuesday at 10 a.m. PT, which you\u2019ll be able tostream and watch online at Nvidia.comwithout having to register and onNvidia\u2019s YouTube channel.\nWe\u2019re expecting Huang to revealmore about Nvidia\u2019s next flagship GPU series, Blackwell Ultra, and the next-gen Rubin chip architecture. Also likely on the agenda: automotive, robotics, and lots and lots of AI updates.\nNvidia.com is also where you\u2019ll find a catalog of all the virtual and on-demand sessions at GTC, including workshops onefficient large language model customization, conversations ongenerative AI for core banking, and demos ofdatasets for specialized domains like biology.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/nvidia-gtc-2025-what-to-expect-from-this-years-show/",
        "date_extracted": "2025-03-14T11:52:28.756302",
        "title": "Nvidia GTC 2025: What to expect from this year\u2019s show",
        "author": null,
        "publication_date": null,
        "content": "GTC, Nvidia\u2019s biggest conference of the year, begins Monday and runs till Friday in San Jose. TechCrunch will be on the ground covering the news as it happens \u2014 and we\u2019re expecting a healthy dose of announcements.\nCEO Jensen Huang will give a keynote address at the SAP Center on Tuesday at 10 a.m. Pacific, focusing on \u2014 what else? \u2014 AI and accelerating computing technologies,according to Nvidia. The company is also teasing reveals related to robotics,sovereign AI,AI agents, and automotive \u2014 plus 1,000 sessions with 2,000 speakers and close to 400 exhibitors.\nHere\u2019s how to watch the Nvidia GTC 2025 keynote online, along with many other sessions, talks, and panels.\nSo what do we expect to see at GTC? Well, Nvidia typically reserves a big chunk of the conference for GPU-related debuts. A new, upgraded iteration of the company\u2019s Blackwell chip lineup seems likely.\nDuring Nvidia\u2019s most recent earnings call, Huangconfirmedthat the upcoming Blackwell B300 series, codenamed Blackwell Ultra, is slated for release in the second half of this year. In addition to higher computing performance, Blackwell Ultra cards pack more memory (288GB), an attractive feature for customers looking to run and train memory-hungry AI models.\nRubin, Nvidia\u2019s next-gen GPU series, is almost certain to get a mention at GTC alongside Blackwell Ultra. Due out in 2026, Rubin promises to deliver what Huang has described as a \u201cbig, big, huge step up\u201d in computing power.\nHuang said during the aforementioned Nvidia earnings call that he\u2019d talk about post-Rubin products at GTC, as well. That could be Rubin Ultra GPUs, or perhaps the GPU architecture that\u2019ll come after the Rubin family.\nBeyond GPUs, Nvidia may illuminate its approach to recent quantum computing advancements. The company has scheduled a \u201cquantum day\u201d for GTC, during which it\u2019ll host execs from prominent companies in the space to \u201c[map] the path toward useful quantum applications.\u201d\nOne thing\u2019s for sure: Nvidia could use a win.\nEarly Blackwell cardsreportedly suffered from severe overheating issues, causing customers to cut their orders. U.S. export controls and fears of tariffs have massively depressed Nvidia\u2019s stock price in recent months. At the same time, the success of Chinese AI lab DeepSeek, which developed efficient models competitive with models from leading AI labs, has prompted investors to worry about the demand for powerful GPUs like Blackwell.\nHuang has asserted that DeepSeek\u2019s rise to prominence will in fact be anet positivefor Nvidia because it\u2019ll accelerate the broader adoption of AI technology. He has also pointed to the growth of power-hungry so-called \u201creasoning\u201d models like OpenAI\u2019s o1 as Nvidia\u2019s next mountain to climb.\nTo be clear, Nvidia isn\u2019t exactly hurting. The company reported a record-breaking quarter in February, notching $39.3 billion in revenue and projecting $43 billion in revenue for the subsequent quarter. While rivals such as AMD have begun to encroach on the company\u2019s territory, Nvidiastill commandsan estimated 82% of the GPU market.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/google-deepmind-unveils-new-ai-models-for-controlling-robots/",
        "date_extracted": "2025-03-14T11:52:31.739110",
        "title": "Google DeepMind unveils new AI models for controlling robots",
        "author": null,
        "publication_date": null,
        "content": "Google DeepMind, Google\u2019s AI research lab, on Wednesdayannounced new AI models called Gemini Roboticsdesigned to enable real-world machines to interact with objects, navigate environments, and more.\nDeepMind published a series of demo videos showing robots equipped with Gemini Robotics folding paper, putting a pair of glasses into a case, and other tasks in response to voice commands. According to the lab, Gemini Robotics was trained to generalize behavior across a range of different robotics hardware, and to connect items robots can \u201csee\u201d with actions they might take.\nDeepMind claims that in tests, Gemini Robotics allowed robots to perform well in environments not included in the training data. The lab has released a slimmed-down model, Gemini Robotics-ER, that researchers can use to train their own models for robotics control, as well as a benchmark called Asimov for gauging risks with AI-powered robots.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/browser-use-one-of-the-tools-powering-manus-is-also-going-viral/",
        "date_extracted": "2025-03-14T11:52:34.761102",
        "title": "Browser Use, one of the tools powering Manus, is also going viral",
        "author": null,
        "publication_date": null,
        "content": "Manus, the viral AI \u201cagent\u201d platform from Chinese startup Butterfly Effect, has had an unintended side effect: raising the profile of another AI tool called Browser Use.\nBrowser Use, which aims to make websites more accessible for agentic applications that perform tasks on a user\u2019s behalf, has experienced explosive growth in the past week. Daily downloads more than quintupled from around 5,000 on March 3 to 28,000 on March 10, co-creator Gregor Zunic told TechCrunch.\n\u201cThe past few days have been really wild,\u201d Zunic said via DM. \u201cWe are the biggest trending repository [on GitHub], got loads of downloads [and] all that actually converts to big usage numbers.\u201d\nWhy the uptick?A post about how Manus leverages Browser Usegarnered over 2.4 millions views and hundreds of reshares on X. Browser Use isone of the componentsManus employs to execute various tasks, like clicking through site menus and filling out forms.\nZunic launched the eponymous company behind Browser Use with Magnus M\u00fcller last year out of ETH Zurich\u2019s Student Project House accelerator. The pair thought web agents \u2014 agents that navigate websites and web apps autonomously \u2014 were going to be the \u201cbig thing\u201d in 2025.\n\u201cWhat started as casual brainstorming over a few lunches turned into a challenge: Let\u2019s build something small, throw it on Hacker News, and see what happens,\u201d Zunic said. \u201cWe put together an MVP in four days, launched it, and boom \u2014 number one. From there, it\u2019s been an absolute rocket.\u201d\nBrower Use extracts a website\u2019s elements \u2014 buttons, widgets, and so on \u2014 to allow AI models to more easily interact with them. The tool can manage multiple browser tabs, set up actions like saving files and performing database operations, and handle mouse and keyboard inputs.\nBrowser Usethe companycharges for managed plans, but also offers a free, self-hosted version of its software. That\u2019s the version that\u2019s blown up in the days since Manus\u2019 unveiling.\nZunic says he and Magnus are trying to \u201csell a shovel\u201d to developers chasing after the gold rush of web agents.\n\u201cWe wanted to create a foundation layer that everyone will build browser agents on,\u201d Zunic said. \u201cIn our minds, there will be more agents on the web than humans by the end of the year.\u201d\nThat might sound overly bullish, but several analysts predict that the broader market for AI agents will indeed grow enormously in the months to come.Accordingto Research and Markets, the sector will reach $42 billion in 2029. Deloitteanticipatesthat half of companies using AI will deploy AI agents by 2027.\nManus effect aside, Browser Use\u2019s timing appears to have been fortuitous.\nUpdated 12:45 p.m. Pacific: An earlier version of this story incorrectly referred to \u201cBrowser Use\u201d as \u201cBrowser User\u201d in the headline. We regret the error.\n",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/398959783-242ade3e-15bc-41c2-988f-cbc5415a66aa.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/daprs-microservices-runtime-now-supports-ai-agents/",
        "date_extracted": "2025-03-14T11:52:37.363998",
        "title": "Dapr\u2019s microservices runtime now supports AI agents",
        "author": null,
        "publication_date": null,
        "content": "Back in 2019, Microsoftopen sourced Dapr, a new runtime for making building distributed microservice-based applications easier. At the time, nobody was talking about AI agents yet, but as it turns out, Dapr had some of the fundamental building blocks for supporting AI agents built-in from the outset. That\u2019s because one of Dapr\u2019s core features is a concept of virtualactors, which can receive and process messages independently from all the other actors in the system.\nToday, the Dapr team is launching Dapr Agents, its take on helping developers build AI agents by providing them with a lot of the building blocks to do so.\n\u201cAgents are a very good use case for Dapr,\u201d Dapr co-creator and maintainer Yaron Schneider explained. \u201cFrom a technical perspective, you could use actors as a very lightweight way to run these agents and really be able to run them at scale with state \u2014 and be resource-efficient. This is all great, but then, there is still a lot of business logic you need to write. The statefulness and the orchestration of it are just one part. And many people, they might choose a workflow engine or an actor framework, but there\u2019s still a lot of work they need to do to actually write the agent logic on the other side. There is lots of agent frameworks out there, but they don\u2019t have the same level of orchestration and statefulness that Dapr has.\u201d\nDapr Agents originated fromFloki, a popular open source project that extended Dapr for this AI agent use case. Talking with the project maintainers, including Microsoft AI researcher Roberto Rodriguez, the two teams decided to bring the project under the Dapr umbrella to ensure the continuity of the new agent framework.\n\u201cIn many ways we see agentic systems and the whole terminology around that as another term for \u2018distributed systems,\u2019 Dapr co-creator and maintainer Mark Fussell said. \u201c[\u2026] Rather than calling them microservices, you can call them agents now, mostly because you can put large language models amongst them all.\u201d\nTo efficiently coordinate those agents, you do need an orchestration engine and statefulness, the team argues \u2014 which is exactly what Dapr delivers. That\u2019s in part because Dapr\u2019s actors are meant to be extremely efficient and able to spin up within milliseconds when a message comes in (and shut down, with their state preserved, when their job is done).\nRight now, Dapr Agents can talk to most of the popular model providers out of the box. These include AWS Bedrock, OpenAI, Anthropic, Mistral, and Hugging Face. Support for local LLMs will arrive very soon.\nOn top of interacting with these models, since Dapr Agents extend the existing Dapr framework, developers also get the ability to define a list of tools that the agent can then use to fulfill a given task.\nCurrently, Dapr Agents supports Python, with .NET support launching soon. Java, JavaScript and Go will follow soon.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/dapr_agents.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/sakana-claims-its-ai-paper-passed-peer-review-but-its-a-bit-more-nuanced-than-that/",
        "date_extracted": "2025-03-14T11:52:40.057016",
        "title": "Sakana claims its AI-generated paper passed peer review \u2014 but it\u2019s a bit more nuanced than that",
        "author": null,
        "publication_date": null,
        "content": "Japanese AI startupSakanasaid that its AI generated one of the first peer-reviewed scientific publications. But while the claim isn\u2019t necessarily untrue, there are caveats to note.\nThedebate swirling around AI and its role in the scientific processgrows fiercer by the day. Many researchers don\u2019t think AI is quite ready to serve as a \u201cco-scientist,\u201d while others think that there\u2019s potential \u2014 but acknowledge it\u2019s early days.\nSakana falls into the latter camp.\nThe company said that it used an AI system called The AI Scientist-v2 to generate a paper that Sakana then submitted to a workshop at ICLR, a long-running and reputable AI conference. Sakana claims that the workshop\u2019s organizers, as well as ICLR\u2019s leadership, had agreed to work with the company to conduct an experiment to double-blind review AI-generated manuscripts.\nSakana said it collaborated with researchers at the University of British Columbia and the University of Oxford to submit three AI-generated papers to the aforementioned workshop for peer review. The AI Scientist-v2 generated the papers \u201cend-to-end,\u201d Sakana claims, including the scientific hypotheses, experiments and experimental code, data analyses, visualizations, text, and titles.\n\u201cWe generated research ideas by providing the workshop abstract and description to the AI,\u201d Robert Lange, a research scientist and founding member at Sakana, told TechCrunch via email. \u201cThis ensured that the generated papers were on topic and suitable submissions.\u201d\nOne paper out of the three was accepted to the ICLR workshop \u2014 a paper that casts a critical lens on training techniques for AI models. Sakana said it immediately withdrew the paper before it could be published in the interest of transparency and respect for ICLR conventions.\n\u201cThe accepted paper both introduces a new, promising method for training neural networks and shows that there are remaining empirical challenges,\u201d Lange said. \u201cIt provides an interesting data point to spark further scientific investigation.\u201d\nBut the achievement isn\u2019t as impressive as it might seem at first glance.\nIn the blog post, Sakana admits that its AI occasionally made \u201cembarrassing\u201d citation errors, for example incorrectly attributing a method to a 2016 paper instead of the original 1997 work.\nSakana\u2019s paper also didn\u2019t undergo as much scrutiny as some other peer-reviewed publications. Because the company withdrew it after the initial peer review, the paper didn\u2019t receive an additional \u201cmeta-review,\u201d during which the workshop organizers could have in theory rejected it.\nThen there\u2019s the fact that acceptance rates for conference workshops tend to be higher than acceptance rates for the main \u201cconference track\u201d \u2014 a fact Sakana candidly mentions in its blog post. The company said that none of its AI-generated studies passed its internal bar for ICLR conference track publication.\nMatthew Guzdial, an AI researcher and assistant professor at the University of Alberta, called Sakana\u2019s results \u201ca bit misleading.\u201d\n\u201cThe Sakana folks selected the papers from some number of generated ones, meaning they were using human judgment in terms of picking outputs they thought might get in,\u201d he said via email. \u201cWhat I think this shows is that humans plus AI can be effective, not that AI alone can create scientific progress.\u201d\nMike Cook, a research fellow at King\u2019s College London specializing in AI, questioned the rigor of the peer reviewers and workshop.\n\u201cNew workshops, like this one, are often reviewed by more junior researchers,\u201d he told TechCrunch. \u201cIt\u2019s also worth noting that this workshop is about negative results and difficulties \u2014 which is great, I\u2019ve run a similar workshop before \u2014 but it\u2019s arguably easier to get an AI to write about a failure convincingly.\u201d\nCook added that he wasn\u2019t surprised an AI can pass peer review, considering that AI excels at writing human-sounding prose. PartlyAI-generatedpaperspassing journal review isn\u2019t even new, Cook pointed out, nor are the ethical dilemmas this poses for the sciences.\nAI\u2019s technical shortcomings \u2014 such as its tendency tohallucinate\u2014 make many scientists wary of endorsing it for serious work. Moreover, experts fear AI could simplyend up generating noisein the scientific literature, not elevating progress.\n\u201cWe need to ask ourselves whether [Sakana\u2019s] result is about how good AI is at designing and conducting experiments, or whether it\u2019s about how good it is at selling ideas to humans \u2014 which we know AI is great at already,\u201d Cook said. \u201cThere\u2019s a difference between passing peer review and contributing knowledge to a field.\u201d\nSakana, to its credit, makes no claim that its AI can produce groundbreaking \u2014 or even especially novel \u2014 scientific work. Rather, the goal of the experiment was to \u201cstudy the quality of AI-generated research,\u201d the company said, and to highlight the urgent need for \u201cnorms regarding AI-generated science.\u201d\n\u201c[T]here are difficult questions about whether [AI-generated] science should be judged on its own merits first to avoid bias against it,\u201d the company wrote. \u201cGoing forward, we will continue to exchange opinions with the research community on the state of this technology to ensure that it does not develop into a situation in the future where its sole purpose is to pass peer review, thereby substantially undermining the meaning of the scientific peer review process.\u201d",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/paper_abstract.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/snap-introduces-ai-video-lenses-powered-by-its-in-house-generative-model/",
        "date_extracted": "2025-03-14T11:52:42.929253",
        "title": "Snap introduces AI Video Lenses powered by its in-house generative model",
        "author": null,
        "publication_date": null,
        "content": "Snapchat is introducing its first-ever video generative AI Lenses, the company told TechCrunch exclusively. The Lenses are powered by Snap\u2019s in-house-built generative video model. The three new AI Video Lenses\u00a0are available to users on the app\u2019s premium subscription tier, Snapchat Platinum, which costs $15.99 per month.\nThe launch comes as Snap unveiled anAI video-generation toolat its Partner Summit last September. A spokesperson for Snap said the new AI Video Lenses leverage later versions of this underlying technology.\nSnap has been seen as a leader in AR, but has also been investing in AI over the past few years alongside nearly every other tech company. With these new AI Video Lenses, Snap is adopting AI to stay competitive and provide its users with features that aren\u2019t yet available on its rivals\u2019 platforms, including Instagram and TikTok.\nWhile Snapchat is starting with three AI Video Lenses at launch, it plans to add more every week. The initial Lenses include \u201cRaccoon\u201d and \u201cFox,\u201d both of which animate furry friends cuddling up with you. The third \u201cSpring Flowers\u201d Lens generates a zoom-out effect revealing the person in your Snap holding a bouquet.\nYou can access the new Lenses through the Lens carousel. You can then select the Lens, then capture a Snap through either your front or back camera. The AI video will generate and then automatically save to your Memories.\n\u201cThese Lenses, powered by our in-house built generative video model, bring some of the most cutting edge AI tools available today to Snapchatters through a familiar Lens format,\u201d the company wrote in ablog post. \u201cWe have a long history of being first movers to bring advanced AR, ML and AI tools directly to our community, and we\u2019re excited to see what Snapchatters create.\u201d\nAs Snapchat notes, it makes sense for the company to bring generative AI to Lenses, given that it\u2019s a format users have embraced for years.\nWhile Snap has tapped AI tools fromOpenAIandGooglein the past to power some of its features, it\u2019s now also building its own in-house models.\nLast month, the companyunveiled an AI text-to-image research modelfor mobile devices that will power some of Snapchat\u2019s features in the coming months. Snap said at the time that by implementing in-house technology, it will be able to offer its community high-quality AI tools at a lower operating cost.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/Img2Video-Lenses-3.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/moonvalley-releases-a-video-generator-it-claims-was-trained-on-licensed-content/",
        "date_extracted": "2025-03-14T11:52:45.554170",
        "title": "Moonvalley releases a video generator it claims was trained on licensed content",
        "author": null,
        "publication_date": null,
        "content": "Los Angeles-based startupMoonvalleyhaslaunchedan AI video-generating model it claims is one of the few trained on openly licensed \u2014 not copyrighted \u2014 data.\nNamed \u201cMarey\u201d after cinema trailblazer \u00c9tienne-Jules Marey, the model was built in collaboration with Asteria, anewer AI animation studio. Marey was trained on \u201cowned or fully licensed\u201d source data, according to Moonvalley, and offers customization options including fine-grained camera and motion controls.\n\u201cMarey enables nuanced control over in-scene movements,\u201d Moonvalley wrote in a press release provided to TechCrunch, \u201csuch as controlling the movement of an individual checkers piece, or animating the exact breeze blowing through a person\u2019s hair.\u201d\nThe wide availability of tools to build video generators has led to a Cambrian explosion of vendors in the space. In fact, it risks becoming oversaturated. Startups such asRunwayandLuma, as well as tech giants likeOpenAIandGoogle, are releasing models at a fast clip \u2014 in many cases with little to distinguish them from each other.\nMoonvalley is pitching Marey, which can generate \u201cHD\u201d clips up to 30 seconds in length, as lower risk than competitors, from a legal perspective.\nMoonvalley is a go! \ud83c\udf17\ud83d\ude80\nAs many of you know, I\u2019ve been working a lot in the video and animation space the last few months, and it\u2019s been thrilling to watch this model being built behind the scenes!\nStoked to have had a chance to start playing with Marey, the world\u2019s first 100%\u2026pic.twitter.com/dDl4KWeHRT\n\u2014 Araminta (@araminta_k)March 12, 2025\n\nMany generative video startups train models on public data, some of which is invariably copyrighted. These companies argue thatfair-usedoctrine shields the practice. But that hasn\u2019t stopped rights ownersfrom lodging complaintsand filing cease and desists.\nMoonvalley says it\u2019s working with partners to handle licensing arrangements and package videos into datasets that the company then purchases. The approach is similar toAdobe\u2019s, which also procures video footage for training from creators through its Adobe Stock platform.\nMany artists and creators are wary of video generators, and understandably so \u2014 they threaten to upend the film and television industry. A 2024studycommissioned by the Animation Guild, a union representing Hollywood animators and cartoonists, estimates that more than 100,000 U.S.-based film, television, and animation jobs will be disrupted by AI by 2026.\nMoonvalley intends to let creators request their content be removed from its models, allow customers to delete their data at any time, and offer anindemnity policyto protect users from copyright challenges.\nUnlike some \u201cunfiltered\u201d video models that readily insert a person\u2019s likeness into clips, Moonvalley is also committing to building guardrails around its creative tooling. Like OpenAI\u2019s Sora, Moonvalley\u2019s models will block certain content, like NSFW phrases, and won\u2019t allow people to prompt them to generate videos of specific people or celebrities.\n\u201cWe\u2019re proving it\u2019s possible to train AI models without brazenly stealing creative work from the creators \u2014 the cinematographers, visual artists, creators, and creative producers \u2014 whose voices we aim to uplift with our technology,\u201d Moonvalley co-founder and CEO Naeem Talukdar said in a statement. \u201cAt Moonvalley, we\u2019re setting a new standard for generative AI to deliver industry-leading AI capabilities while ensuring that the voices and rights of creatives are not lost as this technology and industry evolve.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/why-onyx-thinks-its-open-source-solution-will-win-enterprise-search/",
        "date_extracted": "2025-03-14T11:52:48.457743",
        "title": "Why Onyx thinks its open source solution will win enterprise search",
        "author": null,
        "publication_date": null,
        "content": "Enterprises have troves of internal data and information that employees need to complete their tasks or answer questions for potential customers. But that doesn\u2019t mean the right information is easy to find.\nOnyxwants to solve that problem through its internal enterprise search tool. There are other big names in the category, likeGlean\u2014 which has raised $600 million in venture funding \u2014 fighting for market share in the hot category, but San Francisco-based Onyx has a differentiator that helps separate it from the pack, it says. It\u2019s open source.\nCompanies can get Onyx running in about 30 minutes, and it connects to more than 40 internal company data sources, including Salesforce, GitHub, and Google Drive. Enterprise users can then pay for additional tiers of features like increased sign-in security and increased encryption.\nChris Weaver, co-founder and co-CEO of Onyx, told TechCrunch that he and his co-founder and co-CEO Yuhong Sun originally set out to fix a problem both he and Sun were seeing in their respective engineering roles.\n\u201cWe knew where things were roughly, but it was still kind of hard, [and] new people just couldn\u2019t find anything,\u201d Weaver said. \u201cIt felt like there had to be a better way to do this.\u201d\nOnyx isn\u2019t Weaver and Sun\u2019s first attempt at building a company. Their first idea, a live stats tracking app for Twitch streamers, was going well until Twitch killed embedded streams and rendered the product essentially unusable. Their second effort, a site to help people compare speciality keyboards, didn\u2019t work either.\nBut with Sun\u2019s machine learning background\u00a0and the overall advancements in AI technology, Onyx \u2014 originally called Danswer, a portmanteau for deep answer \u2014 was different. They released the original open source project in 2023 and received strong momentum and feedback right away.\n\u201cRamp was actually one of the early teams that found us,\u201d Sun said. \u201cAt the time, we didn\u2019t have any way for them to pay us or anything. We didn\u2019t have anything like support plans or whatever, and there were no paid features. For us, it was like, people really want to pay for our project. I mean, it\u2019s free, but people want to pay for it. So, you know, maybe there\u2019s a chance to make a business from this.\u201d\nToday the company works with dozens of enterprises, including Netflix, Ramp, and Thales Group. Sun and Weaver largely credit the company\u2019s success to their decision to open source the software. It has allowed companies to experiment and also avoid a lengthy enterprise sales cycle.\n\u201cOpen source is really the only way for this type of solution to scale out and get the momentum into every single business in the world,\u201d said Weaver.\nWhile confident that open source is the winning strategy for internal search, the team is entering a competitive field. Beyond startups like Glean, they face competition from companies building their own internal solutions, like the fintech Klarna, which has built aninternal search and chatbot tool, Kiki.\nOnyx isn\u2019t deterred. Starting an internal search tool from scratch is really hard, Weaver said, and he thinks of Onyx as a foundational tool for companies that want to build their own internal search products. He said the proof is in the numbers.\n\u201cWe\u2019ve seen the usage grow explosively,\u201d Sun said. \u201cWe hit a peak of over 160,000 messages in a single week. We are really hoping to lean into that organic growth and hopefully all the teams in the world will use Onyx one day.\u201d\nThe company also recently attracted a $10 million seed round co-led by Khosla Ventures and First Round Capital, with participation from Y Combinator and angel investors. Among them are Gokul Rajaram, former board member at Coinbase and Pinterest; Arash Ferdowsi, a co-founder of Dropbox; and Amit Agarwal, the former chief product officer of Datadog.\nOnyx plans to use the funds to hire staff and develop more premium features.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/pentera-nabs-60m-at-a-1b-valuation-to-build-simulated-network-attacks-to-train-security-teams/",
        "date_extracted": "2025-03-14T11:52:51.203900",
        "title": "Pentera nabs $60M at a $1B+ valuation to build simulated network attacks to train security teams",
        "author": null,
        "publication_date": null,
        "content": "Strong and smart security operations teams are at the heart of any cybersecurity strategy, and today a startup that builds tooling to help keep them on their toes is announcing some funding on the back of a lot of growth.Pentera\u2014 which has built a system that launches simulations of network attacks to stress test software and human response \u2014 is announcing $60 million in funding, a Series D that values the Boston-based, Tel Aviv-founded startup at over $1 billion.\nThe funding will be used for M&A and to continue developing its product, CEO Amitai Ratzon said in an interview.\nPentera is a play on the term \u201cpen testing,\u201d which is short for penetration testing, programs that have been devised to help drill security teams on potential attack techniques. This is effectively what Pentera has built to an elaborate degree in a product that is officially described as \u201cautomated security validation.\u201d\n\u201cWe provide enterprises and governments a technology that, with a click of a button, can launch a mega attack against themselves, and with another click, the genie goes back into the bottle,\u201d said Ratzon. \u201cThe beautiful thing is that it\u2019s all safe by design.\u201d\nAnd in contrast to, say, a fire drill in an office, Pentera\u2019s simulated attacks are carried out in a way where the rest of the organization outside of the security team is none the wiser \u2014 not unlike a lot of real-world security breaches in fact.\nThe round is coming on the heels of Pentera growing customers by 200% to 1,100 organizations and ARR by 300% in the last four years, underscoring the demand in the market for its tools.\nEvolution Equity Partners is leading the round, with Farallon Capital participating. Prior to this, the company \u2014 which was originally called Pcysys; it rebranded in 2021 \u2014 had raised $190 million in a combination of primary and secondary equity, according toPitchBook. Its other investors include Insight, K1, and Blackstone.\nPentera\u2019s rise is coming amid a wave of automation in the world of cybersecurity.\nThe world of cybersecurity has been virtually ambushed by the arrival of AI, which is used both by malicious hackers to breach systems, and also by a wide array of tools to help identify and stop those attacks in their tracks.\nPentera takes this swing in AI into account as part of its platform. When it launches attacks, it does so around specific vulnerabilities and in the process identifies the different areas in an organization\u2019s network that might be exploited.\nTypically, this could throw up as many as 10,000 alerts, Ratzon said.\nTo be fair, an overwhelming number of alerts in live products is a classic issue with a lot of security tooling, and a number of startups are tackling that problem, too. In the case of Pentera, it automatically takes that 10,000 and whittles it down to six or eight root causes or exploitable vulnerabilities, he said, and then provides suggestions for how to fix them, and then leaves that to the teams to handle.\n\u201cPentera\u00a0has redefined enterprise security testing and validation practices,\u201d said\u00a0Richard Seewald, managing partner at Evolution Equity Partners, in a statement. \u201cPentera\u2019s exceptional growth, strong enterprise adoption, and category-defining innovation make it the clear leader in Automated Security Validation. We are proud to lead this investment and continue our relationship with\u00a0Pentera\u00a0as it scales globally, expands its technology, and continues to set the industry standard for security validation.\u201d\nPentera is far from the only company that provides penetration testing tools to enterprises. Others that create automated simulations that are more direct competitors include Cymulate, which was last valued at around $500 million in a funding round in2022.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/wolf-games-backed-by-law-order-creator-uses-ai-to-create-murder-mystery-games/",
        "date_extracted": "2025-03-14T11:52:53.663475",
        "title": "Wolf Games, backed by \u2018Law & Order\u2019 creator, uses AI to create murder mystery games",
        "author": null,
        "publication_date": null,
        "content": "Elliot Wolf, the executive producer and son of \u201cLaw & Order\u201d creator Dick Wolf, is entering a new venture aimed at engaging true crime fans.\nHe, along with co-founders Andrew Adashek (CEO) and Noah Rosenberg (CTO), are developingWolf Games, a new startup that leverages AI to generate daily murder mystery games. The company also announced on Wednesday its $4 million seed funding round.\nWolf Games\u2019 flagship title is called Public Eye and capitalizes on the growing interest among true crime enthusiasts who often love to play detective.\nPublic Eye is set in a dystopian future where crime rates have skyrocketed to the point where law enforcement thinks asking the public for assistance is a smart idea. Players gather clues, piece together evidence, and enlist the help of an AI assistant, which guides them through investigations and offers hints to help solve the crime.\nHowever, creating new murder mysteries for players to solve on a daily basis is a tall order. To tackle this, Wolf Games leverages an AI engine that helps the team of writers whip up new cases.\nThe AI draws inspiration from headlines published by major news sources such as CBS and NBC. Similar to \u201cLaw & Order,\u201d one of the longest-running true crime dramas in TV history, the company says that the stories in the game are primarily fictional and are inspired by these headlines rather than copied directly.\nIn addition to story creation, AI is also used to generate interview clips and photos of crime scenes.\n\u201cIn a single click, we take this linear story and make it fully interactive and playable,\u201d Wolf told TechCrunch, adding that top AI models like Gemini are used to ensure character consistency throughout the story.\n\u201cIf a character gets a scar on their face halfway through the story, every time that character appears, they\u2019ll have the scar,\u201d Wolf explained.\nWe tested the game ourselves, where we attempted to solve the murder of a store owner. The suspects included a sketchy intern, a drunken boyfriend, and a fed-up daughter. For a story mostly generated by AI, it was surprisingly OK and even had an unexpected twist at the end. (It\u2019s worth noting that it\u2019s hard to go wrong with a true crime story, considering the abundance of real-life events that can inspire dramatic storylines.)\nThe true crime genre of games is highly competitive, but the founders think they have the expertise to garner a significant audience.\nThe caliber of the investors also tells a compelling story. The pre-seed round included participation from Dick Wolf, Beats co-founder Jimmy Iovine, and United Talent Agency Chairman Paul Wachter.\nPublic Eye launches on the web this summer. It\u2019ll be free to play with optional in-app purchases; you\u2019ll need tojoin a waitlistif you want to give it a shot.\nIn the future, Wolf Games is considering working with IP holders to adapt TV shows into new games.\nIt\u2019s notable that Hollywood executives continue to launch AI startups, especially considering the2023strikeswhere the use of AI was a contentious issue. The Oscar-winning film \u201cThe Brutalist\u201d is the latest example of a production that faced backlash from viewers for its use of an AI voice tool.\nHowever, despite the industry grappling with the implications of AI, a growing number of celebrities \u2014 such asAshton Kutcherandwill.i.am\u2014 are investing in AI ventures, indicating a desire to harness this technology for entertainment.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/New-Suspect-e1741731554247.png?w=314"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/meta-faces-publisher-copyright-ai-lawsuit-in-france/",
        "date_extracted": "2025-03-14T11:52:56.341306",
        "title": "Meta faces publisher copyright AI lawsuit in France",
        "author": null,
        "publication_date": null,
        "content": "Meta is facing an AI copyright lawsuit in France that\u2019s been brought by authors and publishers who are accusing it of economic \u201cparasitism,\u201dReutersreports.\nThe French litigation was filed in a Paris court this week by the National Publishing Union (SNE), the National Union of Authors and Composers (SNAC), and the Society of People of Letters (SGDL), which are accusing Meta of unlawfully training its AI models on their protected content.\nThe case is thought to be the first such action against an AI giant in the country. Meta is facing similar litigationin the U.S.in relation to the alleged use of unlicensed protected material to train its large language models, such as Llama.\nReporting on comments made by the publishing associations at a press conference on Wednesday, Reuters quotes Maia Bensimon, the general delegate of SNAC, who alleged Meta is guilty of \u201cmonumental looting.\u201d The SNE\u2019s director general, Renaud Lefebvre, also dubbed the legal fight that the publishers are embarking on as a \u201cDavid versus Goliath battle.\u201d\nMeta has been contacted for comment.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/salesforce-to-invest-1b-in-singapore-to-boost-adoption-of-ai/",
        "date_extracted": "2025-03-14T11:52:59.209015",
        "title": "Salesforce to invest $1B in Singapore to boost adoption of AI",
        "author": null,
        "publication_date": null,
        "content": "Salesforceplans to invest $1 billionin Singapore over the next five years as it seeks to fuel the adoption of its AI agent development platform, Agentforce.\nSalesforce claimed that Agentforce can help alleviate Singapore\u2019s ongoing labor issues and augment the country\u2019s workforce and enterprises by creating \u201cdigital workforces\u201d that combine humans with autonomous AI agents.\nThe initiative follows a recent$500 million commitment in Saudi Arabiaandanother $500 million investment in Argentinaby the cloud software giant to expand its AI and cloud services, including Agentforce.\nThe company has been investing in Singapore for nearly two decades, and set up its first overseas AI Research hub in the country in 2019. Its customers in the country include Singapore Airlines, Grab,M1, FairPrice Group, and Ocean Network Express.\nThe CRM giant separately alsosaid it has signed a deal with Singapore Airlinesto integrate Agentforce; Salesforce\u2019s AI layer, Einstein, in Service Cloud; and Data Cloud into the airline\u2019s customer case management system. The companies also plan to develop AI solutions for airlines at Salesforce\u2019s AI Research hub.\nSalesforce has beendoubling down on AIfor a while now. The company is reportedlyreducing its workforce by more than 1,000 employeeswhilehiring about 2,000 people to sell new AI products.\nOther U.S. tech giants have been investing heavily in Southeast Asia as well. Last May, Amazon Web Services said it wouldinvest a fresh $9 billion over the next five yearsin Singapore to grow its cloud infrastructure and services. And Microsoft last year said it would invest$2.2 billion in Malaysiaand$1.7 billion in Indonesiaover the next four years.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/elea-ai-is-chasing-the-healthcare-productivity-opportunity-by-targeting-pathology-labs-legacy-systems/",
        "date_extracted": "2025-03-14T11:53:01.828865",
        "title": "Elea AI is chasing the healthcare productivity opportunity by targeting pathology labs\u2019 legacy systems",
        "author": null,
        "publication_date": null,
        "content": "VC funding into AI tools for healthcare wasprojected to hit $11 billion last year\u2014 a headline figure that speaks to the widespread conviction that artificial intelligence will prove transformative in a critical sector.\nMany startups applying AI in healthcare are seeking to drive efficiencies by automating some of the administration that orbits and enables patient care. Hamburg-basedEleabroadly fits this mold, but it\u2019s starting with a relatively overlooked and underserved niche \u2014 pathology labs, whose work entails analyzing patient samples for disease \u2014 from where it believes it\u2019ll be able to scale the voice-based, AI agent-powered workflow system it\u2019s developed to boost labs\u2019 productivity to achieve global impact. Including by transplanting its workflow-focused approach to accelerating the output of other healthcare departments, too.\nElea\u2019s initial AI tool is designed to overhaul how clinicians and other lab staff work. It\u2019s a complete replacement for legacy information systems and other set ways of working (such as using Microsoft Office for typing reports) \u2014 shifting the workflow to an \u201cAI operating system\u201d which deploys speech-to-text transcription and other forms of automation to \u201csubstantially\u201d shrink the time it takes them to output a diagnosis.\nAfter around half a year operating with its first users, Elea says its system has been able to cut the time it takes the lab to produce around half their reports down to just two days.\nThe step-by-step, often manual workflow of pathology labs means there\u2019s good scope to boost productivity by applying AI, says Elea\u2019s CEO and co-founder Dr. Christoph Schr\u00f6der. \u201cWe basically turn this all around \u2014 and all of the steps are much more automated \u2026 [Doctors] speak to Elea, the MTAs [medical technical assistants] speak to Elea, tell them what they see, what they want to do with it,\u201d he explains.\n\u201cElea is the agent, performs all the tasks in the system and prints things \u2014 prepares the slides, for example, the staining and all those things \u2014 so that [tasks] go much, much quicker, much, much smoother.\u201d\n\u201cIt doesn\u2019t really augment anything, it replaces the entire infrastructure,\u201d he adds of the cloud-based software they want to replace the lab\u2019s legacy systems and their more siloed ways of working, using discrete apps to carry out different tasks. The idea for the AI OS is to be able to orchestrate everything.\nThe startup is building on variouslarge language models(LLMs) through fine-tuning with specialist information and data to enable core capabilities in the pathology lab context. The platform bakes in speech-to-text to transcribe staff voice notes \u2014 and also \u201ctext-to-structure\u201d; meaning the system can turn these transcribed voice notes into active direction that powers the AI agent\u2019s actions, which can include sending instructions to lab kits to keep the workflow ticking along.\nElea also plans to develop its own foundational model for slide image analysis, per Schr\u00f6der, as it pushes toward developing diagnostic capabilities, too. But for now, it\u2019s focused on scaling its initial offering.\nThe startup\u2019s pitch to labs suggests that what could take them two to three weeks using conventional processes can be achieved in a matter of hours or days as the integrated system is able to stack up and compound productivity gains by supplanting things like the tedious back-and-forth that can surround manual typing up of reports, where human error and other workflow quirks can inject a lot of friction.\nThe system can be accessed by lab staff through an iPad app, Mac app, or web app \u2014 offering a variety of touch-points to suit the different types of users.\nThe business was founded in early 2024 and launched with its first lab in October having spent some time in stealth working on their idea in 2023, per Schr\u00f6der, who has a background in applying AI for autonomous driving projects at Bosch, Luminar, and Mercedes.\nAnother co-founder, Dr. Sebastian Casu \u2014 the startup\u2019s CMO \u2014 brings a clinical background, having spent more than a decade working in intensive care, anesthesiology, and across emergency departments, as well as previously being a medical director for a large hospital chain.\nSo far, Elea has inked a partnership with a major German hospital group (it\u2019s not disclosing which one as yet) that it says processes some 70,000 cases annually. So the system has hundreds of users so far.\nMore customers are slated to launch \u201csoon\u201d \u2014 and Schr\u00f6der also says it\u2019s looking at international expansion, with a particular eye on entering the U.S. market.\nThe startup is disclosing for the first time a \u20ac4 million seed it raised last year \u2014 led by Fly Ventures and Giant Ventures \u2014 that\u2019s been used to build out its engineering team and get the product into the hands of the first labs.\nThis figure is a pretty small sum versus the aforementioned billions in funding that are now flying around the space annually. But Schr\u00f6der argues AI startups don\u2019t need armies of engineers and hundreds of millions to succeed \u2014 it\u2019s more a case of applying the resources you have smartly, he suggests. And in this healthcare context, that means taking a department-focused approach and maturing the target use case before moving on to the next application area.\nStill, at the same time, he confirms the team will be looking to raise a (larger) Series A round \u2014 likely this summer \u2014 saying Elea will be shifting gears into actively marketing to get more labs buying in, rather than relying on the word-of-mouth approach they started with.\nDiscussing their approach versus the competitive landscape for AI solutions in healthcare, he tells us: \u201cI think the big difference is it\u2019s a spot solution versus vertically integrated.\u201d\n\u201cA lot of the tools that you see are add-ons on top of existing systems [such as EHR systems] \u2026 It\u2019s something that [users] need to do on top of another tool, another UI, something else that people that don\u2019t really want to work with digital hardware have to do, and so it\u2019s difficult, and it definitely limits the potential,\u201d he goes on.\n\u201cWhat we built instead is we actually integrated it deeply into our own laboratory information system \u2014 or we call it pathology operating system \u2014 which ultimately means that the user doesn\u2019t even have to use a different UI, doesn\u2019t have to use a different tool. And it just speaks with Elea, says what it sees, says what it wants to do, and says what Elea is supposed to do in the system.\u201d\n\u201cYou also don\u2019t need gazillions of engineers anymore \u2014 you need a dozen, two dozen really, really good ones,\u201d he also argues. \u201cWe have two dozen engineers, roughly, on the team \u2026 and they can get done amazing things.\u201d\n\u201cThe fastest growing companies that you see these days, they don\u2019t have hundreds of engineers \u2014 they have one, two dozen experts, and those guys can build amazing things. And that\u2019s the philosophy that we have as well, and that\u2019s why we don\u2019t really need to raise \u2014 at least initially \u2014 hundreds of millions,\u201d he adds.\n\u201cIt is definitely a paradigm shift \u2026 in how you build companies.\u201d\nChoosing to start with pathology labs was a strategic choice for Elea as not only is the addressable market worth multiple billions of dollars, per Schr\u00f6der, but he couches the pathology space as \u201cextremely global\u201d \u2014 with global lab companies and suppliers amping up scalability for its software as a service play \u2014 especially compared to the more fragmented situation around supplying hospitals.\n\u201cFor us, it\u2019s super interesting because you can build one application and actually scale already with that \u2014 from Germany to the U.K., the U.S.,\u201d he suggests. \u201cEveryone is thinking the same, acting the same, having the same workflow. And if you solve it in German, the great thing with the current LLMs, then you solve it also in English [and other languages like Spanish] \u2026 So it opens up a lot of different opportunities.\u201d\nHe also lauds pathology labs as \u201cone of the fastest growing areas in medicine\u201d \u2014 pointing out that developments in medical science, such as the rise in molecular pathology and DNA sequencing, are creating demand for more types of analysis, and for a greater frequency of analyses. All of which means more work for labs \u2014 and more pressure on labs to be more productive.\nOnce Elea has matured the lab use case, he says they may look to move into areas where AI is more typically being applied in healthcare \u2014 such as supporting hospital doctors to capture patient interactions \u2014 but any other applications they develop would also have a tight focus on workflow.\n\u201cWhat we want to bring is this workflow mindset, where everything is treated like a workflow task, and at the end, there is a report \u2014 and that report needs to be sent out,\u201d he says \u2014 adding that in a hospital context they wouldn\u2019t want to get into diagnostics but would \u201creally focus on operationalizing the workflow.\u201d\nImage processing is another area Elea is interested in other future healthcare applications \u2014 such as speeding up data analysis for radiology.\nWhat about accuracy? Healthcare is a very sensitive use case so any errors in these AI transcriptions \u2014 say, related to a biopsy that\u2019s checking for cancerous tissue \u2014 could lead to serious consequences if there\u2019s a mismatch between what a human doctor says and what Elea hears and reports back to other decision makers in the patient care chain.\nCurrently, Schr\u00f6der says they\u2019re evaluating accuracy by looking at things like how many characters users change in reports the AI serves up. At present, he says there are between 5% to 10% of cases where some manual interactions are made to these automated reports which might indicate an error. (Though he also suggests doctors may need to make changes for other reasons \u2014 but say they are working to \u201cdrive down\u201d the percentage where manual interventions happen.)\nUltimately, he argues, the buck stops with the doctors and other staff who are asked to review and approve the AI outputs \u2014 suggesting Elea\u2019s workflow is not really any different from the legacy processes that it\u2019s been designed to supplant (where, for example, a doctor\u2019s voice note would be typed up by a human and such transcriptions could also contain errors \u2014 whereas now \u201cit\u2019s just that the initial creation is done by Elea AI, not by a typist\u201d).\nAutomation can lead to a higher throughput volume, though, which could be pressure on such checks as human staff have to deal with potentially a lot more data and reports to review than they used to.\nOn this, Schr\u00f6der agrees there could be risks. But he says they have built in a \u201csafety net\u201d feature where the AI can try to spot potential issues \u2014 using prompts to encourage the doctor to look again. \u201cWe call it a second pair of eyes,\u201d he notes, adding: \u201cWhere we evaluate previous findings reports with what [the doctor] said right now and give him comments and suggestions.\u201d\nPatient confidentiality may be another concern attached to agentic AI that relies on cloud-based processing (as Elea does), rather than data remaining on-premise and under the lab\u2019s control. On this, Schr\u00f6der claims the startup has solved for \u201cdata privacy\u201d concerns by separating patient identities from diagnostic outputs \u2014 so it\u2019s basically relying on pseudonymization for data protection compliance.\n\u201cIt\u2019s always anonymous along the way \u2014 every step just does one thing \u2014 and we combine the data on the device where the doctor sees them,\u201d he says. \u201cSo we have basically pseudo IDs that we use in all of our processing steps \u2014 that are temporary, that are deleted afterward \u2014 but for the time when the doctor looks at the patient, they are being combined on the device for him.\u201d\n\u201cWe work with servers in Europe, ensure that everything is data privacy compliant,\u201d he also tells us. \u201cOur lead customer is a publicly owned hospital chain \u2014 called critical infrastructure in Germany. We needed to ensure that, from a data privacy point of view, everything is secure. And they have given us the thumbs up.\u201d\n\u201cUltimately, we probably overachieved what needs to be done. But it\u2019s, you know, always better to be on the safe side \u2014 especially if you handle medical data.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/google-has-given-anthropic-more-funding-than-previously-known-show-new-filings/",
        "date_extracted": "2025-03-14T11:53:04.556903",
        "title": "Google has given Anthropic more funding than previously known, show new filings",
        "author": null,
        "publication_date": null,
        "content": "Anthropic, a San Francisco startup often cast as an independent player in the AI race, hasdeeper tiesto Google than previously known. Court documents recently obtained by The New York Times reveal that Google owns a 14% stake in the company and is set to pour another $750 million into it this year through a convertible debt deal. In total, Google\u2019s investment in Anthropic now exceeds $3 billion.\nDespite having no voting rights, board seats, or direct control over the company, Google\u2019s backing raises questions about how independent Anthropic really is. As AI startups increasingly rely on funding from tech giants, regulators have scrutinized whether these deals give incumbents an unfair advantage, though the Justice Department justdropped a proposalthat would have forced the sale of some of those stakes.\nGoogle, which is developing its own tech while quietly funding competitors, is clearly hedging its bets. Meanwhile, with Amazon also funneling money into Anthropic \u2014 it has agreed to invest up to$8 billionso far in the outfit \u2014 it\u2019s natural to wonder what such ties mean for Anthropic and other big AI startups. Are they still mavericks or becoming extensions of Big Tech?\nAbove: Anthropic co-founder and CEO Dario Amodei speaking at Viva Technology in Paris.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/meta-is-reportedly-testing-in-house-chips-for-ai-training/",
        "date_extracted": "2025-03-14T11:53:07.097975",
        "title": "Meta is reportedly testing in-house chips for AI training",
        "author": null,
        "publication_date": null,
        "content": "Meta is reportedly testing an in-house chip for training AI systems, a part of a strategy to reduce its reliance on hardware makers like Nvidia.\nAccording to Reuters, Meta\u2019s chip, which is designed to handle AI-specific workloads, was manufactured in partnership with Taiwan-based firm TSMC. The company is piloting a \u201csmall deployment\u201d of the chip and plans to scale up production if the test is successful.\nMeta has deployed custom AI chips before, but only to run models \u2014 not train them. As Reuters notes, several of the company\u2019s chip design efforts have been canceled or otherwise scaled back after failing to meet internal expectations.\nMeta expects to spend $65 billion on capital expenditure this year, much of which will go toward Nvidia GPUs. If the company manages to reduce even a fraction of that cost by shifting to in-house chips, it\u2019d be a big win for the social media giant.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/ibms-ceo-doesnt-think-ai-will-replace-programmers-anytime-soon/",
        "date_extracted": "2025-03-14T11:53:09.719004",
        "title": "IBM\u2019s CEO doesn\u2019t think AI will replace programmers anytime soon",
        "author": null,
        "publication_date": null,
        "content": "IBM CEO Arvind Krishna says that, despite the Trump administration\u2019sattacks on globalism, global trade isn\u2019t dead. In fact, he thinks that the U.S.\u2019s key to growth will be embracing an international exchange of goods.\n\u201cSo, I actually am a firm believer \u2014 I think it goes all the way back to the economists who studied global trade in the 1800s \u2014 and I think their perspective was, every 10% increase in global trade leads to a 1% increase in local GDP,\u201d Krishna said during an onstage interview at SXSW on Tuesday. \u201cSo, if we want to really optimize even for local [growth], you got to have global trade.\u201d\nGlobal trade goes hand in hand with allowing overseas talent to flow into the U.S., Krishna said. The administration and its allies have called for increased restrictions onstudentandH-1B work visas, which they claim put U.S. citizens at a disadvantage.\n\u201cWe want people to come here and bring their talent with them and apply that talent,\u201d Krishna said. \u201cAnd we want to develop our own talent as well, but you can\u2019t develop it as well if you\u2019re not bringing the best people from across the world for our people to learn from too. So we should be an international talent hub, and we should have policies that go along with that.\u201d\nDuring the wide-ranging interview, Krishna touched on not only geopolitics but also AI, which he thinks is a valuable technology \u2014 but no panacea.\nHe disagreed with arecent prediction from Dario Amodei, the CEO of Anthropic, that 90% of code may be written by AI in the next three to six months.\n\u201cI think the number is going to be more like 20-30% of the code could get written by AI \u2014 not 90%\u201d Krishna said. \u201cAre there some really simple use cases? Yes, but there\u2019s an equally complicated number of ones where it\u2019s going to be zero.\u201d\nKrishna said he thinks AI will ultimately make programmers more productive, boosting their and their employers\u2019 outputs rather than eliminating programming jobs, as some AI critics have predicted.\n\u201cIf you can do 30% more code with the same number of people, are you going to get more code written or less?\u201d he said. \u201cBecause history has shown that the most productive company gains market share, and then you can produce more products, which lets you get more market share.\u201d\nGranted, IBM has a vested interest in presenting AI as nonthreatening. The company sells a range of AI-powered products and services, including assistive coding tools.\nThe statements are also a bit of a reversal for Krishna, who said in 2023 that IBMplanned to pause hiringon back-office functions that the company anticipated it could replace with AI tech.\nKrishna compared the debates over AI replacing workers to early debates over calculators and Photoshop replacing mathematicians and artists. He acknowledged that there are \u201cunresolved\u201d challenges around intellectual property where it concerns AI training and outputs, but that ultimately, the tech is a positive \u2014 and augmenting \u2014 force.\n\u201cIt\u2019s a tool,\u201d Krishna said of AI. \u201cIf the quality that everybody produces becomes better using these tools, then even for the consumer, now you\u2019re consuming better-quality [products].\u201d\nThis tool will get cheaper, Krishna predicted. While he noted that reasoning models like OpenAI\u2019so1require lots of computing and thus are energy-intensive, he thinks that AI will use \u201cless than 1%\u201d of the energy it\u2019s using today thanks to emerging techniques like those demonstrated by Chinese AI startupDeepSeek.\n\u201cI think DeepSeek gave us a preview that you can live with a much smaller model,\u201d Krishna said. \u201cNow the question arises still, do you still need some really big models to start from? And I think that is what [DeepSeek] didn\u2019t talk about.\u201d\nBut while AI will commoditize, Krishna isn\u2019t convinced that it\u2019ll help humanity arrive at new knowledge, echoing arecent essayby Hugging Face co-founder Thomas Wolf. Rather, Krishna thinks quantum computing \u2014 a technology IBM is heavily invested in, not for nothing \u2014 will be the key to accelerating scientific discovery.\n\u201cAI is learning from already-produced knowledge, literature, graphics, and so on,\u201d Krishna said. \u201cIt is not trying to figure out what is going to come\u00a0\u2026 I am one who does not believe that the current generation of AI is going to get us towards what is called artificial general intelligence\u00a0\u2026 when the AI can have all knowledge be completely reliable and answer questions beyond those that were answerable by Einstein or Oppenheimer or all the Nobel Prize laureates put together.\u201d\nKrishna\u2019s assertions stand in contrast to those from OpenAI CEO Sam Altman, who has argued that \u201csuperintelligent\u201d AI is within the realm of possibility within the next few years and couldmassively accelerate innovation.",
        "tags": [],
        "images": []
    }
]