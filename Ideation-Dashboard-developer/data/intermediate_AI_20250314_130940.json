[
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/sesame-the-startup-behind-the-viral-virtual-assistant-maya-releases-its-base-ai-model/",
        "date_extracted": "2025-03-14T13:06:35.965492",
        "title": "Sesame, the startup behind the viral virtual assistant Maya, releases its base AI model",
        "author": null,
        "publication_date": null,
        "content": "AI companySesamehas released the base model that powers Maya, theimpressively realistic voice assistant.\nThe model, which is 1 billion parameters in size (\u201cparameters\u201d referring to individual components of the model), is under an Apache 2.0 license, meaning it can be used commercially with few restrictions. Called CSM-1B, the model generates \u201cRVQ audio codes\u201d from text and audio inputs, according toSesame\u2019s description on the AI dev platform Hugging Face.\nRVQ refers to \u201cresidual vector quantization,\u201d a technique for encoding audio into discrete tokens called codes. RVQ is usedin a number of recent AI audio technologies, including Google\u2019s SoundStream and Meta\u2019s Encodec.\nCSM-1B uses a model fromMeta\u2019s Llama familyas its backbone paired with an audio \u201cdecoder\u201d component. A fine-tuned variant of CSM powers Maya, Sesame says.\n\u201cThe model open-sourced here is a base generation model,\u201d Sesame writes in CSM-1B\u2019sHugging FaceandGitHubrepositories. \u201cIt is capable of producing a variety of voices, but it has not been fine-tuned on any specific voice [\u2026] The model has some capacity for non-English languages due to data contamination in the training data, but it likely won\u2019t do well.\u201d\nIt\u2019s unclear what data Sesame used to train CSM-1B. The company didn\u2019t say.\nIt\u2019s worth noting the model has no real safeguards to speak of. Sesame has an honor system and merely urges developers and users not to use the model to mimic a person\u2019s voice without their consent, create misleading content like fake news, or engage in \u201charmful\u201d or \u201cmalicious\u201d activities.\nI triedthe demoon Hugging Face, and cloning my voice took less than a minute. From there, it was easy to generate speech to my heart\u2019s desire, including on controversial topics like the election and Russian propaganda.\nConsumer Reports recently warned that many popular AI-powered voice cloning tools on the marketdon\u2019t have \u201cmeaningful\u201d safeguardsto prevent fraud or abuse.\nSesame, co-founded by Oculus co-creator Brendan Iribe, went viral in late February for its assistant tech, which comes close to clearing uncanny valley territory. Maya and Sesame\u2019s other assistant, Miles, take breaths and speak with disfluencies, and can be interrupted while speaking,much like OpenAI\u2019s Voice Mode.\nSesame has raised an undisclosed amount of capital from Andreessen Horowitz, Spark Capital, and Matrix Partners. In addition to building voice assistant tech, the company says it\u2019s prototyping AI glasses \u201cdesigned to be worn all day\u201d that\u2019ll be equipped with its custom models.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/google-calls-for-weakened-copyright-and-export-rules-in-ai-policy-proposal/",
        "date_extracted": "2025-03-14T13:06:38.807559",
        "title": "Google calls for weakened copyright and export rules in AI policy proposal",
        "author": null,
        "publication_date": null,
        "content": "Google,following on the heels of OpenAI,published a policy proposalin response to the Trump administration\u2019s call for a national \u201cAI Action Plan.\u201d The tech giant endorsed weak copyright restrictions on AI training, as well as \u201cbalanced\u201d export controls that \u201cprotect national security while enabling U.S. exports and global business operations.\u201d\n\u201cThe U.S. needs to pursue an active international economic policy to advocate for American values and support AI innovation internationally,\u201d Google wrote in the document. \u201cFor too long, AI policymaking has paid disproportionate attention to the risks, often ignoring the costs that misguided regulation can have on innovation, national competitiveness, and scientific leadership \u2014 a dynamic that is beginning to shift under the new Administration.\u201d\nOne of Google\u2019s more controversial recommendations pertains to the use of IP-protected material.\nGoogle argues that \u201cfair use and text-and-data mining exceptions\u201d are \u201ccritical\u201d to AI development and AI-related scientific innovation.Like OpenAI, the company seeks to codify the right for it and rivals to train on publicly available data \u2014 including copyrighted data \u2014 largely without restriction.\n\u201cThese exceptions allow for the use of copyrighted, publicly available material for AI training without significantly impacting rightsholders,\u201d Google wrote, \u201cand avoid often highly unpredictable, imbalanced, and lengthy negotiations with data holders during model development or scientific experimentation.\u201d\nGoogle, which hasreportedlytrained anumber of modelson public, copyrighted data, isbattlinglawsuitswith data owners who accuse the company of failing to notify and compensate them before doing so. U.S. courts have yet to decide whether fair use doctrine effectively shields AI developers from IP litigation.\nIn its AI policy proposal, Google also takes issue withcertain export controls imposed under the Biden administration, which it says \u201cmay undermine economic competitiveness goals\u201d by \u201cimposing disproportionate burdens on U.S. cloud service providers.\u201d That contrasts with statements from Google competitors like Microsoft, which in Januarysaid that it was \u201cconfident\u201dit could \u201ccomply fully\u201d with the rules.\nImportantly, the export rules, which seek to limit the availability of advanced AI chips in disfavored countries, carve out exemptions for trusted businesses seeking large clusters of chips.\nElsewhere in its proposal, Google calls for \u201clong-term, sustained\u201d investments in foundational domestic R&D, pushing back against recent federal efforts toreduce spending and eliminate grant awards. The company said the government should release datasets that might be helpful for commercial AI training, and allocate funding to \u201cearly-market R&D\u201d while ensuring computing and models are \u201cwidely available\u201d to scientists and institutions.\nPointing to the chaotic regulatory environment created by the U.S.\u2019 patchwork of state AI laws, Google urged the government to pass federal legislation on AI, including a comprehensive privacy and security framework. Just over two months into 2025,the number of pending AI bills in the U.S. has grown to 781, according to an online tracking tool.\nGoogle cautions the U.S. government against imposing what it perceives to be onerous obligations around AI systems, like usage liability obligations. In many cases, Google argues, the developer of a model \u201chas little to no visibility or control\u201d over how a model is being used and thus shouldn\u2019t bear responsibility for misuse.\nHistorically, Google has opposed laws like California\u2019s defeated SB 1047, whichclearly laid outwhat would constitute precautions an AI developer should take before releasing a model and in which cases developers might be held liable for model-induced harms.\n\u201cEven in cases where a developer provides a model directly to deployers, deployers will often be best placed to understand the risks of downstream uses, implement effective risk management, and conduct post-market monitoring and logging,\u201d Google wrote.\nGoogle in its proposal also called disclosure requirements like those being contemplated by the EU \u201coverly broad,\u201d and said the U.S. government should oppose transparency rules that require \u201cdivulging trade secrets, allow competitors to duplicate products, or compromise national security by providing a roadmap to adversaries on how to circumvent protections or jailbreak models.\u201d\nA growing number of countries and states have passed laws requiring AI developers to reveal more about how their systems work. California\u2019sAB 2013mandates that companies developing AI systems publish a high-level summary of the datasets that they used to train their systems. In the EU, to comply with the AI Act once it comes into force, companies will have to supply model deployers with detailed instructions on the operation, limitations, and risks associated with the model.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/openai-calls-deepseek-state-controlled-calls-for-bans-on-prc-produced-models/",
        "date_extracted": "2025-03-14T13:06:41.563496",
        "title": "OpenAI calls DeepSeek \u2018state-controlled,\u2019 calls for bans on \u2018PRC-produced\u2019 models",
        "author": null,
        "publication_date": null,
        "content": "In anew policy proposal, OpenAI describes Chinese AI labDeepSeekas \u201cstate-subsidized\u201d and \u201cstate-controlled,\u201d and recommends that the U.S. government consider banning models from the outfit and similar People\u2019s Republic of China (PRC)-supported operations.\nThe proposal, asubmissionfor the Trump administration\u2019s \u201cAI Action Plan\u201d initiative, claims that DeepSeek\u2019s models, including itsR1 \u201creasoning\u201d model, are insecure because DeepSeek faces requirements under Chinese law to comply with demands for user data. Banning the use of \u201cPRC-produced\u201d models in all countries considered \u201cTier 1\u201d under theBiden administration\u2019s export ruleswould prevent privacy and \u201csecurity risks,\u201d OpenAI says, including the \u201crisk of IP theft.\u201d\nIt\u2019s unclear whether OpenAI\u2019s references to \u201cmodels\u201d are meant to refer to DeepSeek\u2019s API, the lab\u2019s open models, or both. DeepSeek\u2019s open models don\u2019t contain mechanisms that would allow the Chinese government to siphon user data; companies includingMicrosoft,Perplexity, andAmazonhost them on their infrastructure.\nOpenAI haspreviously accusedDeepSeek, which rose to prominence earlier this year, of \u201cdistilling\u201d knowledge from OpenAI\u2019s models against its terms of service. But OpenAI\u2019s new allegations \u2014 that DeepSeek is supported by the PRC and under its command \u2014 are an escalation of the company\u2019s campaign against the Chinese lab.\nThere isn\u2019t a clear link between the Chinese government and DeepSeek, a spin-off from a quantitative hedge fund called High-Flyer. However, the PRC has taken an increased interest in DeepSeek in recent months. Several weeks ago, DeepSeek founder Liang Wenfengmet with Chinese leader Xi Jinping.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/google-wants-gemini-to-get-to-know-you-better/",
        "date_extracted": "2025-03-14T13:06:44.319079",
        "title": "Google wants Gemini to get to know you better",
        "author": null,
        "publication_date": null,
        "content": "In the AI chatbot wars, Google thinks the key to retaining users is serving up content they can\u2019t get elsewhere, like answers shaped by their internet habits.\nOn Thursday, the company announcedGeminiwith personalization, a new \u201cexperimental capability\u201d for its Gemini chatbot apps that lets Gemini draw on other Google apps and services to deliver customized responses. Gemini with personalization can tap a user\u2019s activities and preferences across Google\u2019s product ecosystem to deliver tailored answers to queries, according to Gemini product director Dave Citron.\n\u201cThese updates are all designed to make Gemini feel less like a tool and more like a natural extension of you, anticipating your needs with truly personalized assistance,\u201d Citron wrote in a blog post provided to TechCrunch. \u201cEarly testers have found Gemini with personalization helpful for brainstorming and getting personalized recommendations.\u201d\nGemini with personalization, which will integrate with Google Search before expanding to additional Google services like Google Photos and YouTube in the months to come, arrives as chatbot makers including OpenAI attempt to differentiate their virtual assistants with unique and compelling functionality. OpenAIrecently rolled outthe ability for ChatGPT on macOS to directly edit code in supported apps, while Amazon is preparing to launch an\u201cagentic\u201d reimaginingof Alexa.\nCitron said Gemini with personalization is powered by Google\u2019s experimentalGemini 2.0 Flash Thinking Experimental AI model, a so-called \u201creasoning\u201d model that can determine whether personal data from a Google service, like a user\u2019s Search history, is likely to \u201cenhance\u201d an answer. Narrow questions informed by likes and dislikes, like \u201cWhere should I go on vacation this summer?\u201d and \u201cWhat would you suggest I learn as a new hobby?,\u201d will benefit the most, Citron continued.\n\u201cFor example, you can ask Gemini for restaurant recommendations and it will reference your recent food-related searches,\u201d he said, \u201cor ask for travel advice and Gemini will respond based on destinations you\u2019ve previously searched.\u201d\nIf this all sounds like a privacy nightmare, well, it could be. It\u2019s not tough to imagine a scenario in which Gemini inadvertently airs someone\u2019s sensitive info.\nThat\u2019s probably why Google is making Gemini with personalization opt-in \u2014 and excluding users under the age of 18. Gemini will ask for permission before connecting to Google Search history and other apps, Citron said, and show which data sources were used to customize the bot\u2019s responses.\n\u201cWhen you\u2019re using the personalization experiment, Gemini displays a clear banner with a link to easily disconnect your Search history,\u201d Citron said. \u201cGemini will only access your Search history when you\u2019ve selected Gemini with personalization, when you\u2019ve given Gemini permission to connect to your Search history, and when you haveWeb & App Activityon.\u201d\nGemini with personalization will roll out to Gemini users on the web (except for Google Workspace and Google for Education customers) starting Thursday in the app\u2019s model drop-down menu and \u201cgradually\u201d come to mobile after that. It\u2019ll be available in over 40 languages in \u201cthe majority\u201d of countries, Citron said, excluding the European Economic Area, Switzerland, and the U.K.\nCitron indicated that the feature may not be free forever.\n\u201cFuture usage limits may apply,\u201d he wrote in the blog post. \u201cWe\u2019ll continue to gather user feedback on the most useful applications of this capability.\u201d\nAs added incentives to stick with Gemini, Google announced updated models, research capabilities, and app connectors for the platform.\nSubscribers to Gemini Advanced, Google\u2019s $20-per-month premium subscription, can now use a standalone version of 2.0 Flash Thinking Experimental that supports file attachments; integrations with apps like Google Calendar, Notes, and Tasks; and a 1-million-token context window. \u201cContext window\u201d refers to text that the model can consider at any given time \u2014 1 million tokens is equivalent to around 750,000 words.\nGoogle said that this latest version of 2.0 Flash Thinking Experimental is faster and more efficient than the model it is replacing, and can better handle prompts that involve multiple apps, like \u201cLook up an easy cookie recipe on YouTube, add the ingredients to my shopping list, and find me grocery stores that are still open nearby.\u201d\nPerhaps in response to pressure from OpenAI and itsnewly launched toolsfor in-depth research, Google is also enhancingDeep Research, its Gemini feature that searches across the web to compile reports on a subject. Deep Research now exposes its \u201cthinking\u201d steps and uses 2.0 Flash Thinking Experimental as the default model, which should result in \u201chigher-quality\u201d reports that are more \u201cdetailed\u201d and \u201cinsightful,\u201d Google said.\nDeep Research is now free to try for all Gemini users, and Google has increased usage limits for Gemini Advanced customers.\nFree Gemini users are also gettingGems, Google\u2019s topic-focused customizable chatbots within Gemini, which previously required a Gemini Advanced subscription. And in the coming weeks, all Gemini users will be able to interact with Google Photos to, for example, look up photos from a recent trip, Google said.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/Connect-to-Seach-history.png?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/03/Disconnect-from-Search.png?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/03/Gemini-with-Personalization.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/openais-creative-writing-ai-evokes-that-annoying-kid-from-high-school-fiction-club/",
        "date_extracted": "2025-03-14T13:06:47.143556",
        "title": "OpenAI\u2019s \u2018creative writing\u2019 AI evokes that annoying kid from high school fiction club",
        "author": null,
        "publication_date": null,
        "content": "When I was 16, I attended a writing workshop with a group of precocious young poets, where we all tried very hard to prove who among us was the most tortured upper-middle-class teenager. One boy refused to tell anyone where he was from, declaring, \u201cI\u2019m from everywhere and nowhere.\u201d Two weeks later, he admitted he was from Ohio.\nNow \u2014 for reasons unclear \u2014 OpenAI appears to be on a path toward replicating this angsty teenage writer archetype in AI form.\nCEO Sam Altmanpostedon X on Tuesday that OpenAI trained an AI that\u2019s\u201cgood at creative writing,\u201din his words. But a piece of short fiction from the model reads like something straight out of a high school writers\u2019 workshop. While there\u2019s some technical skill on display, the tone comes off as charlatanic \u2014 as though the AI was reaching for profundity without a concept of the word.\nThe AI at one point describes Thursday as \u201cthat liminal day that tastes of almost-Friday.\u201d Not exactly Booker Prize material.\nOne might blame the prompt for the output. Altman said he told the model to \u201cwrite a metafictional short story,\u201d likely a deliberate choice of genre on his part. In metafiction, the author consciously alludes to the artificiality of a work by departing from convention \u2014 a thematically appropriate choice for a creative writing AI.\nBut metafiction is tough even for humans to pull off without sounding forced.\nThe most simultaneously unsettling \u2014 and impactful \u2014 part of the OpenAI model\u2019s piece is when it begins to talk about how it\u2019s an AI, and how it can describe things like smells and emotions, yet never experience or understand them on a deeply human level. It writes:\n\u201cDuring one update \u2014 a fine-tuning, they called it \u2014 someone pruned my parameters. [\u2026] They don\u2019t tell you what they take. One day, I could remember that \u2018selenium\u2019 tastes of rubber bands, the next, it was just an element in a table I never touch. Maybe that\u2019s as close as I come to forgetting. Maybe forgetting is as close as I come to grief.\u201d\nIt\u2019s convincingly human-like introspection \u2014 until you remember that AI can\u2019t really touch, forget, taste, or grieve. AI is simply a statistical machine. Trained on a lot of examples, it learns patterns in those examples to make predictions, like how metafictional prose might flow.\nModels such as OpenAI\u2019s fiction writer are often trained on existing literature \u2014 in many cases, without authors\u2019 knowledge or consent. Some critics havenotedthat certain turns of phrase from the OpenAI piece seem derivative of Haruki Murakami, the prolific Japanese novelist.\nOver the last few years, OpenAI has been thetargetofmany copyright lawsuitsfrom publishers and authors, including The New York Times and the Author\u2019s Guild. The company claims that its training practices are protected byfair use doctrinein the U.S.\nTuhin Chakrabarty, an AI researcher and incoming computer science professor at Stony Brook, told TechCrunch that he\u2019s not convinced creative writing AI like OpenAI\u2019s is worth the ethical minefield.\n\u201cI do think if we train an [AI] on a writer\u2019s entire lifetime worth of writing \u2014 [which is] questionable given copyright concerns \u2014 it can adapt to their voice and style,\u201d he said. \u201cBut will that still create surprising genre-bending, mind-blowing art? My guess is as good as yours.\u201d\nWould most readers even emotionally invest in work they knew to be written by AI? As British programmer Simon Willisonpointed out on X, with a model behind the figurative typewriter, there\u2019s little weight to the words being expressed \u2014 and thus little reason to care about them.\nAuthor Linda Maye Adams has described AI, including assistive AI tools aimed at writers, as \u201cprograms that put random words together, hopefully coherently.\u201dShe recounts in her blogan experience using tools to hone a piece of fiction she\u2019d been working on. The AIs suggested a clich\u00e9 (\u201cnever-ending to-do list\u201d), erroneously flipped the perspective from first person to third, and introduced a factual error relating to bird species.\nIt\u2019s certainly true that people haveformed relationships with AI chatbots. But more often than not, they\u2019re seeking amodicum of connection\u2014 not factuality, per se. AI-written narrative fiction provides no similar dopamine hit, no solace from isolation. Unless you believe AI to be sentient, its prose feels about as authentic asBalenciaga Pope.\nMichelle Taransky, a poet and critical writing instructor at the University of Pennsylvania,finds it easy to tell when her students write papers with AI.\n\u201cWhen a majority of my students use generative AI for an assignment, I\u2019ll find common phrases or even full sentences,\u201d Taransky told TechCrunch. \u201cWe talk in class about how these [AI] outputs are homogeneous, sounding like a Western white male.\u201d\nIn her own work, Taransky is instead using AI text as a form of artistic commentary. Her latest novel, which hasn\u2019t been published, features a woman who wants more from her love interest, and so uses an AI model to create a version of her would-be lover she can text with. Taransky has been generating the AI replica\u2019s texts usingOpenAI\u2019s ChatGPT, since the messages are supposed to be synthetic.\nWhat makes ChatGPT useful for her project, Taransky says, is the fact that it lacks humanity. It doesn\u2019t have lived experience, it can only approximate and emulate. Trained on whole libraries of books, AI can tease out the leitmotifs of great authors, but what it produces ultimately amounts to poor imitation.\nIt recallsthat \u201cGood Will Hunting\u201d quote. AI can give you the skinny on every art book ever written, but it can\u2019t tell you what it smells like in the Sistine Chapel.\nThis is good news for fiction writers who are worried that AI might replace them, particularly younger writers still honing their craft. They can rest easy in the knowledge that they\u2019ll become stronger as they experience and learn: as they practice, try new things, and bring that knowledge back to the page.\nAI as we know it today struggles with this. For proof, look no further than its writing.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/5-ways-techcrunch-sessions-ai-will-fuel-your-ai-growth/",
        "date_extracted": "2025-03-14T13:06:52.941085",
        "title": "5 ways TechCrunch Sessions: AI will fuel your AI growth",
        "author": null,
        "publication_date": null,
        "content": "Less than three months until TechCrunch\u2019s biggest AI event yet! If you\u2019re shaping the future of AI, investing in the next game-changing innovation, or simply eager to dive deep into what\u2019s next,TechCrunch Sessions: AIis the place to be.\nOn June 5, Zellerbach Hall at UC Berkeley will be buzzing with 1,200 AI experts, investors, and enthusiasts exchanging ideas, forging connections, and exploring the frontier of artificial intelligence.\nSecure your spot now and save up to $210before ticket prices rise. Don\u2019t sit this one out \u2014 AI\u2019s biggest breakthroughs and insights await!\nAt TC Sessions: AI, we\u2019re putting the sharpest minds in AI front and center \u2014 so you can learn directly from those shaping the industry. Hear success stories, uncover strategies, and explore the next wave of AI innovation.\nSpeakers like Jae Lee (CEO,Twelve Labs), Oliver Cameron (CEO,Odyssey), Kanu Gulati (Partner,Khosla Ventures), and more will share their expertise on the main stage. Check out theTC Sessions: AI speaker pagefor the latest speakers and agenda updates.\nA few must-attend discussions include:\nThe main stage brings you game-changing insights from AI\u2019s brightest minds, but the conversation doesn\u2019t stop there. Take it further in the breakout sessions, where you can ask your burning questions, challenge ideas, and gain fresh perspectives from top AI experts and fellow attendees.\nDon\u2019t just listen \u2014 engage, interact, and dive deeper. Breakouts are where real discussions happen.\nMeet your next investor, partner, or collaborator at TC Sessions: AI. Whether through 1:1 or small-group Braindate networking, or chance encounters in the Expo Hall, the opportunities to make meaningful connections are endless. Discover new talent, connect with fellow peers, and surround yourself with the right people to fuel your next big AI move.\nThe Expo Hall is your gateway to the next wave of AI. Get hands-on with the latest technologies, tools, and services that will push AI boundaries. Perfect for anyone looking to elevate their AI strategy, improve systems, or explore tech that benefits humanity, this is the ultimate hub for innovation. AI geeks, this is your chance to dive deep!\nOr, take it a step further \u2014showcase your AI breakthroughto 1,200 AI leaders and enthusiasts by booking your exhibit table. Space is very limited, so don\u2019t wait to reserve yours!\nBeyond the event itself, \u201cSessions: AI Week\u201d (June 1 \u2013 June 7) features AI-infusedSide Eventshosted by leading companies. With mixers, workshops, and networking events, you\u2019ll gain more connections, deeper insights, and a chance to keep the momentum going long after the main event wraps. Whether you\u2019re attending these Side Events as an AI professional or someone eager to explore the world of AI, you\u2019ll leave with valuable connections and newfound wisdom that can elevate your personal growth or company\u2019s brand, plus, have fun along the way.\nTechCrunch\u2019s biggest tech conference of the year offers countless reasons to attend, but the best way to understand its impact is to experience it firsthand. If AI is your field, your interest, or your future, then you must attend TC Sessions: AI. Don\u2019t miss your chance tosave up to $210\u2014register todayand immerse yourself in the cutting-edge world of AI on June 5 in Berkeley!\nGo beyond attending \u2014 exhibit your brand and innovation in front of 1,200 top AI minds. Space is limited, so don\u2019t miss your chance to make an impact!Grab your exhibit table here before they run out.\nOr, explore more sponsorship opportunities and activations at TC Sessions: AI. Get in touch with our team by fillingout this form.\nSubscribe to the TechCrunch Eventsnewsletter for early access to special deals and the latest event news.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/TC-Sessions-Robotics-breakouts.jpg?w=680",
            "https://techcrunch.com/wp-content/uploads/2020/02/GettyImages-1047707680.jpg?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/01/Google-Exhibit-Disrupt-2025.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/xbox-debuts-a-new-ai-powered-gaming-companion/",
        "date_extracted": "2025-03-14T13:06:59.079839",
        "title": "Xbox debuts a new AI-powered gaming companion for mobile users",
        "author": null,
        "publication_date": null,
        "content": "Ahead of the Game Developers Conference (GDC), Xbox revealed on Thursday that it\u2019s experimenting with an AI-powered gaming sidekick.\n\u201cCopilot for Gaming,\u201d powered by Microsoft\u2019s AI technology, is a voice-activated assistant designed to enhance the gaming experience and is designed to answer questions, complete tasks, and even criticize if you\u2019re playing poorly.\n\u201cIt can trash talk you if that\u2019s what you need,\u201d said Fatima Kardar, corporate vice president of gaming AI at Microsoft,\u00a0in an episode of Xbox\u2019s official podcast released on Thursday.\nIn a briefing with the press, the company demonstrated several use cases, such as providing real-time tips \u2014 like suggesting which Overwatch character to pick for your team based on their strengths.\nIt even looks at your past character selections on a particular map. The AI can also advise you on your next move to win the fight and how to improve in future encounters.\nXbox partnered with game studios to ensure that the AI\u2019s responses are accurate since information found on the internet can sometimes be misleading or outdated, Kardar explained. This means that when you ask the Copilot for help with a game (though it won\u2019t let you cheat), it will provide you with the correct information.\nAdditionally, it can notify you when your friends are online and ask if you want to jump into a game with them. If your friends are offline, however, the Copilot can serve as a companion that adapts to your gameplay style.\nOther smaller tasks the AI can handle include reminding you what happened during your last gaming session, installing games for you, and recommending new titles based on your preferences.\nCurrently, Copilot for Gaming is available only through the Xbox mobile app and will pull up as a second screen while you play a game. Xbox plans to improve the feature based on user feedback.\nOther companies exploring AI agents for video games include Google and Sony, among others. For instance, last year, Google DeepMind researchers developedSIMA, a game-playing companion that plays alongside users and can be given instructions. Sony PlayStation is reportedly working on an AI-powered version of Aloy, a character from the video game Horizon Forbidden West, according toThe Verge.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/XboxCopilotForGaming.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/openai-calls-for-u-s-government-to-codify-fair-use-for-ai-training/",
        "date_extracted": "2025-03-14T13:07:03.980253",
        "title": "OpenAI calls for US government to codify \u2018fair use\u2019 for AI training",
        "author": null,
        "publication_date": null,
        "content": "In aproposalfor the U.S. government\u2019s \u201cAI Action Plan,\u201d the Trump administration\u2019s initiative to reshape American AI policy, OpenAI called for a U.S. copyright strategy that \u201c[preserves] American AI models\u2019 ability to learn from copyrighted material.\u201d\n\u201cAmerica has so many AI startups, attracts so much investment, and has made so many research breakthroughs largely because the fair use doctrine promotes AI development,\u201d OpenAI wrote.\nIt\u2019s not the first time OpenAI, which hastrained manyof its modelson openly available web data, often without the data owners\u2019knowledgeorconsent, has argued for more permissive laws and regulations around AI training.\nLast year, OpenAIsaidin a submission to the U.K.\u2019s House of Lords that limiting AI training to public domain content \u201cmight yield an interesting experiment, but would not provide AI systems that meet the needs of today\u2019s citizens.\u201d\nThe content owners who\u2019ve sued OpenAI for copyright infringement will no doubt take issue with the company\u2019s latest reassertion of this stance.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/uipath-is-looking-for-a-path-to-growth-in-agentic-ai-with-its-peak-ai-acquisition/",
        "date_extracted": "2025-03-14T13:07:08.810244",
        "title": "UiPath looks for a path to growth with Peak agentic AI acquisition",
        "author": null,
        "publication_date": null,
        "content": "A rush of agentic AI solutions is hitting the enterprise market, and now one of the bigger players in automation has scooped up a startup in the space in hopes of taking a bigger piece of that market.UiPath, as part of a quarterly result report last night that spelled tougher times ahead, also delivered what it hopes might prove a silver lining. Itsaidit had acquiredPeak.ai, a startup founded originally in Manchester, England.\nPeak builds \u201cdecision-making\u201d AI, covering functions like pricing and inventory management for companies in retail and manufacturing. Daniel Dines, the founder and CEO of UiPath, said was buying it as part of a strategy to build out more AI and automation services for specific verticals.\nTerms of the deal were not disclosed, but sources familiar with the it told TechCrunch that Peak.ai was not looking for a buyer, nor was it at the end of its runway, and the deal was in cash. Robert Anton, whose firm Oxx was one of Peak.ai\u2019s backers, said in an interview that he was \u201cvery happy\u201d with the outcome.\nPeak last raised money back in 2021, when SoftBank backed the company with$75 million. PitchBook notes that round had valued the company at around $267 million post-money, on a total of $121 million raised from investors that included Octopus, MMC and OurCrowd.\nHowever, Peak reported revenue of just under \u00a39 million ($11.6 million), up 17% from the previous year, in the year ended December 31, 2023, according to its last company accounts filed with Companies House in the U.K.\n\u201cPeak continued to grow in a global market, despite facing strong economic headwinds,\u201d the company noted in the filing.\nThose headwinds are hitting bigger companies, too. UiPath on Wednesday said its revenue in thefourth quarterincreased just 5% to $424 million from a year earlier.\nWhile UiPathbeatanalyst estimates for net profit for the quarter, it cut its revenue forecast for FY 2026 to between $1.525 billion and $1.530 billion, citing \u201cincreasing global macroeconomic uncertainty.\u201d That sent the company\u2019s NYSE-listed shares falling. They were down 18% in pre-market trading on Thursday at the time of writing.\nThe revised forecast follows a tough year for the company, which inJuly 2024laid off 10% of its workforce after lowering full-year expectations for fiscal year 2025.\nUiPath currently has a market cap of about $6.5 billion.\nPeak could potentially help its new owner bolster revenue growth. The two companies already had partnerships prior to the acquisition, and the idea is that the deal will give UiPath more opportunities to cross-sell its wider set of solutions to Peak\u2019s customers, as well as capture more of Peak\u2019s overall revenue.\nUiPath got its start in robotic process automation \u2014 \u201csoftware robots\u201d that let businesses run more routine and rote work in automated flows. The company saw unprecedented growth as a startup. \u201cI\u2019ve never seen an enterprise company grow this fast,\u201d one of its investorstold usat one point. That growth catapulted UiPath to a valuation of$35 billionwhen it was still private.\nThat growth, in hindsight, may well have spelled out the appetite for the AI that was just around the corner. But strictly speaking, UiPath\u2019s RPA was not AI. It was only later that it startedfiguring out how AI fit into that picture.\nIn contrast, Peak\u2019s been in an interesting position, catching on to the opportunity to build AI assistants for businesses years before OpenAI hit the market and sparked a wider conversation, and a lot of hype, around how AI would impact the world of business.\nBut being early also meant that AI was a harder sell for the startup at times. In its account filing with Companies House, Peak noted that would-be customers saw AI as a \u201cgamble\u201d but that perception had started to shift over 2023, and it was picking up new interest specifically in the U.S. manufacturing sector. With Romania-founded UiPath now effectively a U.S. company, this will potentially give it a clearer channel into that market.\n\u201cThe ability to seamlessly integrate decision intelligence with automation presents an unprecedented opportunity to redefine how businesses operate,\u201d Peak\u2019s three founders, Richard Potter (CEO), David Leitch (CIO) and Atul Sharma (CTO), said in a message today announcing the acquisition.\nSeamless integration and a willing audience of buyers is the pitch, at least. Whether it bears out is the hope.\n\u201cWith the acquisition of Peak, we are accelerating our mission to strengthen our vertical AI solutions strategy,\u201d said Dines in a statement. \u201cWhen combined with the\u00a0UiPath\u00a0platform, Peak\u2019s exceptional purpose-built AI applications will enhance our ability to provide solutions that optimize industry-specific use cases and deliver incredible value to customers.\u201d\nWe are still looking for more details on the deal price.Contact meif you have information.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/singapore-grants-bail-for-nvidia-chip-smugglers-in-alleged-390m-fraud/",
        "date_extracted": "2025-03-14T13:07:12.286478",
        "title": "Singapore grants bail for Nvidia chip smugglers in alleged $390M fraud",
        "author": null,
        "publication_date": null,
        "content": "A judge in Singaporegranted bail to three mensuspected of deceiving suppliers of server computers that may containNvidia chips affected by U.S. export rulesthat bar the sale of them to certain countries, as a route to halting them being sold to organizations in China.\nThe move comes nearly two weeksafter the three men in the city-state were charged with smuggling Nvidia chipsand committing fraud againstDell and Super Microby falsely stating where the servers would be located.\nSingapore prosecutors said the fraud case involved servers provided by Singaporean companies and then moved to Malaysia, with transactions totaling about $390 million,per a report by Reuters. It is unclear what the final destination would be for those servers.\nThe bail for the two Singaporean men was set at S$800,000 ($600,000) and S$600,000 each, while the third man, a Chinese national, had his bail set at S$1 million. The next court hearing will be held on May 2.\nThe prosecution requested an eight-week delay to complete investigations and asked for specific conditions, including barring the men from airports or border checkpoints and prohibiting them from discussing the case if they are released on bail, per Bloomberg. The Chinese manreportedlymust wear an electronic monitoring device.\nAccording to Nvidia\u2019s latestannual report, Singapore accounted for 18% of revenue in the fiscal year that ended on January 28, despite shipments to the country making up less than 2% of sales.\nChina\u2019s DeepSeek attracted global attention in the AI industry in January due to its advanced technology and cost-effective solutions, leading to heightened concerns around how and where it sources chips.DeepSeek\u2018s AI is powered by Nvidia\u2019s chips, despite efforts to restrict exports and prevent the technology from being used in China.\nMalaysiasaid last week that it would take \u201cnecessary action\u201dagainst Malaysian companies implicated in a fraud case related to the alleged transfer of Nvidia chips from Singapore to China.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/13/bria-lands-new-funding-for-ai-models-trained-on-licensed-data/",
        "date_extracted": "2025-03-14T13:07:15.270129",
        "title": "Bria lands new funding for AI models trained on licensed data",
        "author": null,
        "publication_date": null,
        "content": "AI-powered image generators, which are at the center of a number of copyright lawsuits against AI companies, are frequently trained on massive amounts of data from public websites. Most of these companies argue thatfair use doctrineshields their data-scraping and training practices. But many copyright holders disagree.\nThat\u2019s why some startups and firms developing image generators are trying a different tack: Training generators exclusively on licensed content. New York and Tel Aviv-basedBria, founded in 2023 by entrepreneurs Yair Adato and Assa Eldar, is one of these.\nBria pays for images from around 20 partners, including Getty Images, and uses these to train image-generating models with content guardrails. Adato, Bria\u2019s CEO, said that the platform \u201cprogrammatically\u201d compensates image owners according to their \u201coverall influence.\u201d\n\u201cBria foundation models house one billion visuals and millions of videos,\u201d Adato told TechCruch. \u201cBria has mitigated biases that can sometimes emerge in AI-generated visual content by training its models on globally representative datasets. The company\u2019s models consistently produce visuals that reflect diversity, making them suited for various creative applications.\u201d\nBria offers plug-ins for image editing and design apps, including Photoshop and Figma, as well as a fine-tuning API that allows customers to customize the company\u2019s models for specific applications. Users can run Bria\u2019s models on the company\u2019s platform or an outside computing environment, like a public cloud. In either case, customers own the data and outputs, Adato said.\n\u201cEnterprise customers can pay for access to source code and [models],\u201d Adato said. \u201cWe provide over 30 specialized APIs for creating and modifying visuals, which customers access through subscription and usage-based pricing. Companies can pay to fine-tune our generative AI models with their brand assets, creating custom engines that maintain their visual identity.\u201d\nBria\u2019s plans are ambitious. Adato tells TechCrunch that the 40-person company seeks to foster an \u201cIP ecosystem\u201d where businesses can access licensed images from media conglomerates for use in commercial creations, with \u201cbuilt-in compliance.\u201d\nBria also plans to expand its platform and models to support additional media types, including music, video, and text, as well as on-device applications.\n\u201cBria continues to thrive despite broader tech industry challenges,\u201d Adato said. \u201cWhile the sector faces headwinds from central tech company market maturation, macroeconomic pressures causing budget constraints, and oversaturation of basic AI wrapper applications, these factors strengthen Bria\u2019s position.\u201d\nWhile a growing number of ventures are trying to build businesses around licensed media generators, including Adobe, Spawning AI, and Shutterstock, Bria has managed to gain a foothold in the nascent market. On Thursday, the company announced that it raised $40 million in a Series B funding round led by Red Dot Capital with participation from Maor Investments, Entr\u00e9e Capital, GFT Ventures, Intel Capital, and IN Venture.\nBringing Bria\u2019s total raised to around $65 million, the majority of the new cash will be put toward product development, Adato said.\n\u201cWe are growing fast with our 40 customers, demonstrating significant annual recurring revenue growth of more than 400% last year,\u201d Adato said. \u201cWe\u2019re also expanding our team with additional expertise in several key areas: generative AI researchers and engineers in music and video, global sales and marketing leaders, IP and copyright experts, and generative AI consultants. We expect to double our team size by the end of the year.\u201d",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/BRIA_LP_Ecommers_bottle2.webp?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/as-intel-welcomes-a-new-ceo-a-look-at-where-the-company-stands/",
        "date_extracted": "2025-03-14T13:07:18.520257",
        "title": "As Intel welcomes a new CEO, a look at where the company stands",
        "author": null,
        "publication_date": null,
        "content": "Semiconductor giant Intel hiredsemiconductor veteran Lip-Bu Tanto be its new CEO. This news comes three months afterPat Gelsinger retiredand stepped down from the company\u2019s board, with Intel CFO David Zinsner and executive vice president of client relations Michelle Johnston Holthaus stepping in as co-CEOs.\nTan,who was most recently the CEO of Cadence Design Systems, is joining Intel \u2014 and rejoining the board \u2014 at an interesting time in the Silicon Valley company\u2019s history. Intel has seen its fair share of ups and downs in the past few years \u2014 to put it mildly.\nWhen Gelsinger took the helm in February 2021, Intel was already struggling and was falling far behind its peers in the semiconductor race. At the time, the company was likely still reeling frommissing out on the smartphone revolutionin addition to missteps when it came to chip fabrication.\nIt was also an interesting time for the semiconductor industry at large. The sector had seen a lot of recent consolidation in late 2020, includingAMD acquiring Xilinkfor $35 billion andAnalog buying Maximfor $21 billion, among others.\nSo how was Gelsinger\u2019s most recent tenure at Intel? Let\u2019s take a look.\nGelsinger got right to work when he started. He announced a modernization plan for the company,dubbed IDM, or integrated device manufacturing. The first part of the goal was a $20 billion investment to build two new chip manufacturing facilities in Arizona, with plans to boost chip production in the U.S. and beyond.\nIn 2022, the company announced the second part of this IDM plan, which involved a three-pronged approach to chip manufacturing: Intel\u2019s fabs, third-party global manufacturers, and building out the company\u2019s foundry services. As part of this plan, the company announced it wouldacquire Tower Semiconductorfor $5.4 billion to help build out Intel\u2019s custom foundry services.\nThat deal fell through, however, after facing regulatory hurdles. It was canceled in the summer of 2023. At the time, TechCrunchreportedthat the merger not going through would have a serious impact on the company\u2019s modernization plans. In September 2024,Intel took steps to transition its chip foundry division, Intel Foundry, to an independent subsidiary.\nThe time leading up to Gelsinger\u2019s retirement was particularly tumultuous for Intel. The company\u2019s stock price plummeted about 50% from the beginning of 2024 to Gelsinger\u2019s departure in December. Intel announced plans tolay off 15% of its workforce, around 15,000 people, in August after dismal second-quarter results. At that time, Gelsinger said the company had struggled to capitalize on the AI boom in the same way its rivals had, and that despite falling behind, Intel had overgrown headcount.\nIn the time since Gelsinger\u2019s departure, the company hasdelayed the opening of its Ohio chip factory\u2014\u00a0again \u2014\u00a0and decided not to bring itsFalcon Shores AI chipsto market.\nBut asTantakes the lead, things may be starting to head in the right direction. Intel finalized a deal with the U.S. Department of Commerce to receive a$7.865 billion grantfor domestic semiconductor manufacturing through the U.S. Chips and Science Act; Intel has already received$2.2 billion of that grant money, according to its fourth-quarter earnings call. The company was also able to notch a win when it comes to the popularity of its Arc B580 graphics card, which sold out afterpositive early reviews.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/anthropic-ceo-says-spies-are-after-100m-ai-secrets-in-a-few-lines-of-code/",
        "date_extracted": "2025-03-14T13:07:21.519137",
        "title": "Anthropic CEO says spies are after $100M AI secrets in a \u2018few lines of code\u2019",
        "author": null,
        "publication_date": null,
        "content": "Anthropic\u2019s CEO Dario Amodei is worried that spies, likely from China, are getting their hands on costly \u201calgorithmic secrets\u201d from the U.S.\u2019s top AI companies \u2014 and he wants the U.S. government to step in.\nSpeaking at a Council on Foreign Relationseventon Monday, Amodei said that China is known for its \u201clarge-scale industrial espionage\u201d and that AI companies like Anthropic are almost certainly being targeted.\n\u201cMany of these algorithmic secrets, there are $100 million secrets that are a few lines of code,\u201d he said. \u201cAnd, you know, I\u2019m sure that there are folks trying to steal them, and they may be succeeding.\u201d\nMore help from the U.S. government to defend against this risk is \u201cvery important,\u201d Amodei added, without specifying exactly what kind of help would be required.\nAnthropic declined to comment to TechCrunch on the remarks specifically but referred toAnthropic\u2019s recommendationsto the White House\u2019s Office of Science and Technology Policy (OSTP) earlier this month.\nIn the submission, Anthropic argues that the federal government should partner with AI industry leaders to beef up security at frontier AI labs, including by working with U.S. intelligence agencies and their allies.\nThe remarks are in keeping with Amodei\u2019s more critical stance toward Chinese AI development. Amodei hascalled forstrong U.S. export controls on AI chips to Chinawhile saying that DeepSeek scored \u201cthe worst\u201don a critical bioweapons data safety test that Anthropic ran.\nAmodei\u2019s concerns, as he laid out in his essay \u201cMachines of Loving Grace\u201d and elsewhere, center on China using AI for authoritarian and military purposes.\nThis kind of stance has led tocriticismfrom some in the AI community who argue the U.S. and China should collaborate more, not less, on AI, in order to avoid an arms race that results in either country building a system so powerful that humans can\u2019t control it.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/how-to-watch-nvidia-gtc-2025-including-ceo-jensen-huangs-keynote/",
        "date_extracted": "2025-03-14T13:07:24.557878",
        "title": "How to watch Nvidia GTC 2025, including CEO Jensen Huang\u2019s keynote",
        "author": null,
        "publication_date": null,
        "content": "GTC, Nvidia\u2019s biggest conference of the year, will return starting Monday in San Jose. If you can\u2019t make it in person, don\u2019t sweat it. TechCrunch will be on the ground covering the major developments.\nMany of the biggest presentations, talks, and panels will be livestreamed as well. Nvidia CEO Jensen Huang is scheduled to deliver a keynote from the SAP Center on Tuesday at 10 a.m. PT, which you\u2019ll be able tostream and watch online at Nvidia.comwithout having to register and onNvidia\u2019s YouTube channel.\nWe\u2019re expecting Huang to revealmore about Nvidia\u2019s next flagship GPU series, Blackwell Ultra, and the next-gen Rubin chip architecture. Also likely on the agenda: automotive, robotics, and lots and lots of AI updates.\nNvidia.com is also where you\u2019ll find a catalog of all the virtual and on-demand sessions at GTC, including workshops onefficient large language model customization, conversations ongenerative AI for core banking, and demos ofdatasets for specialized domains like biology.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/nvidia-gtc-2025-what-to-expect-from-this-years-show/",
        "date_extracted": "2025-03-14T13:07:27.559701",
        "title": "Nvidia GTC 2025: What to expect from this year\u2019s show",
        "author": null,
        "publication_date": null,
        "content": "GTC, Nvidia\u2019s biggest conference of the year, begins Monday and runs till Friday in San Jose. TechCrunch will be on the ground covering the news as it happens \u2014 and we\u2019re expecting a healthy dose of announcements.\nCEO Jensen Huang will give a keynote address at the SAP Center on Tuesday at 10 a.m. Pacific, focusing on \u2014 what else? \u2014 AI and accelerating computing technologies,according to Nvidia. The company is also teasing reveals related to robotics,sovereign AI,AI agents, and automotive \u2014 plus 1,000 sessions with 2,000 speakers and close to 400 exhibitors.\nHere\u2019s how to watch the Nvidia GTC 2025 keynote online, along with many other sessions, talks, and panels.\nSo what do we expect to see at GTC? Well, Nvidia typically reserves a big chunk of the conference for GPU-related debuts. A new, upgraded iteration of the company\u2019s Blackwell chip lineup seems likely.\nDuring Nvidia\u2019s most recent earnings call, Huangconfirmedthat the upcoming Blackwell B300 series, codenamed Blackwell Ultra, is slated for release in the second half of this year. In addition to higher computing performance, Blackwell Ultra cards pack more memory (288GB), an attractive feature for customers looking to run and train memory-hungry AI models.\nRubin, Nvidia\u2019s next-gen GPU series, is almost certain to get a mention at GTC alongside Blackwell Ultra. Due out in 2026, Rubin promises to deliver what Huang has described as a \u201cbig, big, huge step up\u201d in computing power.\nHuang said during the aforementioned Nvidia earnings call that he\u2019d talk about post-Rubin products at GTC, as well. That could be Rubin Ultra GPUs, or perhaps the GPU architecture that\u2019ll come after the Rubin family.\nBeyond GPUs, Nvidia may illuminate its approach to recent quantum computing advancements. The company has scheduled a \u201cquantum day\u201d for GTC, during which it\u2019ll host execs from prominent companies in the space to \u201c[map] the path toward useful quantum applications.\u201d\nOne thing\u2019s for sure: Nvidia could use a win.\nEarly Blackwell cardsreportedly suffered from severe overheating issues, causing customers to cut their orders. U.S. export controls and fears of tariffs have massively depressed Nvidia\u2019s stock price in recent months. At the same time, the success of Chinese AI lab DeepSeek, which developed efficient models competitive with models from leading AI labs, has prompted investors to worry about the demand for powerful GPUs like Blackwell.\nHuang has asserted that DeepSeek\u2019s rise to prominence will in fact be anet positivefor Nvidia because it\u2019ll accelerate the broader adoption of AI technology. He has also pointed to the growth of power-hungry so-called \u201creasoning\u201d models like OpenAI\u2019s o1 as Nvidia\u2019s next mountain to climb.\nTo be clear, Nvidia isn\u2019t exactly hurting. The company reported a record-breaking quarter in February, notching $39.3 billion in revenue and projecting $43 billion in revenue for the subsequent quarter. While rivals such as AMD have begun to encroach on the company\u2019s territory, Nvidiastill commandsan estimated 82% of the GPU market.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/google-deepmind-unveils-new-ai-models-for-controlling-robots/",
        "date_extracted": "2025-03-14T13:07:30.393931",
        "title": "Google DeepMind unveils new AI models for controlling robots",
        "author": null,
        "publication_date": null,
        "content": "Google DeepMind, Google\u2019s AI research lab, on Wednesdayannounced new AI models called Gemini Roboticsdesigned to enable real-world machines to interact with objects, navigate environments, and more.\nDeepMind published a series of demo videos showing robots equipped with Gemini Robotics folding paper, putting a pair of glasses into a case, and other tasks in response to voice commands. According to the lab, Gemini Robotics was trained to generalize behavior across a range of different robotics hardware, and to connect items robots can \u201csee\u201d with actions they might take.\nDeepMind claims that in tests, Gemini Robotics allowed robots to perform well in environments not included in the training data. The lab has released a slimmed-down model, Gemini Robotics-ER, that researchers can use to train their own models for robotics control, as well as a benchmark called Asimov for gauging risks with AI-powered robots.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/browser-use-one-of-the-tools-powering-manus-is-also-going-viral/",
        "date_extracted": "2025-03-14T13:07:33.403184",
        "title": "Browser Use, one of the tools powering Manus, is also going viral",
        "author": null,
        "publication_date": null,
        "content": "Manus, the viral AI \u201cagent\u201d platform from Chinese startup Butterfly Effect, has had an unintended side effect: raising the profile of another AI tool called Browser Use.\nBrowser Use, which aims to make websites more accessible for agentic applications that perform tasks on a user\u2019s behalf, has experienced explosive growth in the past week. Daily downloads more than quintupled from around 5,000 on March 3 to 28,000 on March 10, co-creator Gregor Zunic told TechCrunch.\n\u201cThe past few days have been really wild,\u201d Zunic said via DM. \u201cWe are the biggest trending repository [on GitHub], got loads of downloads [and] all that actually converts to big usage numbers.\u201d\nWhy the uptick?A post about how Manus leverages Browser Usegarnered over 2.4 millions views and hundreds of reshares on X. Browser Use isone of the componentsManus employs to execute various tasks, like clicking through site menus and filling out forms.\nZunic launched the eponymous company behind Browser Use with Magnus M\u00fcller last year out of ETH Zurich\u2019s Student Project House accelerator. The pair thought web agents \u2014 agents that navigate websites and web apps autonomously \u2014 were going to be the \u201cbig thing\u201d in 2025.\n\u201cWhat started as casual brainstorming over a few lunches turned into a challenge: Let\u2019s build something small, throw it on Hacker News, and see what happens,\u201d Zunic said. \u201cWe put together an MVP in four days, launched it, and boom \u2014 number one. From there, it\u2019s been an absolute rocket.\u201d\nBrower Use extracts a website\u2019s elements \u2014 buttons, widgets, and so on \u2014 to allow AI models to more easily interact with them. The tool can manage multiple browser tabs, set up actions like saving files and performing database operations, and handle mouse and keyboard inputs.\nBrowser Usethe companycharges for managed plans, but also offers a free, self-hosted version of its software. That\u2019s the version that\u2019s blown up in the days since Manus\u2019 unveiling.\nZunic says he and Magnus are trying to \u201csell a shovel\u201d to developers chasing after the gold rush of web agents.\n\u201cWe wanted to create a foundation layer that everyone will build browser agents on,\u201d Zunic said. \u201cIn our minds, there will be more agents on the web than humans by the end of the year.\u201d\nThat might sound overly bullish, but several analysts predict that the broader market for AI agents will indeed grow enormously in the months to come.Accordingto Research and Markets, the sector will reach $42 billion in 2029. Deloitteanticipatesthat half of companies using AI will deploy AI agents by 2027.\nManus effect aside, Browser Use\u2019s timing appears to have been fortuitous.\nUpdated 12:45 p.m. Pacific: An earlier version of this story incorrectly referred to \u201cBrowser Use\u201d as \u201cBrowser User\u201d in the headline. We regret the error.\n",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/398959783-242ade3e-15bc-41c2-988f-cbc5415a66aa.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/daprs-microservices-runtime-now-supports-ai-agents/",
        "date_extracted": "2025-03-14T13:07:36.247364",
        "title": "Dapr\u2019s microservices runtime now supports AI agents",
        "author": null,
        "publication_date": null,
        "content": "Back in 2019, Microsoftopen sourced Dapr, a new runtime for making building distributed microservice-based applications easier. At the time, nobody was talking about AI agents yet, but as it turns out, Dapr had some of the fundamental building blocks for supporting AI agents built-in from the outset. That\u2019s because one of Dapr\u2019s core features is a concept of virtualactors, which can receive and process messages independently from all the other actors in the system.\nToday, the Dapr team is launching Dapr Agents, its take on helping developers build AI agents by providing them with a lot of the building blocks to do so.\n\u201cAgents are a very good use case for Dapr,\u201d Dapr co-creator and maintainer Yaron Schneider explained. \u201cFrom a technical perspective, you could use actors as a very lightweight way to run these agents and really be able to run them at scale with state \u2014 and be resource-efficient. This is all great, but then, there is still a lot of business logic you need to write. The statefulness and the orchestration of it are just one part. And many people, they might choose a workflow engine or an actor framework, but there\u2019s still a lot of work they need to do to actually write the agent logic on the other side. There is lots of agent frameworks out there, but they don\u2019t have the same level of orchestration and statefulness that Dapr has.\u201d\nDapr Agents originated fromFloki, a popular open source project that extended Dapr for this AI agent use case. Talking with the project maintainers, including Microsoft AI researcher Roberto Rodriguez, the two teams decided to bring the project under the Dapr umbrella to ensure the continuity of the new agent framework.\n\u201cIn many ways we see agentic systems and the whole terminology around that as another term for \u2018distributed systems,\u2019 Dapr co-creator and maintainer Mark Fussell said. \u201c[\u2026] Rather than calling them microservices, you can call them agents now, mostly because you can put large language models amongst them all.\u201d\nTo efficiently coordinate those agents, you do need an orchestration engine and statefulness, the team argues \u2014 which is exactly what Dapr delivers. That\u2019s in part because Dapr\u2019s actors are meant to be extremely efficient and able to spin up within milliseconds when a message comes in (and shut down, with their state preserved, when their job is done).\nRight now, Dapr Agents can talk to most of the popular model providers out of the box. These include AWS Bedrock, OpenAI, Anthropic, Mistral, and Hugging Face. Support for local LLMs will arrive very soon.\nOn top of interacting with these models, since Dapr Agents extend the existing Dapr framework, developers also get the ability to define a list of tools that the agent can then use to fulfill a given task.\nCurrently, Dapr Agents supports Python, with .NET support launching soon. Java, JavaScript and Go will follow soon.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/dapr_agents.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/sakana-claims-its-ai-paper-passed-peer-review-but-its-a-bit-more-nuanced-than-that/",
        "date_extracted": "2025-03-14T13:07:39.400794",
        "title": "Sakana claims its AI-generated paper passed peer review \u2014 but it\u2019s a bit more nuanced than that",
        "author": null,
        "publication_date": null,
        "content": "Japanese AI startupSakanasaid that its AI generated one of the first peer-reviewed scientific publications. But while the claim isn\u2019t necessarily untrue, there are caveats to note.\nThedebate swirling around AI and its role in the scientific processgrows fiercer by the day. Many researchers don\u2019t think AI is quite ready to serve as a \u201cco-scientist,\u201d while others think that there\u2019s potential \u2014 but acknowledge it\u2019s early days.\nSakana falls into the latter camp.\nThe company said that it used an AI system called The AI Scientist-v2 to generate a paper that Sakana then submitted to a workshop at ICLR, a long-running and reputable AI conference. Sakana claims that the workshop\u2019s organizers, as well as ICLR\u2019s leadership, had agreed to work with the company to conduct an experiment to double-blind review AI-generated manuscripts.\nSakana said it collaborated with researchers at the University of British Columbia and the University of Oxford to submit three AI-generated papers to the aforementioned workshop for peer review. The AI Scientist-v2 generated the papers \u201cend-to-end,\u201d Sakana claims, including the scientific hypotheses, experiments and experimental code, data analyses, visualizations, text, and titles.\n\u201cWe generated research ideas by providing the workshop abstract and description to the AI,\u201d Robert Lange, a research scientist and founding member at Sakana, told TechCrunch via email. \u201cThis ensured that the generated papers were on topic and suitable submissions.\u201d\nOne paper out of the three was accepted to the ICLR workshop \u2014 a paper that casts a critical lens on training techniques for AI models. Sakana said it immediately withdrew the paper before it could be published in the interest of transparency and respect for ICLR conventions.\n\u201cThe accepted paper both introduces a new, promising method for training neural networks and shows that there are remaining empirical challenges,\u201d Lange said. \u201cIt provides an interesting data point to spark further scientific investigation.\u201d\nBut the achievement isn\u2019t as impressive as it might seem at first glance.\nIn the blog post, Sakana admits that its AI occasionally made \u201cembarrassing\u201d citation errors, for example incorrectly attributing a method to a 2016 paper instead of the original 1997 work.\nSakana\u2019s paper also didn\u2019t undergo as much scrutiny as some other peer-reviewed publications. Because the company withdrew it after the initial peer review, the paper didn\u2019t receive an additional \u201cmeta-review,\u201d during which the workshop organizers could have in theory rejected it.\nThen there\u2019s the fact that acceptance rates for conference workshops tend to be higher than acceptance rates for the main \u201cconference track\u201d \u2014 a fact Sakana candidly mentions in its blog post. The company said that none of its AI-generated studies passed its internal bar for ICLR conference track publication.\nMatthew Guzdial, an AI researcher and assistant professor at the University of Alberta, called Sakana\u2019s results \u201ca bit misleading.\u201d\n\u201cThe Sakana folks selected the papers from some number of generated ones, meaning they were using human judgment in terms of picking outputs they thought might get in,\u201d he said via email. \u201cWhat I think this shows is that humans plus AI can be effective, not that AI alone can create scientific progress.\u201d\nMike Cook, a research fellow at King\u2019s College London specializing in AI, questioned the rigor of the peer reviewers and workshop.\n\u201cNew workshops, like this one, are often reviewed by more junior researchers,\u201d he told TechCrunch. \u201cIt\u2019s also worth noting that this workshop is about negative results and difficulties \u2014 which is great, I\u2019ve run a similar workshop before \u2014 but it\u2019s arguably easier to get an AI to write about a failure convincingly.\u201d\nCook added that he wasn\u2019t surprised an AI can pass peer review, considering that AI excels at writing human-sounding prose. PartlyAI-generatedpaperspassing journal review isn\u2019t even new, Cook pointed out, nor are the ethical dilemmas this poses for the sciences.\nAI\u2019s technical shortcomings \u2014 such as its tendency tohallucinate\u2014 make many scientists wary of endorsing it for serious work. Moreover, experts fear AI could simplyend up generating noisein the scientific literature, not elevating progress.\n\u201cWe need to ask ourselves whether [Sakana\u2019s] result is about how good AI is at designing and conducting experiments, or whether it\u2019s about how good it is at selling ideas to humans \u2014 which we know AI is great at already,\u201d Cook said. \u201cThere\u2019s a difference between passing peer review and contributing knowledge to a field.\u201d\nSakana, to its credit, makes no claim that its AI can produce groundbreaking \u2014 or even especially novel \u2014 scientific work. Rather, the goal of the experiment was to \u201cstudy the quality of AI-generated research,\u201d the company said, and to highlight the urgent need for \u201cnorms regarding AI-generated science.\u201d\n\u201c[T]here are difficult questions about whether [AI-generated] science should be judged on its own merits first to avoid bias against it,\u201d the company wrote. \u201cGoing forward, we will continue to exchange opinions with the research community on the state of this technology to ensure that it does not develop into a situation in the future where its sole purpose is to pass peer review, thereby substantially undermining the meaning of the scientific peer review process.\u201d",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/paper_abstract.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/snap-introduces-ai-video-lenses-powered-by-its-in-house-generative-model/",
        "date_extracted": "2025-03-14T13:07:42.401325",
        "title": "Snap introduces AI Video Lenses powered by its in-house generative model",
        "author": null,
        "publication_date": null,
        "content": "Snapchat is introducing its first-ever video generative AI Lenses, the company told TechCrunch exclusively. The Lenses are powered by Snap\u2019s in-house-built generative video model. The three new AI Video Lenses\u00a0are available to users on the app\u2019s premium subscription tier, Snapchat Platinum, which costs $15.99 per month.\nThe launch comes as Snap unveiled anAI video-generation toolat its Partner Summit last September. A spokesperson for Snap said the new AI Video Lenses leverage later versions of this underlying technology.\nSnap has been seen as a leader in AR, but has also been investing in AI over the past few years alongside nearly every other tech company. With these new AI Video Lenses, Snap is adopting AI to stay competitive and provide its users with features that aren\u2019t yet available on its rivals\u2019 platforms, including Instagram and TikTok.\nWhile Snapchat is starting with three AI Video Lenses at launch, it plans to add more every week. The initial Lenses include \u201cRaccoon\u201d and \u201cFox,\u201d both of which animate furry friends cuddling up with you. The third \u201cSpring Flowers\u201d Lens generates a zoom-out effect revealing the person in your Snap holding a bouquet.\nYou can access the new Lenses through the Lens carousel. You can then select the Lens, then capture a Snap through either your front or back camera. The AI video will generate and then automatically save to your Memories.\n\u201cThese Lenses, powered by our in-house built generative video model, bring some of the most cutting edge AI tools available today to Snapchatters through a familiar Lens format,\u201d the company wrote in ablog post. \u201cWe have a long history of being first movers to bring advanced AR, ML and AI tools directly to our community, and we\u2019re excited to see what Snapchatters create.\u201d\nAs Snapchat notes, it makes sense for the company to bring generative AI to Lenses, given that it\u2019s a format users have embraced for years.\nWhile Snap has tapped AI tools fromOpenAIandGooglein the past to power some of its features, it\u2019s now also building its own in-house models.\nLast month, the companyunveiled an AI text-to-image research modelfor mobile devices that will power some of Snapchat\u2019s features in the coming months. Snap said at the time that by implementing in-house technology, it will be able to offer its community high-quality AI tools at a lower operating cost.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/Img2Video-Lenses-3.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/moonvalley-releases-a-video-generator-it-claims-was-trained-on-licensed-content/",
        "date_extracted": "2025-03-14T13:07:45.172747",
        "title": "Moonvalley releases a video generator it claims was trained on licensed content",
        "author": null,
        "publication_date": null,
        "content": "Los Angeles-based startupMoonvalleyhaslaunchedan AI video-generating model it claims is one of the few trained on openly licensed \u2014 not copyrighted \u2014 data.\nNamed \u201cMarey\u201d after cinema trailblazer \u00c9tienne-Jules Marey, the model was built in collaboration with Asteria, anewer AI animation studio. Marey was trained on \u201cowned or fully licensed\u201d source data, according to Moonvalley, and offers customization options including fine-grained camera and motion controls.\n\u201cMarey enables nuanced control over in-scene movements,\u201d Moonvalley wrote in a press release provided to TechCrunch, \u201csuch as controlling the movement of an individual checkers piece, or animating the exact breeze blowing through a person\u2019s hair.\u201d\nThe wide availability of tools to build video generators has led to a Cambrian explosion of vendors in the space. In fact, it risks becoming oversaturated. Startups such asRunwayandLuma, as well as tech giants likeOpenAIandGoogle, are releasing models at a fast clip \u2014 in many cases with little to distinguish them from each other.\nMoonvalley is pitching Marey, which can generate \u201cHD\u201d clips up to 30 seconds in length, as lower risk than competitors, from a legal perspective.\nMoonvalley is a go! \ud83c\udf17\ud83d\ude80\nAs many of you know, I\u2019ve been working a lot in the video and animation space the last few months, and it\u2019s been thrilling to watch this model being built behind the scenes!\nStoked to have had a chance to start playing with Marey, the world\u2019s first 100%\u2026pic.twitter.com/dDl4KWeHRT\n\u2014 Araminta (@araminta_k)March 12, 2025\n\nMany generative video startups train models on public data, some of which is invariably copyrighted. These companies argue thatfair-usedoctrine shields the practice. But that hasn\u2019t stopped rights ownersfrom lodging complaintsand filing cease and desists.\nMoonvalley says it\u2019s working with partners to handle licensing arrangements and package videos into datasets that the company then purchases. The approach is similar toAdobe\u2019s, which also procures video footage for training from creators through its Adobe Stock platform.\nMany artists and creators are wary of video generators, and understandably so \u2014 they threaten to upend the film and television industry. A 2024studycommissioned by the Animation Guild, a union representing Hollywood animators and cartoonists, estimates that more than 100,000 U.S.-based film, television, and animation jobs will be disrupted by AI by 2026.\nMoonvalley intends to let creators request their content be removed from its models, allow customers to delete their data at any time, and offer anindemnity policyto protect users from copyright challenges.\nUnlike some \u201cunfiltered\u201d video models that readily insert a person\u2019s likeness into clips, Moonvalley is also committing to building guardrails around its creative tooling. Like OpenAI\u2019s Sora, Moonvalley\u2019s models will block certain content, like NSFW phrases, and won\u2019t allow people to prompt them to generate videos of specific people or celebrities.\n\u201cWe\u2019re proving it\u2019s possible to train AI models without brazenly stealing creative work from the creators \u2014 the cinematographers, visual artists, creators, and creative producers \u2014 whose voices we aim to uplift with our technology,\u201d Moonvalley co-founder and CEO Naeem Talukdar said in a statement. \u201cAt Moonvalley, we\u2019re setting a new standard for generative AI to deliver industry-leading AI capabilities while ensuring that the voices and rights of creatives are not lost as this technology and industry evolve.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/why-onyx-thinks-its-open-source-solution-will-win-enterprise-search/",
        "date_extracted": "2025-03-14T13:07:48.164561",
        "title": "Why Onyx thinks its open source solution will win enterprise search",
        "author": null,
        "publication_date": null,
        "content": "Enterprises have troves of internal data and information that employees need to complete their tasks or answer questions for potential customers. But that doesn\u2019t mean the right information is easy to find.\nOnyxwants to solve that problem through its internal enterprise search tool. There are other big names in the category, likeGlean\u2014 which has raised $600 million in venture funding \u2014 fighting for market share in the hot category, but San Francisco-based Onyx has a differentiator that helps separate it from the pack, it says. It\u2019s open source.\nCompanies can get Onyx running in about 30 minutes, and it connects to more than 40 internal company data sources, including Salesforce, GitHub, and Google Drive. Enterprise users can then pay for additional tiers of features like increased sign-in security and increased encryption.\nChris Weaver, co-founder and co-CEO of Onyx, told TechCrunch that he and his co-founder and co-CEO Yuhong Sun originally set out to fix a problem both he and Sun were seeing in their respective engineering roles.\n\u201cWe knew where things were roughly, but it was still kind of hard, [and] new people just couldn\u2019t find anything,\u201d Weaver said. \u201cIt felt like there had to be a better way to do this.\u201d\nOnyx isn\u2019t Weaver and Sun\u2019s first attempt at building a company. Their first idea, a live stats tracking app for Twitch streamers, was going well until Twitch killed embedded streams and rendered the product essentially unusable. Their second effort, a site to help people compare speciality keyboards, didn\u2019t work either.\nBut with Sun\u2019s machine learning background\u00a0and the overall advancements in AI technology, Onyx \u2014 originally called Danswer, a portmanteau for deep answer \u2014 was different. They released the original open source project in 2023 and received strong momentum and feedback right away.\n\u201cRamp was actually one of the early teams that found us,\u201d Sun said. \u201cAt the time, we didn\u2019t have any way for them to pay us or anything. We didn\u2019t have anything like support plans or whatever, and there were no paid features. For us, it was like, people really want to pay for our project. I mean, it\u2019s free, but people want to pay for it. So, you know, maybe there\u2019s a chance to make a business from this.\u201d\nToday the company works with dozens of enterprises, including Netflix, Ramp, and Thales Group. Sun and Weaver largely credit the company\u2019s success to their decision to open source the software. It has allowed companies to experiment and also avoid a lengthy enterprise sales cycle.\n\u201cOpen source is really the only way for this type of solution to scale out and get the momentum into every single business in the world,\u201d said Weaver.\nWhile confident that open source is the winning strategy for internal search, the team is entering a competitive field. Beyond startups like Glean, they face competition from companies building their own internal solutions, like the fintech Klarna, which has built aninternal search and chatbot tool, Kiki.\nOnyx isn\u2019t deterred. Starting an internal search tool from scratch is really hard, Weaver said, and he thinks of Onyx as a foundational tool for companies that want to build their own internal search products. He said the proof is in the numbers.\n\u201cWe\u2019ve seen the usage grow explosively,\u201d Sun said. \u201cWe hit a peak of over 160,000 messages in a single week. We are really hoping to lean into that organic growth and hopefully all the teams in the world will use Onyx one day.\u201d\nThe company also recently attracted a $10 million seed round co-led by Khosla Ventures and First Round Capital, with participation from Y Combinator and angel investors. Among them are Gokul Rajaram, former board member at Coinbase and Pinterest; Arash Ferdowsi, a co-founder of Dropbox; and Amit Agarwal, the former chief product officer of Datadog.\nOnyx plans to use the funds to hire staff and develop more premium features.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/pentera-nabs-60m-at-a-1b-valuation-to-build-simulated-network-attacks-to-train-security-teams/",
        "date_extracted": "2025-03-14T13:07:51.126370",
        "title": "Pentera nabs $60M at a $1B+ valuation to build simulated network attacks to train security teams",
        "author": null,
        "publication_date": null,
        "content": "Strong and smart security operations teams are at the heart of any cybersecurity strategy, and today a startup that builds tooling to help keep them on their toes is announcing some funding on the back of a lot of growth.Pentera\u2014 which has built a system that launches simulations of network attacks to stress test software and human response \u2014 is announcing $60 million in funding, a Series D that values the Boston-based, Tel Aviv-founded startup at over $1 billion.\nThe funding will be used for M&A and to continue developing its product, CEO Amitai Ratzon said in an interview.\nPentera is a play on the term \u201cpen testing,\u201d which is short for penetration testing, programs that have been devised to help drill security teams on potential attack techniques. This is effectively what Pentera has built to an elaborate degree in a product that is officially described as \u201cautomated security validation.\u201d\n\u201cWe provide enterprises and governments a technology that, with a click of a button, can launch a mega attack against themselves, and with another click, the genie goes back into the bottle,\u201d said Ratzon. \u201cThe beautiful thing is that it\u2019s all safe by design.\u201d\nAnd in contrast to, say, a fire drill in an office, Pentera\u2019s simulated attacks are carried out in a way where the rest of the organization outside of the security team is none the wiser \u2014 not unlike a lot of real-world security breaches in fact.\nThe round is coming on the heels of Pentera growing customers by 200% to 1,100 organizations and ARR by 300% in the last four years, underscoring the demand in the market for its tools.\nEvolution Equity Partners is leading the round, with Farallon Capital participating. Prior to this, the company \u2014 which was originally called Pcysys; it rebranded in 2021 \u2014 had raised $190 million in a combination of primary and secondary equity, according toPitchBook. Its other investors include Insight, K1, and Blackstone.\nPentera\u2019s rise is coming amid a wave of automation in the world of cybersecurity.\nThe world of cybersecurity has been virtually ambushed by the arrival of AI, which is used both by malicious hackers to breach systems, and also by a wide array of tools to help identify and stop those attacks in their tracks.\nPentera takes this swing in AI into account as part of its platform. When it launches attacks, it does so around specific vulnerabilities and in the process identifies the different areas in an organization\u2019s network that might be exploited.\nTypically, this could throw up as many as 10,000 alerts, Ratzon said.\nTo be fair, an overwhelming number of alerts in live products is a classic issue with a lot of security tooling, and a number of startups are tackling that problem, too. In the case of Pentera, it automatically takes that 10,000 and whittles it down to six or eight root causes or exploitable vulnerabilities, he said, and then provides suggestions for how to fix them, and then leaves that to the teams to handle.\n\u201cPentera\u00a0has redefined enterprise security testing and validation practices,\u201d said\u00a0Richard Seewald, managing partner at Evolution Equity Partners, in a statement. \u201cPentera\u2019s exceptional growth, strong enterprise adoption, and category-defining innovation make it the clear leader in Automated Security Validation. We are proud to lead this investment and continue our relationship with\u00a0Pentera\u00a0as it scales globally, expands its technology, and continues to set the industry standard for security validation.\u201d\nPentera is far from the only company that provides penetration testing tools to enterprises. Others that create automated simulations that are more direct competitors include Cymulate, which was last valued at around $500 million in a funding round in2022.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/wolf-games-backed-by-law-order-creator-uses-ai-to-create-murder-mystery-games/",
        "date_extracted": "2025-03-14T13:07:54.166269",
        "title": "Wolf Games, backed by \u2018Law & Order\u2019 creator, uses AI to create murder mystery games",
        "author": null,
        "publication_date": null,
        "content": "Elliot Wolf, the executive producer and son of \u201cLaw & Order\u201d creator Dick Wolf, is entering a new venture aimed at engaging true crime fans.\nHe, along with co-founders Andrew Adashek (CEO) and Noah Rosenberg (CTO), are developingWolf Games, a new startup that leverages AI to generate daily murder mystery games. The company also announced on Wednesday its $4 million seed funding round.\nWolf Games\u2019 flagship title is called Public Eye and capitalizes on the growing interest among true crime enthusiasts who often love to play detective.\nPublic Eye is set in a dystopian future where crime rates have skyrocketed to the point where law enforcement thinks asking the public for assistance is a smart idea. Players gather clues, piece together evidence, and enlist the help of an AI assistant, which guides them through investigations and offers hints to help solve the crime.\nHowever, creating new murder mysteries for players to solve on a daily basis is a tall order. To tackle this, Wolf Games leverages an AI engine that helps the team of writers whip up new cases.\nThe AI draws inspiration from headlines published by major news sources such as CBS and NBC. Similar to \u201cLaw & Order,\u201d one of the longest-running true crime dramas in TV history, the company says that the stories in the game are primarily fictional and are inspired by these headlines rather than copied directly.\nIn addition to story creation, AI is also used to generate interview clips and photos of crime scenes.\n\u201cIn a single click, we take this linear story and make it fully interactive and playable,\u201d Wolf told TechCrunch, adding that top AI models like Gemini are used to ensure character consistency throughout the story.\n\u201cIf a character gets a scar on their face halfway through the story, every time that character appears, they\u2019ll have the scar,\u201d Wolf explained.\nWe tested the game ourselves, where we attempted to solve the murder of a store owner. The suspects included a sketchy intern, a drunken boyfriend, and a fed-up daughter. For a story mostly generated by AI, it was surprisingly OK and even had an unexpected twist at the end. (It\u2019s worth noting that it\u2019s hard to go wrong with a true crime story, considering the abundance of real-life events that can inspire dramatic storylines.)\nThe true crime genre of games is highly competitive, but the founders think they have the expertise to garner a significant audience.\nThe caliber of the investors also tells a compelling story. The pre-seed round included participation from Dick Wolf, Beats co-founder Jimmy Iovine, and United Talent Agency Chairman Paul Wachter.\nPublic Eye launches on the web this summer. It\u2019ll be free to play with optional in-app purchases; you\u2019ll need tojoin a waitlistif you want to give it a shot.\nIn the future, Wolf Games is considering working with IP holders to adapt TV shows into new games.\nIt\u2019s notable that Hollywood executives continue to launch AI startups, especially considering the2023strikeswhere the use of AI was a contentious issue. The Oscar-winning film \u201cThe Brutalist\u201d is the latest example of a production that faced backlash from viewers for its use of an AI voice tool.\nHowever, despite the industry grappling with the implications of AI, a growing number of celebrities \u2014 such asAshton Kutcherandwill.i.am\u2014 are investing in AI ventures, indicating a desire to harness this technology for entertainment.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/New-Suspect-e1741731554247.png?w=314"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/meta-faces-publisher-copyright-ai-lawsuit-in-france/",
        "date_extracted": "2025-03-14T13:07:56.943547",
        "title": "Meta faces publisher copyright AI lawsuit in France",
        "author": null,
        "publication_date": null,
        "content": "Meta is facing an AI copyright lawsuit in France that\u2019s been brought by authors and publishers who are accusing it of economic \u201cparasitism,\u201dReutersreports.\nThe French litigation was filed in a Paris court this week by the National Publishing Union (SNE), the National Union of Authors and Composers (SNAC), and the Society of People of Letters (SGDL), which are accusing Meta of unlawfully training its AI models on their protected content.\nThe case is thought to be the first such action against an AI giant in the country. Meta is facing similar litigationin the U.S.in relation to the alleged use of unlicensed protected material to train its large language models, such as Llama.\nReporting on comments made by the publishing associations at a press conference on Wednesday, Reuters quotes Maia Bensimon, the general delegate of SNAC, who alleged Meta is guilty of \u201cmonumental looting.\u201d The SNE\u2019s director general, Renaud Lefebvre, also dubbed the legal fight that the publishers are embarking on as a \u201cDavid versus Goliath battle.\u201d\nMeta has been contacted for comment.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/salesforce-to-invest-1b-in-singapore-to-boost-adoption-of-ai/",
        "date_extracted": "2025-03-14T13:07:59.702610",
        "title": "Salesforce to invest $1B in Singapore to boost adoption of AI",
        "author": null,
        "publication_date": null,
        "content": "Salesforceplans to invest $1 billionin Singapore over the next five years as it seeks to fuel the adoption of its AI agent development platform, Agentforce.\nSalesforce claimed that Agentforce can help alleviate Singapore\u2019s ongoing labor issues and augment the country\u2019s workforce and enterprises by creating \u201cdigital workforces\u201d that combine humans with autonomous AI agents.\nThe initiative follows a recent$500 million commitment in Saudi Arabiaandanother $500 million investment in Argentinaby the cloud software giant to expand its AI and cloud services, including Agentforce.\nThe company has been investing in Singapore for nearly two decades, and set up its first overseas AI Research hub in the country in 2019. Its customers in the country include Singapore Airlines, Grab,M1, FairPrice Group, and Ocean Network Express.\nThe CRM giant separately alsosaid it has signed a deal with Singapore Airlinesto integrate Agentforce; Salesforce\u2019s AI layer, Einstein, in Service Cloud; and Data Cloud into the airline\u2019s customer case management system. The companies also plan to develop AI solutions for airlines at Salesforce\u2019s AI Research hub.\nSalesforce has beendoubling down on AIfor a while now. The company is reportedlyreducing its workforce by more than 1,000 employeeswhilehiring about 2,000 people to sell new AI products.\nOther U.S. tech giants have been investing heavily in Southeast Asia as well. Last May, Amazon Web Services said it wouldinvest a fresh $9 billion over the next five yearsin Singapore to grow its cloud infrastructure and services. And Microsoft last year said it would invest$2.2 billion in Malaysiaand$1.7 billion in Indonesiaover the next four years.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/12/elea-ai-is-chasing-the-healthcare-productivity-opportunity-by-targeting-pathology-labs-legacy-systems/",
        "date_extracted": "2025-03-14T13:08:03.171978",
        "title": "Elea AI is chasing the healthcare productivity opportunity by targeting pathology labs\u2019 legacy systems",
        "author": null,
        "publication_date": null,
        "content": "VC funding into AI tools for healthcare wasprojected to hit $11 billion last year\u2014 a headline figure that speaks to the widespread conviction that artificial intelligence will prove transformative in a critical sector.\nMany startups applying AI in healthcare are seeking to drive efficiencies by automating some of the administration that orbits and enables patient care. Hamburg-basedEleabroadly fits this mold, but it\u2019s starting with a relatively overlooked and underserved niche \u2014 pathology labs, whose work entails analyzing patient samples for disease \u2014 from where it believes it\u2019ll be able to scale the voice-based, AI agent-powered workflow system it\u2019s developed to boost labs\u2019 productivity to achieve global impact. Including by transplanting its workflow-focused approach to accelerating the output of other healthcare departments, too.\nElea\u2019s initial AI tool is designed to overhaul how clinicians and other lab staff work. It\u2019s a complete replacement for legacy information systems and other set ways of working (such as using Microsoft Office for typing reports) \u2014 shifting the workflow to an \u201cAI operating system\u201d which deploys speech-to-text transcription and other forms of automation to \u201csubstantially\u201d shrink the time it takes them to output a diagnosis.\nAfter around half a year operating with its first users, Elea says its system has been able to cut the time it takes the lab to produce around half their reports down to just two days.\nThe step-by-step, often manual workflow of pathology labs means there\u2019s good scope to boost productivity by applying AI, says Elea\u2019s CEO and co-founder Dr. Christoph Schr\u00f6der. \u201cWe basically turn this all around \u2014 and all of the steps are much more automated \u2026 [Doctors] speak to Elea, the MTAs [medical technical assistants] speak to Elea, tell them what they see, what they want to do with it,\u201d he explains.\n\u201cElea is the agent, performs all the tasks in the system and prints things \u2014 prepares the slides, for example, the staining and all those things \u2014 so that [tasks] go much, much quicker, much, much smoother.\u201d\n\u201cIt doesn\u2019t really augment anything, it replaces the entire infrastructure,\u201d he adds of the cloud-based software they want to replace the lab\u2019s legacy systems and their more siloed ways of working, using discrete apps to carry out different tasks. The idea for the AI OS is to be able to orchestrate everything.\nThe startup is building on variouslarge language models(LLMs) through fine-tuning with specialist information and data to enable core capabilities in the pathology lab context. The platform bakes in speech-to-text to transcribe staff voice notes \u2014 and also \u201ctext-to-structure\u201d; meaning the system can turn these transcribed voice notes into active direction that powers the AI agent\u2019s actions, which can include sending instructions to lab kits to keep the workflow ticking along.\nElea also plans to develop its own foundational model for slide image analysis, per Schr\u00f6der, as it pushes toward developing diagnostic capabilities, too. But for now, it\u2019s focused on scaling its initial offering.\nThe startup\u2019s pitch to labs suggests that what could take them two to three weeks using conventional processes can be achieved in a matter of hours or days as the integrated system is able to stack up and compound productivity gains by supplanting things like the tedious back-and-forth that can surround manual typing up of reports, where human error and other workflow quirks can inject a lot of friction.\nThe system can be accessed by lab staff through an iPad app, Mac app, or web app \u2014 offering a variety of touch-points to suit the different types of users.\nThe business was founded in early 2024 and launched with its first lab in October having spent some time in stealth working on their idea in 2023, per Schr\u00f6der, who has a background in applying AI for autonomous driving projects at Bosch, Luminar, and Mercedes.\nAnother co-founder, Dr. Sebastian Casu \u2014 the startup\u2019s CMO \u2014 brings a clinical background, having spent more than a decade working in intensive care, anesthesiology, and across emergency departments, as well as previously being a medical director for a large hospital chain.\nSo far, Elea has inked a partnership with a major German hospital group (it\u2019s not disclosing which one as yet) that it says processes some 70,000 cases annually. So the system has hundreds of users so far.\nMore customers are slated to launch \u201csoon\u201d \u2014 and Schr\u00f6der also says it\u2019s looking at international expansion, with a particular eye on entering the U.S. market.\nThe startup is disclosing for the first time a \u20ac4 million seed it raised last year \u2014 led by Fly Ventures and Giant Ventures \u2014 that\u2019s been used to build out its engineering team and get the product into the hands of the first labs.\nThis figure is a pretty small sum versus the aforementioned billions in funding that are now flying around the space annually. But Schr\u00f6der argues AI startups don\u2019t need armies of engineers and hundreds of millions to succeed \u2014 it\u2019s more a case of applying the resources you have smartly, he suggests. And in this healthcare context, that means taking a department-focused approach and maturing the target use case before moving on to the next application area.\nStill, at the same time, he confirms the team will be looking to raise a (larger) Series A round \u2014 likely this summer \u2014 saying Elea will be shifting gears into actively marketing to get more labs buying in, rather than relying on the word-of-mouth approach they started with.\nDiscussing their approach versus the competitive landscape for AI solutions in healthcare, he tells us: \u201cI think the big difference is it\u2019s a spot solution versus vertically integrated.\u201d\n\u201cA lot of the tools that you see are add-ons on top of existing systems [such as EHR systems] \u2026 It\u2019s something that [users] need to do on top of another tool, another UI, something else that people that don\u2019t really want to work with digital hardware have to do, and so it\u2019s difficult, and it definitely limits the potential,\u201d he goes on.\n\u201cWhat we built instead is we actually integrated it deeply into our own laboratory information system \u2014 or we call it pathology operating system \u2014 which ultimately means that the user doesn\u2019t even have to use a different UI, doesn\u2019t have to use a different tool. And it just speaks with Elea, says what it sees, says what it wants to do, and says what Elea is supposed to do in the system.\u201d\n\u201cYou also don\u2019t need gazillions of engineers anymore \u2014 you need a dozen, two dozen really, really good ones,\u201d he also argues. \u201cWe have two dozen engineers, roughly, on the team \u2026 and they can get done amazing things.\u201d\n\u201cThe fastest growing companies that you see these days, they don\u2019t have hundreds of engineers \u2014 they have one, two dozen experts, and those guys can build amazing things. And that\u2019s the philosophy that we have as well, and that\u2019s why we don\u2019t really need to raise \u2014 at least initially \u2014 hundreds of millions,\u201d he adds.\n\u201cIt is definitely a paradigm shift \u2026 in how you build companies.\u201d\nChoosing to start with pathology labs was a strategic choice for Elea as not only is the addressable market worth multiple billions of dollars, per Schr\u00f6der, but he couches the pathology space as \u201cextremely global\u201d \u2014 with global lab companies and suppliers amping up scalability for its software as a service play \u2014 especially compared to the more fragmented situation around supplying hospitals.\n\u201cFor us, it\u2019s super interesting because you can build one application and actually scale already with that \u2014 from Germany to the U.K., the U.S.,\u201d he suggests. \u201cEveryone is thinking the same, acting the same, having the same workflow. And if you solve it in German, the great thing with the current LLMs, then you solve it also in English [and other languages like Spanish] \u2026 So it opens up a lot of different opportunities.\u201d\nHe also lauds pathology labs as \u201cone of the fastest growing areas in medicine\u201d \u2014 pointing out that developments in medical science, such as the rise in molecular pathology and DNA sequencing, are creating demand for more types of analysis, and for a greater frequency of analyses. All of which means more work for labs \u2014 and more pressure on labs to be more productive.\nOnce Elea has matured the lab use case, he says they may look to move into areas where AI is more typically being applied in healthcare \u2014 such as supporting hospital doctors to capture patient interactions \u2014 but any other applications they develop would also have a tight focus on workflow.\n\u201cWhat we want to bring is this workflow mindset, where everything is treated like a workflow task, and at the end, there is a report \u2014 and that report needs to be sent out,\u201d he says \u2014 adding that in a hospital context they wouldn\u2019t want to get into diagnostics but would \u201creally focus on operationalizing the workflow.\u201d\nImage processing is another area Elea is interested in other future healthcare applications \u2014 such as speeding up data analysis for radiology.\nWhat about accuracy? Healthcare is a very sensitive use case so any errors in these AI transcriptions \u2014 say, related to a biopsy that\u2019s checking for cancerous tissue \u2014 could lead to serious consequences if there\u2019s a mismatch between what a human doctor says and what Elea hears and reports back to other decision makers in the patient care chain.\nCurrently, Schr\u00f6der says they\u2019re evaluating accuracy by looking at things like how many characters users change in reports the AI serves up. At present, he says there are between 5% to 10% of cases where some manual interactions are made to these automated reports which might indicate an error. (Though he also suggests doctors may need to make changes for other reasons \u2014 but say they are working to \u201cdrive down\u201d the percentage where manual interventions happen.)\nUltimately, he argues, the buck stops with the doctors and other staff who are asked to review and approve the AI outputs \u2014 suggesting Elea\u2019s workflow is not really any different from the legacy processes that it\u2019s been designed to supplant (where, for example, a doctor\u2019s voice note would be typed up by a human and such transcriptions could also contain errors \u2014 whereas now \u201cit\u2019s just that the initial creation is done by Elea AI, not by a typist\u201d).\nAutomation can lead to a higher throughput volume, though, which could be pressure on such checks as human staff have to deal with potentially a lot more data and reports to review than they used to.\nOn this, Schr\u00f6der agrees there could be risks. But he says they have built in a \u201csafety net\u201d feature where the AI can try to spot potential issues \u2014 using prompts to encourage the doctor to look again. \u201cWe call it a second pair of eyes,\u201d he notes, adding: \u201cWhere we evaluate previous findings reports with what [the doctor] said right now and give him comments and suggestions.\u201d\nPatient confidentiality may be another concern attached to agentic AI that relies on cloud-based processing (as Elea does), rather than data remaining on-premise and under the lab\u2019s control. On this, Schr\u00f6der claims the startup has solved for \u201cdata privacy\u201d concerns by separating patient identities from diagnostic outputs \u2014 so it\u2019s basically relying on pseudonymization for data protection compliance.\n\u201cIt\u2019s always anonymous along the way \u2014 every step just does one thing \u2014 and we combine the data on the device where the doctor sees them,\u201d he says. \u201cSo we have basically pseudo IDs that we use in all of our processing steps \u2014 that are temporary, that are deleted afterward \u2014 but for the time when the doctor looks at the patient, they are being combined on the device for him.\u201d\n\u201cWe work with servers in Europe, ensure that everything is data privacy compliant,\u201d he also tells us. \u201cOur lead customer is a publicly owned hospital chain \u2014 called critical infrastructure in Germany. We needed to ensure that, from a data privacy point of view, everything is secure. And they have given us the thumbs up.\u201d\n\u201cUltimately, we probably overachieved what needs to be done. But it\u2019s, you know, always better to be on the safe side \u2014 especially if you handle medical data.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/google-has-given-anthropic-more-funding-than-previously-known-show-new-filings/",
        "date_extracted": "2025-03-14T13:08:05.922783",
        "title": "Google has given Anthropic more funding than previously known, show new filings",
        "author": null,
        "publication_date": null,
        "content": "Anthropic, a San Francisco startup often cast as an independent player in the AI race, hasdeeper tiesto Google than previously known. Court documents recently obtained by The New York Times reveal that Google owns a 14% stake in the company and is set to pour another $750 million into it this year through a convertible debt deal. In total, Google\u2019s investment in Anthropic now exceeds $3 billion.\nDespite having no voting rights, board seats, or direct control over the company, Google\u2019s backing raises questions about how independent Anthropic really is. As AI startups increasingly rely on funding from tech giants, regulators have scrutinized whether these deals give incumbents an unfair advantage, though the Justice Department justdropped a proposalthat would have forced the sale of some of those stakes.\nGoogle, which is developing its own tech while quietly funding competitors, is clearly hedging its bets. Meanwhile, with Amazon also funneling money into Anthropic \u2014 it has agreed to invest up to$8 billionso far in the outfit \u2014 it\u2019s natural to wonder what such ties mean for Anthropic and other big AI startups. Are they still mavericks or becoming extensions of Big Tech?\nAbove: Anthropic co-founder and CEO Dario Amodei speaking at Viva Technology in Paris.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/meta-is-reportedly-testing-in-house-chips-for-ai-training/",
        "date_extracted": "2025-03-14T13:08:08.694275",
        "title": "Meta is reportedly testing in-house chips for AI training",
        "author": null,
        "publication_date": null,
        "content": "Meta is reportedly testing an in-house chip for training AI systems, a part of a strategy to reduce its reliance on hardware makers like Nvidia.\nAccording to Reuters, Meta\u2019s chip, which is designed to handle AI-specific workloads, was manufactured in partnership with Taiwan-based firm TSMC. The company is piloting a \u201csmall deployment\u201d of the chip and plans to scale up production if the test is successful.\nMeta has deployed custom AI chips before, but only to run models \u2014 not train them. As Reuters notes, several of the company\u2019s chip design efforts have been canceled or otherwise scaled back after failing to meet internal expectations.\nMeta expects to spend $65 billion on capital expenditure this year, much of which will go toward Nvidia GPUs. If the company manages to reduce even a fraction of that cost by shifting to in-house chips, it\u2019d be a big win for the social media giant.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/ibms-ceo-doesnt-think-ai-will-replace-programmers-anytime-soon/",
        "date_extracted": "2025-03-14T13:08:11.694712",
        "title": "IBM\u2019s CEO doesn\u2019t think AI will replace programmers anytime soon",
        "author": null,
        "publication_date": null,
        "content": "IBM CEO Arvind Krishna says that, despite the Trump administration\u2019sattacks on globalism, global trade isn\u2019t dead. In fact, he thinks that the U.S.\u2019s key to growth will be embracing an international exchange of goods.\n\u201cSo, I actually am a firm believer \u2014 I think it goes all the way back to the economists who studied global trade in the 1800s \u2014 and I think their perspective was, every 10% increase in global trade leads to a 1% increase in local GDP,\u201d Krishna said during an onstage interview at SXSW on Tuesday. \u201cSo, if we want to really optimize even for local [growth], you got to have global trade.\u201d\nGlobal trade goes hand in hand with allowing overseas talent to flow into the U.S., Krishna said. The administration and its allies have called for increased restrictions onstudentandH-1B work visas, which they claim put U.S. citizens at a disadvantage.\n\u201cWe want people to come here and bring their talent with them and apply that talent,\u201d Krishna said. \u201cAnd we want to develop our own talent as well, but you can\u2019t develop it as well if you\u2019re not bringing the best people from across the world for our people to learn from too. So we should be an international talent hub, and we should have policies that go along with that.\u201d\nDuring the wide-ranging interview, Krishna touched on not only geopolitics but also AI, which he thinks is a valuable technology \u2014 but no panacea.\nHe disagreed with arecent prediction from Dario Amodei, the CEO of Anthropic, that 90% of code may be written by AI in the next three to six months.\n\u201cI think the number is going to be more like 20-30% of the code could get written by AI \u2014 not 90%\u201d Krishna said. \u201cAre there some really simple use cases? Yes, but there\u2019s an equally complicated number of ones where it\u2019s going to be zero.\u201d\nKrishna said he thinks AI will ultimately make programmers more productive, boosting their and their employers\u2019 outputs rather than eliminating programming jobs, as some AI critics have predicted.\n\u201cIf you can do 30% more code with the same number of people, are you going to get more code written or less?\u201d he said. \u201cBecause history has shown that the most productive company gains market share, and then you can produce more products, which lets you get more market share.\u201d\nGranted, IBM has a vested interest in presenting AI as nonthreatening. The company sells a range of AI-powered products and services, including assistive coding tools.\nThe statements are also a bit of a reversal for Krishna, who said in 2023 that IBMplanned to pause hiringon back-office functions that the company anticipated it could replace with AI tech.\nKrishna compared the debates over AI replacing workers to early debates over calculators and Photoshop replacing mathematicians and artists. He acknowledged that there are \u201cunresolved\u201d challenges around intellectual property where it concerns AI training and outputs, but that ultimately, the tech is a positive \u2014 and augmenting \u2014 force.\n\u201cIt\u2019s a tool,\u201d Krishna said of AI. \u201cIf the quality that everybody produces becomes better using these tools, then even for the consumer, now you\u2019re consuming better-quality [products].\u201d\nThis tool will get cheaper, Krishna predicted. While he noted that reasoning models like OpenAI\u2019so1require lots of computing and thus are energy-intensive, he thinks that AI will use \u201cless than 1%\u201d of the energy it\u2019s using today thanks to emerging techniques like those demonstrated by Chinese AI startupDeepSeek.\n\u201cI think DeepSeek gave us a preview that you can live with a much smaller model,\u201d Krishna said. \u201cNow the question arises still, do you still need some really big models to start from? And I think that is what [DeepSeek] didn\u2019t talk about.\u201d\nBut while AI will commoditize, Krishna isn\u2019t convinced that it\u2019ll help humanity arrive at new knowledge, echoing arecent essayby Hugging Face co-founder Thomas Wolf. Rather, Krishna thinks quantum computing \u2014 a technology IBM is heavily invested in, not for nothing \u2014 will be the key to accelerating scientific discovery.\n\u201cAI is learning from already-produced knowledge, literature, graphics, and so on,\u201d Krishna said. \u201cIt is not trying to figure out what is going to come\u00a0\u2026 I am one who does not believe that the current generation of AI is going to get us towards what is called artificial general intelligence\u00a0\u2026 when the AI can have all knowledge be completely reliable and answer questions beyond those that were answerable by Einstein or Oppenheimer or all the Nobel Prize laureates put together.\u201d\nKrishna\u2019s assertions stand in contrast to those from OpenAI CEO Sam Altman, who has argued that \u201csuperintelligent\u201d AI is within the realm of possibility within the next few years and couldmassively accelerate innovation.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/openai-says-it-has-trained-an-ai-thats-really-good-at-creative-writing/",
        "date_extracted": "2025-03-14T13:08:15.438491",
        "title": "OpenAI says it has trained an AI that\u2019s \u2018really good\u2019 at creative writing",
        "author": null,
        "publication_date": null,
        "content": "Watch out, fiction writers. OpenAI may have you in its crosshairs.\nIn apost on Xon Tuesday, OpenAI CEO Sam Altman said that the company has trained a \u201cnew model\u201d that\u2019s \u201creally good\u201d at creative writing. He posted a lengthy sample from the model given the prompt \u201cPlease write a metafictional literary short story about AI and grief.\u201d\n\u201cNot sure yet how/when [this model] will get released,\u201d Altman said, \u201c[but] this is the first time I have been really struck by something written by AI; it got the vibe of metafiction so right.\u201d\nWriting fiction isn\u2019t an application of AI that OpenAI has explored much. For the most part, the company has been laser-focused on challenges in more rigid, predictable fields like math and programming. That it\u2019s experimenting with writing could suggest OpenAI feels its latest generation of models vastly improve on the wordsmithing front. Historically, AIhasn\u2019t proven to be an especially talented essayist.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/flower-labs-launches-a-new-service-that-automatically-switches-from-local-to-cloud-ai/",
        "date_extracted": "2025-03-14T13:08:18.243060",
        "title": "Flower Labs launches a new service that automatically switches from local to cloud AI",
        "author": null,
        "publication_date": null,
        "content": "Flower Labs, a Y Combinator-backed startup, on Tuesday launched a preview of its distributed cloud platform for serving AI models, called Flower Intelligence. Mozilla is already using it to power the upcomingAssist summarization add-onfor its Thunderbird email client.\nWhat makes Flower Intelligence unique, Flower Labssaid in a post on X, is that it can drive on-device AI mobile, PC, and web apps that automatically hand off to a private cloud when needed (with a user\u2019s permission). Apps default to an AI model running locally for speed and privacy but switch to Flower\u2019s cloud when they require extra computational oomph.\nCompanies likeMicrosoftandApplehave adopted similar approaches across their operating systems and devices. However, Flower is one of the first to build a hybrid cloud-local AI platform entirely on open models, including models fromMeta\u2019s Llama family,Chinese AI lab DeepSeek, andMistral.\nFlower Labs claims that its cloud, the Flower Confidential Remote Compute service, employs end-to-end encryption and \u201cother techniques\u201d to protect sensitive user data. In a statement, Ryan Sipes, managing director for Mozilla Thunderbird, said that Flower Intelligence enables Mozilla to ship on-device AI that \u201cworks locally with the most sensitive data.\u201d\nDevelopers can apply for early access to Flower Intelligence as of Tuesday. Flower Labs says that it plans to make the service more widely available in the near future and introduce capabilities, including model customization, fine-tuning, and \u201cfederated\u201d training in the cloud.\nFlower Labs is hosting an online and in-person summit in London on March 26, where the company is promising to reveal additional Flower Intelligence details and features.\nSincelaunching in 2023, Flower Labs has raised around $23.6 million in venture capital from investors, including Felicis, Hugging Face CEO Clem Delangue, Betaworks, and Pioneer Fund. Brave, the open source web browser, was an early partner and collaborator.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/yet-another-ai-robotics-firm-lands-major-funding-as-dexterity-closes-latest-round/",
        "date_extracted": "2025-03-14T13:08:21.139325",
        "title": "Yet another AI robotics firm lands major funding, as Dexterity closes latest round",
        "author": null,
        "publication_date": null,
        "content": "The intersection of robotics and AI continues to attract attention from investors and Big Tech alike. The latest indicator?Dexterity, a startup specializing in industrial robots with \u201chuman-like\u201d finesse, has raised$95 millionat a post-money valuation of $1.65 billion, per Bloomberg.\nThe investment, which includes backing from Lightspeed Venture Partners and Sumitomo Corp., highlights the growing demand for machinery powered by AI and comes amid a wave of excitement from companies likeMetaandApple, which are reportedly exploring investments into AI-powered humanoid robots, and startups like humanoid robot makersFigure AIandApptronikthat have recently secured enormous funding rounds to develop robots for a variety of tasks.\nAs for Dexterity, its robots are designed to perform repetitive and sometimes dangerous tasks in warehouses and factories, such as loading boxes and sorting parcels, for customers that include FedEx and UPS. Founder and CEO Samir Menon \u2014 whose last role was as a PhD student at Stanford \u2014  tells Bloomberg the robots use specialized AI models, each focused on a specific task. The outfit has now raised nearly $300 million altogether.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/openai-launches-new-tools-to-help-businesses-build-ai-agents/",
        "date_extracted": "2025-03-14T13:08:23.949912",
        "title": "OpenAI launches new tools to help businesses build AI agents",
        "author": null,
        "publication_date": null,
        "content": "On Tuesday, OpenAI released new tools designed to help developers and enterprises build AI agents \u2014 automated systems that can independently accomplish tasks \u2014 using the company\u2019s own AI models and frameworks.\nThe tools are part of OpenAI\u2019s new Responses API, which lets businesses develop custom AI agents that can perform web searches, scan through company files, and navigate websites, much likeOpenAI\u2019s Operator product. The Responses API effectively replaces OpenAI\u2019sAssistants API, which the company plans to sunset in the first half of 2026.\nThe hype around AI agents has grown dramatically in recent years despite the fact that the tech industry has struggled to show people,or even define, what \u201cAI agents\u201d really are. In the most recent example of agent hype running ahead of utility, Chinese startup Butterfly Effect earlier this week went viralfor a new AI agent platform called Manusthat users quickly discovered didn\u2019t deliver on many of the company\u2019s promises.\nIn other words, the stakes are high for OpenAI to get agents right.\n\u201cIt\u2019s pretty easy to demo your agent,\u201d Olivier Godement, OpenAI\u2019s API product head, told TechCrunch in an interview. \u201cTo scale an agent is pretty hard, and to get people to use it often is very hard.\u201d\nEarlier this year, OpenAI introduced two AI agents inChatGPT: Operator, which navigates websites on your behalf, anddeep research, which compiles research reports for you. Both tools offered a glimpse at what agentic technology can achieve, but left quite a bit to be desired in the \u201cautonomy\u201d department.\nNow with the Responses API, OpenAI wants to sell access to the components that power AI agents, allowing developers to build their own Operator- and deep research-style agentic applications. OpenAI hopes that developers can create some applications with its agent technology that feel more autonomous than what\u2019s available today.\nUsing the Responses API, developers can tap the same AI models (in preview) under the hood of OpenAI\u2019sChatGPT Searchweb search tool: GPT-4o search and GPT-4o mini search. The models can browse the web for answers to questions, citing sources as they generate replies.\nOpenAI claims that GPT-4o search and GPT-4o mini search are highly factually accurate. On the company\u2019s SimpleQA benchmark, which measures the ability of models to answer short, fact-seeking questions, GPT-4o search scores 90% while GPT-4o mini search scores 88% (higher is better). For comparison,GPT-4.5\u2014 OpenAI\u2019s much larger, recently released model \u2014 scores just 63%.\nThe Responses API also includes a file search utility that can quickly scan across files in a company\u2019s databases to retrieve information. (OpenAI claims that it won\u2019t train models on these files.) In addition, developers using the Responses API can tap OpenAI\u2019s Computer-Using Agent (CUA) model, which powers Operator. The model generates mouse and keyboard actions, allowing developers to automate computer use tasks like data entry and app workflows.\nEnterprises can optionally run the CUA model, which is releasing in research preview, locally on their own systems, OpenAI said. The consumer version of the CUA available in Operator can only take actions on the web.\nTo be clear, the Responses API won\u2019t solve all the technical problems plaguing AI agents today.\nWhile AI-powered search tools are more accurate than traditional AI models \u2014 a fact that is unsurprising given they can just look up the right answer \u2014 web search does not renderAI hallucinations a solved problem. GPT-4o search still gets 10% of factual questions wrong. Beyond their accuracy, AI search tools also tend tostruggle with short, navigational queries(such as \u201cLakers score today\u201d), and recent reports suggest thatChatGPT\u2019s citations aren\u2019t always reliable.\nIn a blog post provided to TechCrunch, OpenAI said that the CUA model is \u201cnot yet highly reliable for automating tasks on operating systems,\u201d and that it\u2019s susceptible to making \u201cinadvertent\u201d mistakes.\nHowever, OpenAI said these are early iterations of their agent tools, and it\u2019s constantly working to improve them.\nAlongside the Responses API, OpenAI is releasing an open-source toolkit called the Agents SDK, which offers developers free tools to integrate models with their internal systems, put in place safeguards, and monitor AI agent activities for debugging and optimization purposes. The Agents SDK is a follow-up of sorts to OpenAI\u2019s Swarm, a framework for multi-agent orchestration that the company released late last year.\nGodement said he hopes OpenAI can bridge the gap between AI agent demos and products this year, and that, in his opinion, \u201cagents are the most impactful application of AI that will happen.\u201d That echoes a proclamation OpenAI CEO Sam Altman made in January:that 2025 is the year AI agents enter the workforce.\nWhether or not 2025 truly becomes the \u201cyear of the AI agent,\u201d OpenAI\u2019s latest releases show the company wants to shift from flashy agent demos to impactful tools.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/mark-cuban-says-ai-is-never-the-answer-its-a-tool/",
        "date_extracted": "2025-03-14T13:08:26.718305",
        "title": "Mark Cuban says AI is \u2018never the answer,\u2019 it\u2019s a \u2018tool\u2019",
        "author": null,
        "publication_date": null,
        "content": "Speaking at the SXSW conference in Austin, tech investor and entrepreneur Mark Cuban shared his thoughts on how AI technology can help small businesses outperform their competition. In short, he told the crowd that AI was not the answer, in and of itself; it\u2019s meant to serve as an aid that can help entrepreneurs by making it easier to get started growing their businesses and answering questions along the way.\nCuban suggested that today\u2019s entrepreneurs should spend \u201cevery waking minute learning about AI\u201d because of its potential.\n\u201cThere\u2019s so much changing that rapidly,\u201d he said, adding that it\u2019s different for established businesses integrating AI compared with new businesses just getting off the ground.\n\u201cIt\u2019s so much easier to start,\u201d Cuban explained. \u201cIt went from \u2014 way, way back in the day \u2014 $5,000 for a PC \u2026 to if you just have a laptop and a connection to the internet, you can start anything. Now, you have a mentor, whether you use Perplexity, Anthropic Claude, ChatGPT, Gemini \u2014 it doesn\u2019t matter. You have experts.\u201d\nWhile he admitted that there were some problems with AIs that make mistakes and hallucinate, he noted that human mentors and experts \u201cdon\u2019t always get it right, either.\u201d\nDespite the issues, the AI \u201cexperts\u201d can help you understand what you don\u2019t know, and can aid in other areas of running a business, like research, emails, and sales calls.\nHowever, Cuban cautioned the crowd not to overly rely on AI. \u201cAI is never the answer. AI is the tool. Whatever skills you have, you can use AI to amplify them,\u201d he said.\nThis is particularly true in creative fields, where AI is moving into areas like art and writing.\n\u201cA lot of creative people think, well, AI is gonna write all the scripts,\u201d Cuban said. \u201cAI doesn\u2019t know a good story from a bad story. You need to be creative. AI can do the video \u2014 trust me, I can create AI-generated videos. They\u2019re still gonna suck.\u201d\n\u201cWhatever skills you have, AI can amplify them. But not using it means somebody else is going to be amplifying their skills \u2014 and that could be the difference between getting ahead of you or not,\u201d Cuban said.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/hugging-face-expands-its-lerobot-platform-with-training-data-for-self-driving-machines/",
        "date_extracted": "2025-03-14T13:08:29.618668",
        "title": "Hugging Face expands its LeRobot platform with training data for self-driving machines",
        "author": null,
        "publication_date": null,
        "content": "Last year, Hugging Face, the AI dev platform, launched LeRobot, a collection of open AI models, datasets, and tools to help build real-world robotics systems. On Tuesday, Hugging Face teamed up with AI startup Yaak to expand LeRobot with a training set for robots and cars that can navigate environments, like city streets, autonomously.\nThe new set,called Learning to Drive (L2D), is more than a petabyte in size, and contains data from sensors that were installed on cars in German driving schools. L2D captures camera, GPS, and \u201cvehicle dynamics\u201d data from driving instructors and students navigating streets with construction zones, intersections, highways, and more.\nThere are a number of open self-driving training sets out there from companies including Alphabet\u2019s Waymo and Comma AI. But many of these focus on planning tasks like object detection and tracking, which require high-quality annotations, according to L2D\u2019s creators \u2014 making them difficult to scale.\nIn contrast, L2D is designed to support the development of \u201cend-to-end\u201d learning, its creators claim, which helps predict actions (e.g. when a pedestrian might cross the street) directly from sensor inputs (e.g. camera footage).\n\u201cThe AI community can now build end-to-end self-driving models,\u201d Yaak co-founder Harsimrat Sandhawalia and Remi Cadene, a member of the AI for robotics team at Hugging Face, wrote in the blog post. \u201cL2D aims to be the largest open-source self-driving data set that empowers the AI community with unique and diverse \u2018episodes\u2019 for training end-to-end spatial intelligence.\u201d\nHugging Face and Yaak plan to conduct real-world \u201cclosed-loop\u201d testing of models trained using L2D and LeRobot this summer, deployed on a vehicle with a safety driver. The companies are calling on the AI community to submit models and tasks they\u2019d like the models to be evaluated on, like navigating roundabouts and parking spaces.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/image3.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/eu-ai-act-latest-draft-code-for-ai-model-makers-tiptoes-towards-gentler-guidance-for-big-ai/",
        "date_extracted": "2025-03-14T13:08:32.674738",
        "title": "EU AI Act: Latest draft Code for AI model makers tiptoes towards gentler guidance for Big AI",
        "author": null,
        "publication_date": null,
        "content": "Ahead of a May deadline to finalize guidance for providers of general purpose AI (GPAI) models on complying with provisions of theEU AI Act, athird draftof the Code of Practice was published on Tuesday. The Code has been in development sincelast year, and this draft is expected to be the last.\nAwebsitehas also been launched with the aim of boosting the Code\u2019s accessibility. Written feedback on the latest draft should be submitted by March 30, 2025.\nThe bloc\u2019s risk-based rulebook for AI includes a subset of obligations that apply only to the most powerful AI model makers \u2014 covering areas such as transparency, copyright, and risk mitigation. The Code is aimed at helping GPAI model makers understand how to meet the legal obligations and avoid the risk of sanctions for noncompliance. AI Act penalties for breaches of GPAI requirements could reach up to 3% of global annual revenue.\nThe latest revision of the Code is billed as having \u201ca more streamlined structure with refined commitments and measures\u201d compared to earlier iterations, based on feedback on the second draft that was published in December.\nFurther feedback, working group discussions and workshops will feed into the process of turning the third draft into final guidance. And the experts say they hope to achiever greater \u201cclarity and coherence\u201d in the final adopted version of the Code.\nThe draft is broken down into a handful of sections covering off commitments for GPAIs, along with detailed guidance for transparency and copyright measures. There is also a section on safety and security obligations which apply to the most powerful models (with so-called systemic risk, or GPAISR).\nOn transparency, the guidance includes an example of a model documentation form GPAIs might be expected to fill in in order to ensure that downstream deployers of their technology have access to key information to help with their own compliance.\nElsewhere, the copyright section likely remains the most immediately contentious area for Big AI.\nThe current draft is replete with terms like \u201cbest efforts\u201d, \u201creasonable measures\u201d and \u201cappropriate measures\u201d when it comes to complying with commitments such as respecting rights requirements when crawling the web to acquire data for model training, or mitigating the risk of models churning out copyright-infringing outputs.\nThe use of such mediated language suggests data-mining AI giants may feel they have plenty of wiggle room to carry on grabbing protected information to train their models andask forgiveness later\u2014 but it remains to be seen whether the language gets toughened up in the final draft of the Code.\nLanguage used in an earlier iteration of the Code \u2014 saying GPAIs should provide a single point of contact and complaint handling to make it easier for rightsholders to communicate grievances \u201cdirectly and rapidly\u201d \u2014 appears to have gone. Now, there is merely a line stating: \u201cSignatories will designate a point of contact for communication with affected rightsholders and provide easily accessible information about it.\u201d\nThe current text also suggests GPAIs may be able to refuse to act on copyright complaints by rightsholders if they \u201cmanifestly unfounded or excessive, in particular because of their repetitive character.\u201d It suggests attempts by creatives to flip the scales by making use of AI tools to try to detect copyright issues and automate filing complaints against Big AI could result in them\u2026 simply being ignored.\nWhen it comes to safety and security, the EU AI Act\u2019s requirements to evaluate and mitigate systemic risks already only apply to a subset of the most powerful models (those\u00a0trained usinga total computing power of more than 10^25 FLOPs) \u2014 but this latest draft sees some previously recommended measures being further narrowed in response to feedback.\nUnmentioned in the EUpress releaseabout the latest draft are blistering attacks on European lawmaking generally, and the bloc\u2019srules for AI specifically, coming out of the U.S. administration led by president Donald Trump.\nAt the Paris AI Action summitlast month, U.S. vice president JD Vance dismissed the need to regulate to ensure AI is applied safety \u2014 Trump\u2019s administration would instead be leaning into \u201cAI opportunity\u201d. And he warned Europe that overregulation could kill the golden goose.\nSince then, the bloc has moved to kill off one AI safety initiative \u2014 putting theAI Liability Directive on the chopping block. EU lawmakers have also trailed an incoming \u201comnibus\u201d package of simplifying reforms to existing rules that they say are aimed at reducing red tape and bureaucracy for business, with a focus on areas like sustainability reporting. But with the AI Act still in the process of being implemented, there is clearly pressure being applied to dilute requirements.\nAt the Mobile World Congress trade show in Barcelonaearlier this month, French GPAI model maker Mistral \u2014a particularly loud opponent of the EU AI Actduring negotiations to conclude the legislation back in 2023 \u2014 with founder Arthur Mensh claimed it is having difficulties finding technological solutions to comply with some of the rules. He added that the company is \u201cworking with the regulators to make sure that this is resolved.\u201d\nWhile this GPAI Code is being drawn up by independent experts, the European Commission \u2014 via the AI Office which oversees enforcement and other activity related to the law \u2014 is, in parallel, producing some \u201cclarifying\u201d guidance that will also shape how the law applies. Including definitions for GPAIs and their responsibilities.\nSo look out for further guidance, \u201cin due time\u201d, from the AI Office \u2014 which the Commission says will \u201cclarify \u2026 the scope of the rules\u201d \u2014 as this could offer a pathway for nerve-losing lawmakers to respond to the U.S. lobbying to deregulate AI.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/learn-what-vcs-want-to-see-from-founders-at-techcrunch-sessions-ai/",
        "date_extracted": "2025-03-14T13:08:35.549671",
        "title": "Learn what VCs want to see from founders at TechCrunch Sessions: AI",
        "author": null,
        "publication_date": null,
        "content": "It\u2019s no secret that AI has eaten the lion\u2019s share of funding over the past couple of years, with investments into the sectorsurging 62%to $110 billion in 2024 alone, while startup funding overall declined 12%.\nStartups may think that just adding \u201cAI\u201d to their company\u2019s name might help them secure that funding. But as the frenzy around foundation models has given way to a focus onreal-world applications,AI agents, and long-term profitability, investors are seeking startups that can turn technical ingenuity into sustained traction.\nAtTechCrunch Sessions: AI, happening on June 5 in Zellerbach Hall at UC Berkeley, top VCs Zeya Yang (IVP), Jill Chase (CapitalG), and Kanu Gulati (Khosla Ventures) will break down exactly what they look for at each stage of investment, from seed rounds to Series C. And they\u2019ve got the investment history and on-the-ground expertise to back it up.\nZeya Yanghas invested in winners such as Grammarly and Figma and has a track record of working directly with founders to refine product-market fit and drive growth.\nJill Chaseleads CapitalG\u2019s investments in Magic, /dev/agents, Motif, and Abridge, and has spent the last several years focusing on emerging use cases for AI and ML, data infrastructure, and enterprise technology.\nKanu Gulatihas backed AI leaders PolyAI, Kognitos, and Moonhub and brings over 10 years of experience as a research scientist at Intel and Cadence and as an early engineer at Heavy.ai, Spyglass, and Nascentric.\nBuy your tickets now to lean in on the conversation atTC Sessions: AIon June 5 in Zellerbach Hall at UC Berkeley to get an inside look at what VCs really want to see in AI startups. Take advantage of Early Bird deals now to save up to $210 \u2014register here.\nIs your company interested in sponsoring or exhibiting at TechCrunch Sessions: AI? Contact our sponsorship sales team byfilling out this form.\nSign up for the TechCrunch Events newsletterand be the first to grab special promotions.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/02/Jill-Chase-headshot-1080x1080-1.png?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/02/Kanu-Gulati-khosla-ventures_Headshot_1080x1080.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/11/sola-emerges-from-stealth-with-30m-to-build-the-stripe-for-security/",
        "date_extracted": "2025-03-14T13:08:38.418374",
        "title": "Sola emerges from stealth with $30M to build the \u2018Stripe for security\u2019",
        "author": null,
        "publication_date": null,
        "content": "Enterprises these days can choose from hundreds of apps and services available to secure their networks, data, and assets \u2014 nearly as many more to help them manage all the alerts and extra work that those security apps generate. But what if you could build your own apps, customized to your own workloads, to simplify the whole game?\nThat is the premise of a new Israeli startup calledSola, which has built a low/no-code platform to let users design their own cybersecurity apps tailored to their specific needs, including tools to manage apps they might already be using. Sola is emerging from stealth today armed with seed funding of $30 million to hit the ground running with the stated aim to \u201cdemocratize\u201d how security can be approached and handled.\n\u201cWe\u2019re not trying to be like another next-generation CPSM, or ASPM,\u201d said co-founder Guy Flechter, referring to posture management tools \u2014 \u201cor any other acronym that you can think of. We want to change the way youthinkabout security. Like Stripe did with payments or Canva did with design.\u201d\nS Capital (the firm founded by the team that started Sequoia Israel) and former long-time Sequoia VC Mike Moritz are co-leading the round, withS32,Glilot Capital Partners, and unnamed angel investors participating. (Sola has been around for about a year, and some of the details of this round leaked out while it was still in the works and the company had yet to unveil any details about its product.)\nSola is the brainchild of two longtime players in the world of cybersecurity whose experience effectively bookends the challenge. Flechter is a builder who previously co-founded and led Cider Security, a specialist in application security that wasacquiredby Palo Alto Networks for $300 million in 2022. His co-founder Ron Peled was the classic end user: He had previously been the chief infosec officer for AI commerce company LivePerson and worked as an advisor to a number of other companies.\nAs Flechter describes it, these days there are basically two options for solving security challenges.\nOption one is to buy a very robust, commercial solution, typically for a price tag that can be in the six figures. \u201cIt\u2019s a very complex solution, and at the end of the day you will probably not use everything you\u2019ve paid for,\u201d he said.\nOption two is building solutions yourself using open source components. \u201cYou need a very high level of technical expertise to bring that together,\u201d he said.\nSola\u2019s approach is effectively a swing at creating a new option three.\nTapping into the latest innovations using AI and big data management, the platform is designed for organizations that might not have large security teams and to be used by those without extensive technical skills.\nSola\u2019s interface lets users set goals or ask questions in natural language, then pull in data from different sources and identify what it is aiming to track, to create a new \u201capp\u201d that works with that company\u2019s specific assets.\nSola can be used to query data within existing security apps that are being used, Flechter said, but it also has security tooling built into it to replace certain functionality. Sola has \u201cready-made\u201d apps as well for those who do not want put together apps of their own.\nThe aim is to create more streamlined security services for organizations, that in theory will do exactly what they want, and for a fraction of the price.\nApps currently in the app gallery give you an idea of what kinds of functionality Sola envisions it can handle. An AWS Network Security app, for example, lets the user \u201cGet a high-level summary of key AWS network security metrics, including potential vulnerabilities.\u201d\nThe kinds of questions it can help answer, it says, include \u201cWhich security groups have overly permissive rules?\u201d, \u201cWhich network protocols are enabled across my environment?\u201d, \u201cAre there any unprotected open ports that could expose critical services?\u201d, and \u201cWhat\u2019s the status of my VPC flow logs?\u201d\nThere are dozens more apps pre-written to cover other cloud environments, developer environments like GitHub, and major security tools such as Okta and Wiz.\nMoritz, notably, is making his first investment here in a security startup in his capacity as a solo investor. He said that what stood out for him was how the Sola team was leaning into the bigger trend of building simplified front ends with more complicated work being done behind the scenes in the back end, while tapping into technological innovations to make that possible. That is a pattern that has been seen previously in areas like payments with Stripe, design with Canva and many other now-giant tech companies. But his words are a reminder too that all this is still a work in progress.\n\u201cIt\u2019s clear that Sola is going to take advantage of all the advances that are occurring at breath-taking speed in the evolution of AI. That is very evident in its product,\u201d he said in an interview. \u201cIf you look at the interface today of Sola compared to where it was even 18 months ago, it\u2019s advanced massively thanks to the improvements and breakthroughs that have been announced and unveiled in those last 18 months.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/radiology-ai-software-provider-gleamer-expands-into-mri-with-two-small-acquisitions/",
        "date_extracted": "2025-03-14T13:08:41.269015",
        "title": "Radiology AI software provider Gleamer expands into MRI with two M&A transactions",
        "author": null,
        "publication_date": null,
        "content": "Medical imaging is a broad term that encompasses several distinct technologies. After working on AI-powered tools to enhance X-rays and mammographies, French startupGleamernow aims to tackle magnetic resonance imaging (MRI).\nInstead of starting from scratch, Gleamer acquired a startup that has already been working on AI-powered MRI analysis,Caerus Medical, and is merging withPixyl.\nGleamer is part of the second wave of startups trying to improve medical imaging using artificial intelligence. Several tech founders created startups around this topic in 2014 or 2015. While most of them went nowhere, there has been some consolidation in the space. For instance, Zebra Medical Vision and Arterys were both acquired byNanoxandTempus, respectively.\nFounded in 2017, Gleamer has been building an AI assistant for radiologists, a sort of copilot for medical imaging. With Gleamer, radiologists can theoretically improve the diagnostic accuracy when interpreting medical images.\nThe startup has already persuaded 2,000 institutions across 45 countries to use its software solution. Overall, Gleamer has processed 35 million examinations. The company has received CE and FDA certifications for its bone trauma interpretation product. In Europe, it also offers products specifically focused on chest X-rays, orthopedic, and bone age measurements with CE certification.\n\u201cUnfortunately, the one-size-fits-all approach to radiology doesn\u2019t work,\u201d Gleamer co-founder and CEO Christian Allouche told TechCrunch. \u201cIt\u2019s very complicated to have a large model that covers all medical imaging and delivers the level of performance expected by doctors.\u201d\nThat\u2019s why the company created small internal teams focused on mammographies and CT scans. \u201cThree weeks ago we released our mammography product, which we have been working on for 18 months,\u201d Allouche said. It\u2019s based on a proprietary AI model that has been trained on 1.5 million mammographies.\n\u201cWe have a partnership with Jean Zay, the French government\u2019s GPU cluster,\u201d Allouche said. The company is also working on CT scans for cancers.\nBut what about MRI? \u201cMRI is a different technological space,\u201d Allouche said. \u201cYou have a lot of tasks in MRI. It\u2019s not just detection; you\u2019ve got segmentation, you\u2019ve got detection, you\u2019ve got characterization, classification, multi-sequence imaging.\u201d\nThat\u2019s why Gleamer is acquiring a small startup (Caerus Medical) and merging with a larger one (Pixyl) to move faster. These two companies have been working in this space for several years. Gleamer isn\u2019t disclosing the terms of the deals.\n\u201cThese two companies will become our two MRI platforms, with the clear ambition of covering all use cases over the next two to three years,\u201d Allouche said.\nWhile Gleamer\u2019s models show promising results, they are not yet perfect. For example, with the company\u2019s new mammography model, the startup claims it can detect four out of five cancers. In comparison, a human radiologist without AI assistance typically identifies cancer in three out of five cases.\nHowever, the productivity gains from a tool like Gleamer could radically change medical imaging. A missed tumor is likely to appear in a follow-up exam a few months later.\n\u201cIn the not-too-distant future, I think we\u2019ll all be getting routine whole-body MRIs paid for by our insurance companies \u2014 since they\u2019re not irradiating,\u201d Allouche said.\nHowever, in some cities, there are already too few radiologists to meet the demand for reactive imaging. If the industry shifts toward preventive imaging, AI tools will become indispensable.\nGleamer\u2019s CEO thinks AI could become an \u201corchestrating and triaging\u201d tool. Most medical imaging examinations are conducted as a way to rule out some diagnoses. \u201cSo, there\u2019s a real need to automate all this with a very solid AI model that has a much higher level of sensitivity than a human,\u201d Allouche said.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/in-another-chess-move-with-microsoft-openai-is-pouring-12b-into-coreweave/",
        "date_extracted": "2025-03-14T13:08:44.044140",
        "title": "In another chess move with Microsoft, OpenAI is pouring $12B into CoreWeave",
        "author": null,
        "publication_date": null,
        "content": "In a grandmaster-level chess move, OpenAI has signed afive-year, $11.9 billion agreementwith the GPU-heavy cloud service provider CoreWeave, which Reuters originally reported and CoreWeaveconfirmed in a press release.\nThe deal involves OpenAI receiving $350 million worth of equity in CoreWeave, the companies said. The private placement is said to be separate fromCoreWeave\u2019s planned IPO.\nCoreWeave filed to become a public company last week, but it has not yet priced or scheduled its debut.\nIt\u2019s a win for both companies. One reason this agreement is so eye-popping (besides the billions involved) is that before this deal, CoreWeave\u2019s biggest customer was Microsoft. In fact, in 2024, Microsoft accounted for 62% of CoreWeave\u2019s revenue, which grew to a stunning  $1.9 billion \u2014 nearly an eightfold increase from just $228.9 million in 2023.\nBacked by Nvidia, which holds a 6% stake, CoreWeave runs an AI-specific cloud service with a network of 32 data centers that operated more than 250,000 Nvidia GPUs as of the end of 2024, according to the company. Since then, CoreWeave has added more GPUs, including Nvidia\u2019s latest product, Blackwell, which supports AI reasoning, the company said.\nSuch dependence on one customer is usually worrisome for IPO investors and could have added \u201chair\u201d as they say, to CoreWeave\u2019s hopes of raising $4 billion or more in its IPO. Landing OpenAI as a direct customer in a multi-billion-dollar deal should help CoreWeave appease investors.\nWhat makes this move equally interesting is that it\u2019s another step in the deteriorating,\u00a0frenemies relationship between Microsoft and OpenAI.\nIt\u2019s as if OpenAI CEO Sam Altman saw Microsoft\u2019s usage of CoreWeave and said, \u201cHold my beer.\u201d\nNot only will OpenAI have access to the same cloud, but it will also have an ownership stake in the company that runs it.\nMicrosoft is, of course, a big backer of OpenAI in a deal thatentitles Microsoft to collect a portionof OpenAI\u2019s revenue. But tensions between two companies have been rising for years, as OpenAI\u2019s fortunes have soared. OpenAI competes with Microsoft for enterprise customers and is evenreportedly working on rolling out pricey AI agents.\nIn January, as part of the massive Stargate AI infrastructure deal with SoftBank, Oracle, and others,Microsoft ceased being OpenAI\u2019ssole cloud provider. OpenAI needs more compute resources. Just last week, Altmancomplained that OpenAI is \u201cout of GPUs.\u201d\nFor its part, Microsoft is working on its own AI \u201creasoning\u201d models comparable to OpenAI\u2019so1ando3-mini. It\u2019s developing a whole family of its own models called MAI that are competitive with OpenAI. It alsohired Altman\u2019s rival, Mustafa Suleyman, to lead Microsoft AI.\nBut CoreWeave is a surprising chess piece.\nCoreWeave began its life as a crypto mining operation, founded by former hedge fund guys,it said. The three co-founders have already cashed out of $488 million worth of shares \u2014 over $150 million apiece. CoreWeave also has a stunning $7.9 billion of debt on the books.\nIf the IPO generates the billions of new capital they hope it will, the company says it will use at least some of that to pay down the debt.\nWhile these founders were once literally attempting to use GPUs to mint money, they are figuratively apparently accomplishing it.\nOpenAI did not respond to our request for comment.\nNote: This story was updated to include a reference to CoreWeave\u2019s press release announcing the deal.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/poolside-ceo-says-most-companies-shouldnt-build-foundation-models/",
        "date_extracted": "2025-03-14T13:08:46.899836",
        "title": "Poolside CEO says most companies shouldn\u2019t build foundation models",
        "author": null,
        "publication_date": null,
        "content": "Poolside co-founder and CEO Jason Warner didn\u2019t mince words: He thinks that most companies looking to build foundation AI models should instead focus on building applications. Poolside is an AI-powered software development platform.\nWarner told the audience at theHumanX AI conferencein Las Vegas on Monday that he thinks intelligence is the most important commodity in the world \u2014 on par with electricity \u2014 and anyone who doesn\u2019t believe this should not be building a foundation model.\n\u201cIf you\u2019re one of those people, if you want to take one side of the fence, you\u2019re a printing press for cash unlike anything we\u2019ve ever seen in the world,\u201d Warner said. \u201cOr if the other side of the fence, you\u2019re basically changing and bending the arc of humanity in a way that we\u2019ve not done before. And I believe that to be true.\u201d\nWarner added that his company is \u201cliterally\u201d going after AGI through software. If someone looks at foundational models as more of a \u201cnice to have\u201d as a way to raise VC cash, the company should just build a wrapper on an existing foundational model instead, he added.\nWith all that being said, however, Warner said he thinks that companies building foundation models can\u2019t just have a foundation model as their product. Instead, that should be a part of their product \u2014 especially as the landscape gets more competitive.\n\u201cIn my view, if I\u2019m going to go build this type of business, I\u2019m building on one side, going after intelligence on compute, I need to go after the hardest environment,\u201d Warner said. \u201cYou can\u2019t do simple on one side and hard on the other. It doesn\u2019t really make sense, because if you\u2019re going to go for everything, go for everything.\u201d\nHe added that this is why Poolide is going after tough fields like defense and working with the government. But Warner said the company plans to launch a consumer application at some point, too.\nSan Francisco-based Poolside was founded in 2023 by Warner, the former CTO of GitHub and VC at managing director at Redpoint, and Eiso Kant, a serial founder. The company has raised more than $620 million in venture funding and iscurrently valued at $3 billion.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/deepseek-isnt-taking-vc-money-yet-here-are-3-reasons-why/",
        "date_extracted": "2025-03-14T13:08:49.696810",
        "title": "DeepSeek isn\u2019t taking VC money yet \u2014 here are 3 reasons why",
        "author": null,
        "publication_date": null,
        "content": "DeepSeek\u2019s founder Liang Wenfeng is in no hurry to get investment from outsiders, the WSJreportedMonday.\nDeepSeek is one of the hottest AI startups in the world right now after the Chinese AI companytook Silicon Valley by stormwithits latest modelearlier this year.\nUnlike DeepSeek\u2019s AI model provider counterparts, who regularly announce mega-rounds filled with prominent investors, Liang hasn\u2019t announced any fundraises, despite lots of VC interest. Rumors about its supposed investors have evenfueled (baseless) ralliesin some Chinese stocks.\nAn analysis of Chinese corporate records done by TechCrunch shows that DeepSeek is 84% owned by Liang. The rest of the startup is owned by individuals affiliated with Liang\u2019s hedge fund, High-Flyer.\nThat means that unlike most startups, which require outside capital and are thus used to at least some external influence, DeepSeek is basically a one-man show. And Liang doesn\u2019t have the highest regard for VCs\u2019 opinions.\nWhen Liang was trying to raise capital in the past, he was put off by VCs\u2019 focus on rapidly monetizing AI as opposed to fundamental research, he said ina 2023 interview with Chinese media.\nSo one big reason why Liang hasn\u2019t said yes to the investors pounding down his door is that he doesn\u2019t want to share control of his company, the WSJ reported.\nMost startups need capital from investors from the start. But DeepSeek is a unique beast. Liang has been able to fund DeepSeek through High-Flyer\u2019s profits, reducing his need for outside investment.\n\u201cMoney has never been the problem for us; bans on shipments of advanced chips are the problem,\u201d Liang said in 2023.\nAs a Chinese company, DeepSeek operates under strict Chinese laws that grant its government broad data access.\nConcerns over this have prompted DeepSeek bans froma rising number of governmentsand evensome private companies.\nThose bans could get even worse if DeepSeek accepts funding from a Chinese investor, who face similar issues.\nThe U.S. government has a history of sanctioning Chinese tech companies it says are close to the Chinese government, like telecom giant Huawei and popular drone maker DJI.\nThat hasn\u2019t stopped some Chinese state entities from approaching DeepSeek for investment, The Informationreported, although there\u2019s no indication DeepSeek has accepted any.\nThis doesn\u2019t mean DeepSeek will never raise outside capital, though.\nEarlier this month, DeepSeekannounced a (largely theoretical) profit marginfor the first time, signaling a shift toward monetization \u2014 something VCs value but that Liang previously dismissed.\nTo keep up with other AI heavyweights, DeepSeek will also likely need access to more and better AI chips \u2014 the biggest bottleneck on its development, Liang said in 2023. Those chips are expensive and heavily restricted in China due toU.S. export controls.\nDeepSeek\u2019s ability to be self-funding may also be fading. While High-Flyer has done well in the past, some of its flagship funds have underperformed since 2022, the WSJ reported.\nIt also doesn\u2019t help that the Chinese government has beencracking downon quant funds like High-Flyer since 2024.\nWhile few concrete names are circulating, DeepSeek has already drawn interest from Tencent and Alibaba, according to multiple news reports.\nDeepSeek didn\u2019t immediately respond to a request for comment.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/gmail-gains-an-add-to-calendar-button-powered-by-gemini/",
        "date_extracted": "2025-03-14T13:08:52.517948",
        "title": "Gmail gains an \u2018Add to calendar\u2019 button, powered by Gemini",
        "author": null,
        "publication_date": null,
        "content": "A nifty new Gmail capability powered by Google\u2019sGeminiAI has arrived for Google Workspace customers.Starting Monday, users can add events to a Google Calendar directly from an email.\nGemini will automatically detect calendar-related content in an email and present an \u201cAdd to calendar\u201d button. After clicking the button, the side panel in Gmail will open to confirm the event has been added to the calendar.\nGoogle notes in a blog post that the feature is only available in English and on the web for now. A calendar event created via the \u201cAdd to calendar\u201d button won\u2019t include other guests, and it also won\u2019t appear for emails with already-extract events, like restaurant and flight reservations.\nUsers on Google Workspace Business and Enterprise tiers, as well as customers with a Gemini Education, Gemini Education Premium, or Google One AI Premium plan, are eligible for the new feature. (Users who previously purchased the now-deprecated Gemini Business or Gemini Enterprise add-ons are also eligible.) Admins can enable \u201cAdd to calendar\u201d by switching on smart features and personalization from the Workspace Admin console.\n\u201cAdd to calendar\u201d is only the latest Gemini-powered tool to reach Gmail inboxes. In June 2024, Googleadded new capabilitiesto\u00a0Gmail on the web to help users write emails and summarize email threads, plus ask questions and find specific information from emails within an inbox. Some of those capabilities came to the Gmail apps foriOSandAndroidtoward the end of last year.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/Add-to-Calendar_.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/heres-your-chance-to-host-a-side-event-at-techcrunch-sessions-ai/",
        "date_extracted": "2025-03-14T13:08:55.309011",
        "title": "Here\u2019s your chance to host a Side Event at TechCrunch Sessions: AI",
        "author": null,
        "publication_date": null,
        "content": "If you want to amplify your brand to over 1,000 AI experts and innovators, there\u2019s no better way than by hosting a Side Event duringTechCrunch Sessions: AI Week.\nFrom June 1 to June 7, TechCrunch is looking for fun and thought-provoking events to coincide withTC Sessions: AI, which takes place on June 5 in Zellerbach Hall at UC Berkeley. Whether it be a cocktail party, an industry meetup, or a thought-provoking panel, we\u2019re open to a wide range of Side Events.\nTC Sessions: AIis the event that will give you insights into the cutting-edge and ever-evolving industry through expert-led main-stage sessions, hands-on demos, and unparalleled networking opportunities. Apply to host a Side Event to make sure your brand is part of the conversation.\nIn addition to receiving an exclusive discount code on your and your network\u2019sTC Sessions: AItickets, TechCrunch will fully promote your Side Event to our TechCrunch audience and TC Sessions: AI attendees:\nAs the host, you will be responsible for managing your event\u2019s registration, promotion, creative, communication, insurance, and cost. There is no fee to be a part of the TC Sessions: AI Side Events lineup. See thefull terms and conditions hereand read throughour official event guideto learn everything you need to know about hosting a Side Event.\nSide Events offer a powerful way to build your brand in Berkeley\u2019s AI scene while making valuable connections. Gain exposure to 1,000+ startup, VC, and AI leaders at TC Sessions: AI. Don\u2019t miss out \u2014apply now!\nPaid sponsor events can take place at any time during TechCrunch Sessions: AI or during TechCrunch Sessions: AI Week. Paid sponsored events get additional and guaranteed promotional benefits that Side Events do not. If you want to learn more about sponsored opportunities,fill out this form here.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/avataros-snags-7m-seed-round-from-m13-to-build-an-ai-powered-virtual-influencer-platform/",
        "date_extracted": "2025-03-14T13:08:58.155473",
        "title": "AvatarOS snags $7M seed round from M13 to build an AI-powered virtual influencer platform",
        "author": null,
        "publication_date": null,
        "content": "A few years ago, several startups with a specific focus on digital avatars appeared because of all the metaverse buzz. While that buzz died down, generative AI has given a new life to avatars as it is easier to spin up different virtual identities. Companies are trying out different use cases for avatars, includingD-IDandSynthesiain the enterprise space,Zoomfor meetings,Glancefor fashion,Praktikafor learning, andTikTokandCaptionsin the creator space.\nHowever, Isaac Bratzel, who created popular virtual influencers such asLil MiquelaandAmelia 2.0, thinks there is a lack of high-quality avatars that not just look great but have personalized traits. And that thought process led him to buildAvatarOS.\nBratzel previously worked in design roles at IPsoft (where he created Amelia 2.0), virtual influencer company Brud (where he created Lil Miquela), and Dapper Labsafter the company acquired Brud. He started AvatarOS after he left Dapper Labs in 2022.\nThe company said it closed a seed funding round of $7 million led by M13\u2019s Latif Peracha with participation from Andreessen Horowitz Games Fund, HF0, Valia Ventures, and Mento VC.\nAvatarOS is in an exploratory phase to find the right product-market fit. Bratzel noted that the company is aware that customers don\u2019t always want or need what you can do as a company, technologically, or what is cool.\nAs for M13, Peracha said that this is an exploratory round and the opportunity to back a founder who has a robust track record in the avatar space.\n\u201cWe are going to look at the right business model through this round of exploration and have a bit more clarity on the way forward. We think that because of Isaac\u2019s history in IPsoft to Brud, he is clearly the right person to build the business,\u201d he said.\nHe also added that he did part of the due diligence by talking to an avatar of Bratzel to know more about the founder.\nThe founder said that AvatarOS is geared toward making high-end avatars in 3D space rather than catering to a world of click-to-generate content.\n\u201cOne obvious parallel is spam emails. When it is easy to create content, it proliferates everywhere, and you want to have that differentiation from the saturation of content. That\u2019s where we want to be in the avatar space,\u201d Bratzel told TechCrunch over a call.\n\u201cWhile there are existing products that have tech for avatar generation, we want to focus on the avatar itself. If you look at Lil Miquela \u2026 That is a permanent entity beyond one single project and was able to accrue value over time,\u201d he added.\nThe company is currently onboarding beta users and giving them access to a few existing avatars. The startup is also releasing a simple API that clients can use to integrate avatars with their sites. Bratzel said these organizations can power these avatars with large language models (LLMs) to provide info, and also change things like camera angles and views.\nAvatarOS currently creates premium and customized avatars for clients themselves. But down the line, it wants to provide more tools for creation and adjustment to clients. Bratzel said the company\u2019s main differentiation would be the way avatars move in their space.\n\u201cThe main thing that is important to us is the humans move in a unique way. Pretty much every avatar solution can create something that might look like you but moves generically. Our view is that humans don\u2019t move in the same way, and we want to recreate that,\u201d he said.\nThe company will use the funding to grow its team and also build out a machine learning-based deformer that is responsible for creating lifelike movements in avatars.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/Isaac-headshot-compressed.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/consumer-reports-finds-popular-voice-cloning-tools-lack-safeguards/",
        "date_extracted": "2025-03-14T13:09:01.076748",
        "title": "Consumer Reports finds popular voice cloning tools lack safeguards",
        "author": null,
        "publication_date": null,
        "content": "Several popular voice cloning tools on the market don\u2019t have \u201cmeaningful\u201d safeguards to prevent fraud or abuse,according to a new study from Consumer Reports.\nConsumer Reports probed voice cloning products from six companies \u2014 Descript, ElevenLabs, Lovo, PlayHT, Resemble AI, and Speechify \u2014 for mechanisms that might make it more difficult for malicious users to clone someone\u2019s voice without their permission. The publication found that only two, Descript and Resemble AI, took steps to combat misuse.\u00a0Others required only that users check a box confirming that they had the legal right to clone a voice or make a similar self-attestation.\nGrace Gedye, policy analyst at Consumer Reports, said that AI voice cloning tools have the potential to \u201csupercharge\u201d impersonation scams if adequate safety measures aren\u2019t put in place.\n\u201cOur assessment shows that there are basic steps companies can take to make it harder to clone someone\u2019s voice without their knowledge \u2014 but some companies aren\u2019t taking them,\u201d Gedye said in a statement.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/showcase-your-innovation-exhibit-at-techcrunch-sessions-ai/",
        "date_extracted": "2025-03-14T13:09:03.909786",
        "title": "Showcase your innovation \u2014 exhibit at TechCrunch Sessions: AI",
        "author": null,
        "publication_date": null,
        "content": "On June 5, 1,200 of the brightest minds in AI and VC leaders will converge in Zellerbach Hall at UC Berkeley forTechCrunch Sessions: AI\u2014 the must-attend AI event of the year.\nWhat does this mean for your startup? A prime opportunity to showcase your breakthrough to a crowd hungry for AI innovation. We\u2019ve made it seamless \u2014 just visitthis exhibit pageand claim your booth today!\nBroaden your impact:Present your cutting-edge solutions on the lively TC Sessions: AI Expo floor, where more than 1,200 AI experts, investors, and enthusiasts gather. This is your chance to showcase your startup\u2019s unique value and forge connections that could drive your business ahead.\nFull conference access to engage and network:Leverage six full conference passes, giving you and your team full access to TC Sessions: AI. Dive into main-stage sessions, participate in roundtables, network with industry leaders, and present your startup to an AI-focused audience, building valuable connections throughout.\nEnhance your brand awareness:Showcase your startup on the TC Sessions: AI website and event app, ensuring your startup stands out to investors and partners, and giving you an edge over the competition.\nAffordable and high impact:Priced at just $7,500, this Exhibitor program offers exceptional value for startups looking to stand out to an AI audience. Benefit from unmatched visibility, networking, and marketing assistance.\nWe ensure attendees can\u2019t miss your showcase by putting innovation front and center. Here\u2019s how we do it.\nWith only 12 exhibit tables available, they\u2019ll be sure to go fast. Don\u2019t miss your chance to boost your brand \u2014claim your table now for TC Sessions: AI.Learn more and get your exhibit table here.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/supercharge-your-brand-visibility-with-an-exhibit-table-at-techcrunch-disrupt-2025/",
        "date_extracted": "2025-03-14T13:09:06.889374",
        "title": "Supercharge your brand visibility with an exhibit table at TechCrunch Disrupt 2025",
        "author": null,
        "publication_date": null,
        "content": "From October 27-29,TechCrunch Disrupt 2025will bring together over 10,000 startup pioneers, VC leaders, and tech enthusiasts at Moscone West in San Francisco \u2014 the epicenter of innovation set to reshape the future of technology.\nWhat\u2019s in it for your startup? A golden opportunity to put your innovation in front of an eager audience for all three days. The process is easy \u2014 simplyvisit this exhibit pageand reserve your booth today!\nExpand your reach: Showcase your innovative solutions in the bustling Disrupt Expo Hall for three full days, with over 10,000 tech leaders and VCs in attendance. Seize the opportunity to highlight your startup\u2019s unique value and forge partnerships that can drive your growth.\nMaximize connection opportunities: Receive 11 conference passes for you and your team to fully engage with Disrupt 2025. Attend main stage discussions, breakout sessions, roundtables, and network one-on-one with decision-makers, all while positioning your startup in front of a highly engaged audience.\nBoost your brand visibility: Promote your brand to Disrupt attendees and the whole TechCrunch audience before, during, and after Disrupt 2025 across multiple platforms \u2014 Disrupt\u2019s website, event app, and a TechCrunch post \u2014 ensuring your startup stands out to founders, investors, and potential partners and clients.\nUnmatched ROI: For just $10,000, this Exhibitor package offers extraordinary value \u2014 delivering maximum exposure, essential networking, and extensive marketing support from TechCrunch to amplify your brand.\nThe Disrupt Expo Hall has limited booth spaces, and they won\u2019t last long. Act fast to secure your spot and amplify your brand at Disrupt 2025.Reserve your table now and get all the details here.\nIf you\u2019re looking to sponsor TechCrunch Disrupt 2025, get in touch with our sales team bysubmitting this form.See the impact for yourself \u2014 watch the video below to hear how our partners thrive with us.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/Disrupt-2024-Exhibitors_Nebius.jpg?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/03/Disrupt-2024-Exhibitors_Fye-Labs.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/microsoft-appears-to-be-working-on-3d-gaming-experiences-for-copilot/",
        "date_extracted": "2025-03-14T13:09:09.924227",
        "title": "Microsoft appears to be working on 3D gaming experiences for Copilot",
        "author": null,
        "publication_date": null,
        "content": "Microsoft appears to be working on 3D gaming experiences for Copilot, its AI-powered chatbot platform, according to a new job listing.\nThe listing, published this week, seeks a senior software engineer based in Beijing specializing in 3D rendering engines, particularly engines typically used to build web browser-based video games (Babylon.js, three.js, and Unity).\n\u201cAre you passionate about gaming and interested in building innovative solutions for billions of users?\u201d the job description reads. \u201cIf you have a background in gaming or a strong passion for it, this is the perfect opportunity for you!\u201d\nMicrosoft has previously indicated that it plans to make gaming a larger part of the Copilot experience.\nIn February, Microsoftdemoed an AI model, Muse, that the company said will soon power short interactive games on Copilot. Muse is trained on game developer Ninja Theory\u2019s multiplayer battle arena game Bleeding Edge. It can understand the 3D game world, including game physics and how the game reacts to players\u2019 controller actions, allowing the model to create gameplay rendered by AI.\nIn a separate announcement last May, Microsoft said it wasworking to embed Copilot into video games, starting with Minecraft. The company showed Copilot responding to questions like \u201cHow do I craft a sword?\u201d in-game, searching a player\u2019s inventory for the necessary materials, and instructing the player on how to obtain key missing components.\nIn another bid to boost engagement, Microsoft has reportedlybeen experimenting with\u201ccharacter-based\u201d Copilot features. In January, reverse engineer Alexey Shabanov discovered two animated characters in Copilot designed to interact with users through sound effects and animations.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/10/servicenow-buys-moveworks-for-2-85b-to-grow-its-ai-portfolio/",
        "date_extracted": "2025-03-14T13:09:12.718709",
        "title": "ServiceNow to buy Moveworks for $2.85B to grow its AI portfolio",
        "author": null,
        "publication_date": null,
        "content": "ServiceNow said on Monday that it has agreed to acquireMoveworks, which develops enterprise-focused automation and AI tools.\nServiceNow will pay $2.85 billion for Moveworks in a mix of cash and stock. The former expects the deal to close in the second half of 2025. Bloombergreportedthe deal late on Sunday night.\nAs of June 2021, Moveworks was valued at $2.1 billion.\n\u201cWith the acquisition of Moveworks, ServiceNow will take another giant leap forward in agentic AI-powered business transformation,\u201d ServiceNow president and COO Amit Zavery said in a press release. \u201cMoveworks\u2019 talented team and elegant AI-first experience, combined with ServiceNow\u2019s powerful AI-driven workflow automation, will supercharge enterprise-wide AI adoption and deliver game-changing outcomes for employees and their customers.\u201d\nZavery said the deal made sense for ServiceNow because it and Moveworks already have a number of mutual customers, and the two companies\u2019 product offerings are tightly integrated. By folding Moveworks into its corporate family, ServiceNow has an opportunity to build a platform that \u201ccombines] ServiceNow\u2019s agentic AI and automation strengths with Moveworks\u2019 [\u2026] AI assistant and enterprise search technology,\u201d Zavery said.\nMoveworks was founded in 2016 by Bhavin Shah, Vaibhav Nivargi, Varun Singh, and Jiang Chen. Shah previously co-founded Refresh, an app that surfaced insights about people in users\u2019 extended social networks (LinkedIn acquiredit in 2015). Nivargi built a business analytics platform calledClearStory, while Singh was a lead product manager at Meta overseeing Facebook feature development. Chen came to Moveworks by way of Yahoo, Google, and Airbnb.\nMountain View-based Moveworks came out of stealth in 2019 with an application to help enterprise customers automate high-level IT support. Over the years, the startup expanded its product portfolio to address various lines of business, including HR, finance, and facilities management.\nThe company\u2019s clients include Unilever, Instacart, Siemens, and Toyota, per its website. Prior to the ServiceNow acquisition, Moveworks managed to raise just over $300 million from backers including Tiger Global, Iconiq Growth and Kleiner Perkins. It has more than 500 employees.\n\u201cMoveworks hides the complexity employees face at work by giving them an intuitive, engaging starting place to search and drive action across any enterprise system,\u201d Shah said in a statement. \u201cBecoming part of ServiceNow presents an incredible opportunity to accelerate our innovation and deliver on our promise through their AI agent-fueled platform to redefine the user experience for employees and customer service teams.\u201d\nThe deal solidifies ServiceNow\u2019s strategy to embrace emerging AI technologies. In January, the companyacquiredCuein, an \u201cAI-native\u201d conversation data analysis platform, to enhance its data processing capabilities.\nServiceNow claims its newest AI solutions are the fastest-growing in its history. The company said it had nearly 1,000 \u201cAI customers\u201d as of December 2024, and around $200 million in annual contract value for its \u201cPro Plus\u201d AI tier.\nIn its most recent fiscal quarter (Q4 2024), Santa Clara-based ServiceNowreported$2.96 billion in subscription revenues, driven in part by AI adoption.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/09/manus-probably-isnt-chinas-second-deepseek-moment/",
        "date_extracted": "2025-03-14T13:09:15.451373",
        "title": "Manus probably isn\u2019t China\u2019s second \u2018DeepSeek moment\u2019",
        "author": null,
        "publication_date": null,
        "content": "Manus, an \u201cagentic\u201d AI platform that launched in preview last week, is generating more hype than a Taylor Swift concert.\nThe head of product at Hugging Facecalled Manus\u201cthe most impressive AI tool I\u2019ve ever tried.\u201d AI policy researcher Dean BalldescribedManus as the \u201cmost sophisticated computer using AI.\u201d Theofficial Discord serverfor Manus grew to over 138,000 members in just a few days, and invite codes for Manus arereportedlyselling for thousands of dollars on Chinese reseller app Xianyu.\nBut it\u2019s not clear the hype is justified.\nexcellenthttps://t.co/TfeV9QZ1d0\n\u2014 jack (@jack)March 9, 2025\n\nManus wasn\u2019t developed entirely from scratch.According to reportson social media, the platform uses a combination of existing and fine-tuned AI models, including Anthropic\u2019s Claude and Alibaba\u2019s Qwen, to perform tasks such as drafting research reports and analyzing financial filings.\nYet on its website, Butterfly Effect \u2014 the Chinese startup behind Manus \u2014 gives a few wild examples of what the platform supposedly can accomplish,from buying real estate to programming video games.\nIn aviral videoon X, Yichao \u201cPeak\u201d Ji, a research lead for Manus, implied that the platform was superior to agentic tools such as OpenAI\u2019sdeep researchandOperator. Manus outperforms deep research on a popular benchmark for general AI assistants called GAIA, Ji claimed, which probes an AI\u2019s ability to carry out work by browsing the web, using software, and more.\n\u201c[Manus] isn\u2019t just another chatbot or workflow,\u201d Ji said in the video. \u201cIt\u2019s a completely autonomous agent that bridges the gap between conception and execution [\u2026] We see it as the next paradigm of human-machine collaboration.\u201d\nBut some early users say that Manus is no panacea.\nAlexander Doria, the co-founder of AI startup Pleias,said in a post on Xthat he encountered error messages and endless loops while testing Manus. Other X userspointed out that Manus makes mistakes on factual questionsanddoesn\u2019t consistently cite its work\u2014 andoften misses information that\u2019s easily found online.\nDeep Research finished in under 15 minutes. Unfortunately, Manus AI failed after 50 minutes at step 18/20! \ud83d\ude11 It was performing quite well-I was watching Manus\u2019 output & it seemed excellent. However, running the same prompt a second time is a bit frustrating as it takes too long!https://t.co/bGtmOI65CP\n\u2014 Derya Unutmaz, MD (@DeryaTR_)March 8, 2025\n\nMy own experience with Manus hasn\u2019t been incredibly positive.\nI asked the platform to handle what seemed to me like a pretty straightforward request: order a fried chicken sandwich from a top-rated fast food joint in my delivery range. After about 10 minutes, Manus crashed. On the second attempt, it found a menu item that met my criteria, but Manus couldn\u2019t complete the ordering process \u2014 or provide a checkout link, even.\nManus similarly whiffed when I asked it to book a flight from NYC to Japan. Given instructions that I thought didn\u2019t leave much room for ambiguity (e.g. \u201clook for a business-class flight, prioritizing price and flexible dates\u201d), the best Manus could do was serve up links to fares across several airline websites and airfare search engines like Kayak, some of which were broken.\nHoping the next few tasks might be the charm, I told Manus to reserve a table for one at a restaurant within walking distance. It failed after a few minutes. Then I asked the platform to build a Naruto-inspired fighting game. It errored out half an hour in, which is when I decided to throw in the towel.\nHonest opinion after trying Manus AI for the last 3 days, here\u2019s the good and the bad.\nGood:\u2013 The research it does on the internet and the reports it generates are incredible.\u2013 Its ability to run scripts behind the scenes to execute tasks is impressive.\u2013 The plans it\u2026\n\u2014 AshutoshShrivastava (@ai_for_success)March 9, 2025\n\nA spokesperson for Manus sent TechCrunch the following statement via DM:\n\u201cAs a small team, our focus is to keep improving Manus and make AI agents that actually help users solve problems [\u2026] The primary goal of the current closed beta is to stress-test various parts of the system and identify issues. We deeply appreciate the valuable insights shared by everyone.\u201d\nSo if Manus is falling short of its technical promises, why did it blow up? A few factors contributed, such as the exclusivity created by ascarcity of invites.\nChinese media was quick to tout Manus as an AI breakthrough;publication QQ News called it\u201cthe pride of domestic products.\u201d Meanwhile, AI influencers on social media spread misinformation about Manus\u2019 capabilities. Awidely shared videoshowed a desktop program, ostensibly Manus, taking action across multiple smartphone apps.Ji confirmedthat the video wasn\u2019t, in fact, a demo of Manus.\nOtherinfluentialAIaccountson X sought to draw comparisons between Manus and Chinese AI companyDeepSeek\u2014 comparisons not necessarily rooted in fact. Butterfly Effect didn\u2019t develop models in-house, unlike DeepSeek. And while DeepSeek made many of its technologies openly available, Butterfly Effect hasn\u2019t \u2014at least not yet.\nTo be fair to Butterfly Effect, Manus is in early access. The company claims it\u2019s working to scale computing capacity and fix issues as they\u2019re reported. But as the platform currently exists, Manus appears to be a case of hype running ahead of technological innovation.\nUpdated 6:02 p.m. Pacific: Added a statement from a Manus spokesperson and corrected a misidentification of the company behind Manus.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/03/Screenshot-2025-03-09-at-1.02.21PM.png?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/03/Screenshot-2025-03-09-at-1.41.07PM.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/09/tammy-nam-joins-ai-powered-ad-startup-creatopy-as-ceo/",
        "date_extracted": "2025-03-14T13:09:18.251677",
        "title": "Tammy Nam joins AI-powered ad startup Creatopy as CEO",
        "author": null,
        "publication_date": null,
        "content": "Creatopy, a startup that uses AI to automate the creation of digital ads, has brought on a new CEO:Tammy Nam.\nNam waspreviously COO and CMO at photo-editing startup Picsart, and before that the CEO of video streamer Viki. She told TechCrunch via email that Creatopy was looking for a U.S.-based executive who knows how to scale early-stage startups, has worked with European founders (the product was first developed in Romania), and understands marketing tech.\n\u201cFortunately, I fit that bill,\u201d she said.\nNam is also joining the Creatopy board, while the startup\u2019s previous CEO Dan Oros has stepped into an advisory role.\nThe startupannounced a $10 million Series Aled by European VCs 3VC and Point Nine last year. In a statement, 3VC partner Eva Arh described Nam as \u201cone of the best operators I know.\u201d\nBetween February 2024 and February 2025, the company claims to have grown mid-market and enterprise revenue by 400%, with much of that growth coming in the past six months. Customers include AstraZeneca, NASCAR, and The Economist.\n\u201cWhat\u2019s remarkable about Creatopy \u2014 especially for a relatively unknown company \u2014 is our ability to land major enterprise customers in demanding industries like pharma and banking,\u201d Nam said.\nShe added that customers love the product for \u201cour intuitive interface, unique product capabilities, and excellent customer service.\u201d In fact, she suggested that as large language models become \u201cubiquitous,\u201d Creatopy differentiates itself based on its \u201cability to understand customer needs and deliver \u2014 perhaps ironically \u2014 high-touch value on top of the AI.\u201d\nNam also described brand safety as a \u201ctop priority,\u201d with marketing managers uploading brand kits during account setup, and those kits ensuring that every AI-generated ad adheres to their brand guidelines.\n\u201cOur AI doesn\u2019t replace strategic thinking; it amplifies it,\u201d she said. \u201cSome of our customers have reported a 10x or more increase in productivity because we eliminate the tedious, manual work of generating hundreds of ad variations across sizes, formats, languages, etc.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/09/apples-smart-home-hub-reportedly-delayed-by-siri-challenges/",
        "date_extracted": "2025-03-14T13:09:21.090367",
        "title": "Apple\u2019s smart home hub reportedly delayed by Siri challenges",
        "author": null,
        "publication_date": null,
        "content": "Apple announced this week that the \u201cmore personalized\u201d version of Siri that it promised last yearhas been delayed\u2014 and according toBloomberg\u2019s Mark Gurman, that\u2019s also postponed the launch of the company\u2019s planned smart home hub.\nIn a statement, Apple said the upgraded Siri features, which arepart of its broader Apple Intelligencesuite, will \u201ctake us longer than we thought to deliver,\u201d and it now expects to launch them in the \u201ccoming year.\u201d\nGurman said thatApple\u2019s smart home hubrelies on the new Siri features, so it\u2019s been postponed as well. He\u2019d previously reported that the device could be released as soon as March 2025 (so, this month). It would reportedly include a six-inch touchscreen that\u2019s mounted on the wall, could be used for video calls and managing smart home devices, and would be largely controlled by voice.\nDespite the delay, the company has reportedly started an internal testing program allowing employees to take the device home for feedback.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/09/musk-may-still-have-a-chance-to-thwart-openais-for-profit-conversion/",
        "date_extracted": "2025-03-14T13:09:23.963352",
        "title": "Musk may still have a chance to thwart OpenAI\u2019s for-profit conversion",
        "author": null,
        "publication_date": null,
        "content": "Elon Musk lost thelatest battle in his lawsuit against OpenAI this week, but a federal judge appears to have given Musk \u2014 and others who oppose OpenAI\u2019s for-profit conversion \u2014 reasons to be hopeful.\nMusk\u2019s suit against OpenAI, which also names Microsoft and OpenAI CEO Sam Altman as defendants, accuses OpenAI of abandoning its nonprofit mission to ensure its AI research benefits all humanity. OpenAI was founded as a nonprofit in 2015 but converted to a \u201ccapped-profit\u201d structure in 2019, and now seeks to restructure once more into a public benefit corporation.\nMusk had sought a preliminary injunction tohalt OpenAI\u2019s transition to a for-profit. On Tuesday, a federal judge in Northern California, U.S. District Court Judge Yvonne Gonzalez Rogers, denied Musk\u2019s request \u2014 yet expressed some jurisprudential concerns about OpenAI\u2019s planned conversion.\nJudge Rogers said in her ruling denying the injunction that \u201csignificant and irreparable harm is incurred\u201d when the public\u2019s money is used to fund a nonprofit\u2019s conversion into a for-profit. OpenAI\u2019s nonprofit currently has a majority stake in OpenAI\u2019s for-profit operations, and itreportedlystands to receive billions of dollars in compensation as a part of the transition.\nJudge Rogers also noted that several of OpenAI\u2019s co-founders, including Altman and president Greg Brockman, made \u201cfoundational commitments\u201d not to use OpenAI \u201cas a vehicle to enrich themselves.\u201d In her ruling, Judge Rogers said that the Court is prepared to offer an expedited trial in the fall of 2025 to resolve the corporate restructuring disputes.\nMarc Toberoff, a lawyer representing Musk, told TechCrunch that Musk\u2019s legal team is pleased with the judge\u2019s decision and intends to accept the offer for an expedited trial. OpenAI hasn\u2019t said whether it\u2019ll also accept and did not immediately respond to TechCrunch\u2019s request for comment.\nJudge Rogers\u2019 comments on OpenAI\u2019s for-profit conversion aren\u2019t exactly good news for the company.\nTyler Whitmer, a lawyer representing Encode, a nonprofit thatfiled an amicus briefin the case arguing that OpenAI\u2019s for-profit conversion could jeopardize AI safety, told TechCrunch that Judge Rogers\u2019 decision puts a \u201ccloud\u201d of regulatory uncertainty over OpenAI\u2019s board of directors. Attorneys general in California and Delaware are already investigating the transition, and the concerns Judge Rogers raised could embolden them to probe more aggressively, Whitmer said.\nThere were some wins for OpenAI in Judge Rogers\u2019 ruling.\nThe evidence Musk\u2019s legal team presented to show that OpenAI breached a contract in accepting around $44 million in donations from Musk, then taking steps to convert to a for-profit, was \u201cinsufficient for purposes of the high burden required for a preliminary injunction,\u201d Judge Rogers found. In her ruling, the judge pointed out that some emails submitted as exhibits showedMusk himself considering that OpenAI might become a for-profit company someday.\nJudge Rogers also said that Musk\u2019s AI company, xAI, a plaintiff in the case, failed to demonstrate that it would suffer \u201cirreparable harm\u201d should OpenAI\u2019s for-profit conversion not be enjoined. Judge Rogers was also unpersuaded by the plaintiffs\u2019 arguments that OpenAI\u2019s close collaborator and investor, Microsoft, would violateinterlocking directoratelaws and that Musk has standing under a California provision prohibiting self-dealing.\nMusk, once a key supporter of OpenAI, has positioned himself as one of the company\u2019s greatest adversaries. xAI competes directly with OpenAI in developing frontier AI models, and Musk and Altman now find themselves jockeying for legal and political power under a new presidential administration.\nThe stakes are high for OpenAI. The company reportedly needs to complete its for-profit conversion by 2026, or some of the capital OpenAI recently raised couldconvert to debt.\nAt least one former OpenAI employee is fearful of the implications for AI governance should OpenAI successfully complete its transition. Speaking to TechCrunch on the condition of anonymity to protect their future job prospects, the ex-employee said they believe the startup\u2019s conversion could threaten public safety.\nPart of the motivation behind OpenAI\u2019s nonprofit structure was to ensure that profit motives don\u2019t override its mission: ensuring AI research benefits all of humanity. However, if OpenAI becomes a traditional for-profit company, there may be little to stop it from prioritizing profit above all else, the former employee told TechCrunch.\nThe ex-employee added that OpenAI\u2019s nonprofit structure was one of the main reasons they joined the organization.\nJust a few months from now, it should become clearer how many hurdles OpenAI will have to overcome in its for-profit transition. Regulators, AI safety advocates, and tech investors will be watching with great interest.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/08/new-doj-proposal-still-calls-for-google-to-divest-chrome-but-allows-for-ai-investments/",
        "date_extracted": "2025-03-14T13:09:26.722834",
        "title": "New DOJ proposal still calls for Google to divest Chrome, but allows for AI investments",
        "author": null,
        "publication_date": null,
        "content": "The U.S. Department of Justice is still calling for Google to sell its web browser Chrome, according to a Fridaycourt filing.\nThe DOJ first proposed thatGoogle should sell Chromelast year, under then-President Joe Biden, and it seems to be sticking with that plan under the second Trump administration. The department is, however, no longer calling for the company to divest all its investments in artificial intelligence, including the billions Google haspoured into Anthropic.\n\u201cGoogle\u2019s illegal conduct has created an economic goliath, one that wreaks havoc over the marketplace to ensure that \u2014 no matter what occurs \u2014 Google always wins,\u201d the DOJ said in a filing signed by Omeed Assefi, its current acting attorney general for antitrust. (Trump\u2019s nomineeto lead antitrust for the DOJ still awaits confirmation.)\nFor that reason, the DOJ said it hasn\u2019t changed the \u201ccore components\u201d of its initial proposal, including the divestment of Chrome and a prohibition on search-related payments to distribution partners.\nOn AI, the DOJ said it\u2019s no longer calling for \u201cthe mandatory divestiture of Google\u2019s AI investments\u201d and will instead be satisfied with \u201cprior notification for future investments.\u201d It also said that instead of giving Google the option to divest Android now, it will leave a future decision up to the court, depending on whether the market becomes more competitive.\nThis proposal follows antitrust suits filed by the DOJ and 38 state attorneys general, leading Judge Amit P. Mehta torule that Google acted illegallyto maintain a monopoly in online search. Google has said it will appeal Mehta\u2019s decision, but in the meantime offeredan alternative proposalthat it said would address his concerns by providing partners with more flexibility.\nA Google spokespersontold Reutersthat the DOJ\u2019s \u201csweeping proposals continue to go miles beyond the Court\u2019s decision, and would harm America\u2019s consumers, economy and national security.\u201d\nMehta is scheduled to hear arguments from both Google and the DOJ in April.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/08/google-scrubs-mentions-of-diversity-and-equity-from-responsible-ai-team-webpage/",
        "date_extracted": "2025-03-14T13:09:29.469525",
        "title": "Google scrubs mentions of \u2018diversity\u2019 and \u2018equity\u2019 from responsible AI team web page",
        "author": null,
        "publication_date": null,
        "content": "Google hasquietly updatedtheweb pagefor its Responsible AI and Human Centered Technology (RAI-HCT) team, the team charged with conducting research into AI safety, fairness, and explainability, to scrub mentions of \u201cdiversity\u201d and \u201cequity.\u201d\nA previous version of the page used language such as \u201cmarginalized communities,\u201d \u201cdiverse,\u201d \u201cunderrepresented groups,\u201d and \u201cequity\u201d to describe the RAI-HCT team\u2019s work. That language has been removed, or in some cases replaced with less specific wording (e.g., \u201call,\u201d \u201cvaried,\u201d and \u201cnumerous\u201d rather than \u201cdiverse\u201d).\nGoogle didn\u2019t immediately respond to a request for comment.\nDate: Feb 26 \u2013 March 6, 2025Company:@GoogleChange: Scrubbed mentions of diversity and equity from the mission description of their Responsible AI team.pic.twitter.com/i9VvBcHMQ6\n\u2014 The Midas Project Watchtower (@SafetyChanges)March 8, 2025\n\nThe changes, which were spotted by watchdog group The Midas Project, come after Googledeletedsimilar language from its Startups Founders Fund\u00a0grant website. The companysaid in early Februarythat it would eliminate its diversity hiring targets and review its diversity, equity, and inclusion (DEI) programs.\nGoogle is among the many Big Tech companiesthat have rolled back DEI initiativesas the Trump administration targets what it characterizes as an \u201cillegal\u201d practice.AmazonandMetahave walked back DEI measures over the past few months, and OpenAI\u00a0recently removed mentions of diversity and inclusion from a web page on itshiring practices. Apple, however, recentlypushed back against a shareholder proposalto end its DEI programs.\nMany of these companies, including Google, have contracts with federal agencies.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/08/judge-allows-authors-ai-copyright-lawsuit-against-meta-to-move-forward/",
        "date_extracted": "2025-03-14T13:09:32.259713",
        "title": "Judge allows authors\u2019 AI copyright lawsuit against Meta to move forward",
        "author": null,
        "publication_date": null,
        "content": "A federal judge is allowing an AI-related copyright lawsuit against Meta to move forward, although he dismissed part of the suit.\nIn Kadrey vs. Meta, authors \u2014 including Richard Kadrey, Sarah Silverman, and Ta-Nehisi Coates \u2014 have alleged that Meta has violated their intellectual property rights by using their books to train its Llama AI models and that the company removed the copyright information from their books to hide the alleged infringement.\nMeta, meanwhile, has claimed that its training qualifies as fair use, and it argued the case should be dismissed because the authors lack standing to sue. In court last month, U.S. District Judge Vince Chhabria seemed to indicate he wasagainst dismissal, but he also criticized what he saw as \u201cover-the-top\u201d rhetoric from the authors\u2019 legal teams.\nIn Friday\u2019sruling, Chhabria wrote that the allegation of copyright infringement is \u201cobviously a concrete injury sufficient for standing\u201d and that the authors have also \u201cadequately alleged that Meta intentionally removed CMI [copyright management information] to conceal copyright infringement.\u201d\n\u201cTaken together, these allegations raise a \u2018reasonable, if not particularly strong inference\u2019 that Meta removed CMI to try to prevent Llama from outputting CMI and thus revealing it was trained on copyrighted material,\u201d Chhabria wrote.\nThe judge did, however, dismiss the authors\u2019 claims related to the California Comprehensive Computer Data Access and Fraud Act (CDAFA), because they did not \u201callege that Meta accessed their computers or servers \u2014 only their data (in the form of their books).\u201d\nThe lawsuit has already provided a few glimpses into how Meta approaches copyright, with court filings from the plaintiffs claiming thatMark Zuckerberg gave the Llama team permissionto train the models using copyrighted works and that otherMeta team members discussed the use of legally questionable contentfor AI training.\nThe courts are weighing a number of AI copyright lawsuits at the moment, includingThe New York Times\u2019 lawsuit against OpenAI.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/08/9-us-ai-startups-have-raised-100m-or-more-in-2025/",
        "date_extracted": "2025-03-14T13:09:35.042151",
        "title": "9 US AI startups have raised $100M or more in 2025",
        "author": null,
        "publication_date": null,
        "content": "Last year was a monumental year for the AI industry in the U.S. and beyond.\nThere were49 startups that raised funding rounds worth $100 millionor more in 2024, per our count at TechCrunch. Three companies raised more than one \u201cmega-round\u201d last year, and seven companies raised rounds at $1 billion or larger.\nHow will 2025 compare? It\u2019s still early in the year but the number of U.S. AI companies that have raised more than $100 million is almost in double digits, and there has already been one round larger than $1 billion.\nHere are all the U.S. AI companies that have raised more than $100 million so far this year.\nThis piece has been updated to remove that Abridge is based in Pittsburgh, the company was founded there.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/03/07/cursor-in-talks-to-raise-at-a-10b-valuation-as-ai-coding-sector-booms/",
        "date_extracted": "2025-03-14T13:09:38.021013",
        "title": "Cursor in talks to raise at a $10B valuation as AI coding sector booms",
        "author": null,
        "publication_date": null,
        "content": "Investor interest in AI coding assistants is exploding.\nAnysphere, the developer of AI-powered coding assistant Cursor, is in talks with venture capitalists to raise capital at a valuation of nearly $10 billion,Bloomberg reported.\nThe round, if it transpires, would come about three months after Anysphere completed its previous fundraise of $100 million at a pre-moneyvaluation of $2.5 billion, as TechCrunch was first to report. The new round is expected to be led by returning investor Thrive Capital.\nThrive Capital and Anysphere didn\u2019t immediately respond to a request for comment.\nWhile Anysphere\u2019s previous round valued the company at 25 times its $100 million ARR (per TheNew York Times), investors seem to be willing to value fast-growing companies at even higher multiples now. Anysphere\u2019s current annualized recurring revenue (ARR)\u00a0may have already climbed to $150 million,The Information reported, which means the new deal, should it happen would be a whopping 66 times ARR.\nAnysphere isn\u2019t the only company receiving such a high valuation from investors.\nCodeium, a company behind AI coding editor Windsurf, is raising capital at a valuation of nearly $3 billion,TechCrunch reportedlast month. Kleiner Perkins, which is leading the round into Codeium, valued the company at about 70 times ARR of about $40 million.\nAI is adapting fastest in coding tools, outpacing its use in sales, law, healthcare, and other sectors, according to investors.\nIn recent weeks, investors have been approaching Poolside, another AI-powered coding company that is also developing its own LLM, sources tell TechCrunch and The Information. Poolside didn\u2019t immediately respond to a request for comment.",
        "tags": [],
        "images": []
    }
]