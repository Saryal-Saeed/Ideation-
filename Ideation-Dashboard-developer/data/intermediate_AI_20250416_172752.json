[
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/16/hammerspace-an-unstructured-data-wrangler-used-by-nvidia-meta-and-tesla-raises-100m-at-500m-valuation/",
        "date_extracted": "2025-04-16T17:26:36.679624",
        "title": "Hammerspace, an unstructured data wrangler used by Nvidia, Meta and Tesla, raises $100M at $500M+ valuation",
        "author": null,
        "publication_date": null,
        "content": "Artificial intelligence services at their heart are massive data plays: you need data \u2014 a lot of it \u2014 to build the models, and then the models need efficient ways to ingest and output data to work.\nA company calledHammerspacehas built a system to help AI and other organisations tap into data troves with minimal heavy lifting, and it\u2019s been seeing impressive adoption. Now, withcustomersincluding NVIDIA, Meta, Tesla, Palantir and the Department of Defense as well as other very recognisable names, Hammerspace is announcing $100 million in funding to expand its business.\nThe funding is being described as a \u201cstrategic venture round,\u201d and it values Hammerspace at over $500 million, sources close to the company told TechCrunch. Its backers include Altimeter Capital and ARK Invest, alongside strategic investors that are not being disclosed. The investors are being described as \u201chighly participatory.\u201d\nThe funding is notable because it points to the ecosystem developing around the value that the market sees in AI companies, which are raising billions of dollars both to build their capital-intensive businesses and meet massive demand.\nBut as Jamin Ball, a partner at Altimeter, noted, \u201cYou don\u2019t have an AI strategy without a data strategy.\u201d So a company that is building a platform to enable that data strategy can itself become very valuable, too.\nHammerspace said much of its growth so far has been through word-of-mouth. It will be using a portion of this funding to expand on that more proactively with sales and marketing.\nHammerspacepreviously raised $56 millionfrom Prosperity7 Ventures (the venture arm of Saudi Aramco), ARK Invest, Pier 88 Hedge Fund, and other unnamed investors. Prior to that, it was self-funded by its CEO and co-founderDavid Flynn, the pioneer technologist known for his early work on Linux, supercomputers and flash computing.\nThere are a vast number of companies that have set out to plug the big gap that exists in the data market today. \u201cVast\u201d is an operative word here, as it is one of the companies that competes with Hammerspace, along with Dell, Pure Storage, Weka and many others in the worlds of data orchestration, file management, data pipeline, and data management.\nThat gap goes something like this: The apps and other digital services we use to work and do everything else in life these days produce a lot of potentially valuable data. But data troves exist in silos \u2014 they\u2019re fragmented, stored across multiple (competing) clouds and other environments, and are often unstructured. That makes them a challenge to use.\nThis gap applies across a wide range of enterprise use cases, but perhaps the biggest of these at the moment is AI.\n\u201cAI has been the perfect storm for needing what I have built,\u201d Flynn said in an interview.\nHammerspace, as we\u2019ve noted before, is named afterthe conceptfirst coined from cartoons and comics, where characters pull objects they need out of thin air.\nThis is, in effect, what Hammerspace does. The startup provides a way of making large amounts of data, regardless of where it lives or how it is used, accessible and available to an organization just when they need it, and keeping it out of the way when they do not.\nAs Flynn describes it, typically the way that enterprises would have worked with data would be to port it from wherever it is to where it needs to be processed. \u201cYou need to install stuff on every system,\u201d he said. \u201cIt\u2019s a mess.\u201d\nIt\u2019s also slow. \u201cThe AI arms race is such a sprint,\u201d he said. With \u201ctime to value\u201d now a key priority for these companies, Hammerspace is signing up a lot of customers that are anxious about idle time.\nFlynn\u2019s background in flash computing is central to Hammerspace\u2019s breakthrough. Built on Linux, ubiquitous in the database world, he could see that the key to organising data across disparate locations was to create a file system to do so.\nThe heart of this is the Linux kernel NFS client, ubiquitous across many of the data systems. Hammerspace\u2019s co-founder and CTOTrond Myklebustwas the lead developer of the Linux kernel NFS client, and the startup remains its lead maintainer. The \u201cfile system\u201d that the company has built for managing, moving and orchestrating data is based on a particular implementation in Linux that taps this. What it does, Flynn said, \u201cis unique across the industry.\u201d\nLonger term, Flynnsaid last yearthat Hammerspace may go public as early as this year.\u00a0That timeline has changed now but the direction has not.\u00a0\u201cYes, IPO is absolutely the Hammerspace intended strategy,\u201d Flynn said. \u201cWe likely are still approximately two years out (dependent on market conditions).\u201d\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/16/google-used-ai-to-suspend-over-39m-ad-accounts-committing-fraud/",
        "date_extracted": "2025-04-16T17:26:39.115854",
        "title": "Google used AI to suspend over 39M ad accounts suspected of fraud",
        "author": null,
        "publication_date": null,
        "content": "Google on Wednesday said it suspended 39.2 million advertiser accounts on its platform in 2024  \u2014\u00a0more than triple the number from the previous year \u2014\u00a0in its latest crackdown on ad fraud.\nBy leveraging large language models (LLMs) and using signals such as business impersonation and illegitimate payment details, the search giant said it could suspend a \u201cvast majority\u201d of ad accounts before they ever served an ad.\nLast year, Google launched over 50 LLM enhancements to enhance its safety enforcement mechanisms across all its platforms.\n\u201cWhile these AI models are very, very important to us and have delivered a series of impressive improvements, we still have humans involved throughout the process,\u201d said Alex Rodriguez, a general manager for Ads Safety at Google, in a virtual media roundtable.\nThe executive told reporters that a team of over 100 experts assembled across Google, including members from the Ads Safety team, the Trust and Safety division, and researchers from DeepMind. They analyzed deepfake ad scams involving public figure impersonations and developed countermeasures.\nThe company introduced technical countermeasures and over 30 ads and publisher policy updates last year. These moves helped suspend over 700,000 offending advertising accounts, leading to a 90% drop in reports of deepfake ads, the company claims.\nIn the U.S. alone, Google said it suspended 39.2 million advertiser accounts and took down 1.8 billion ads last year, with key violations tied to ad network abuse, trademark misuse, healthcare claims, personalized ads, and misrepresentation.\nIndia, the world\u2019s most populous country and the second biggest internet market after China in terms of users, saw 2.9 million account suspensions last year, Google said, making it the second-highest after the U.S. The company also removed 247.4 million ads in India, with the top five policy violations related to financial services, trademark misuse, ad network abuse, personalized ads, and gambling and games.\nOf all the advertiser account suspensions, Google said it suspended 5 million accounts for scam-related violations.\nOverall, the company removed almost half a billion ads related to scams.\nGoogle also verified more than 8,900 new election advertisers in 2024, which saw half of the world\u2019s population go to the polls, and removed 10.7 million election ads. However, Rodriguez noted that the volume of election ads compared to Google\u2019s overall ad numbers was relatively small and would not significantly impact its safety metrics this year.\nIn total, Google said it blocked 5.1 billion ads last year and removed 1.3 billion pages. In comparison, itblockedover 5.5 billion ads and took action against 2.1 billion publisher pages in 2023.\nGoogle told TechCrunch that the decreasing numbers indicated improvements in its prevention efforts. By improving early detection and suspension of malicious accounts, fewer harmful ads are produced or reach the platform, the company said.\nThe company also restricted 9.1 billion ads last year, it said.\nImportantly, large-scale suspensions sometimes spark concerns over how fairly a company applies its rules. Google said it offers an appeal process that includes human reviews to ensure it took \u201cappropriate action.\u201d\n\u201cOftentimes, some of our message wasn\u2019t as clear and transparent about specifics, about what the rationale was, or reasoning, and sometimes that left the advertiser a little more confused. We ended up updating a bunch of our policies as it related to that, a bunch of our transparency capabilities in terms of the messaging around what and why to help the advertiser\u2026It\u2019s been a big focus for the team as part of 2024 and into 2025,\u201d Rodriguez said.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/ad-account-suspensions-20241.jpg",
            "https://techcrunch.com/wp-content/uploads/2025/04/google-ad-blocked-20241.jpg"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/grok-gains-a-canvas-like-tool-for-creating-docs-and-apps/",
        "date_extracted": "2025-04-16T17:26:41.852368",
        "title": "Grok gains a canvas-like tool for creating docs and apps",
        "author": null,
        "publication_date": null,
        "content": "Grok, the chatbot from Elon Musk\u2019s AI company, xAI, has gained a canvas-like feature for editing and creating documents and basic apps.\nCalled Grok Studio, the feature was announced on X late Tuesday. It\u2019s available for both free and paying Grok users on Grok.com\n\u201cGrok can now generate documents, code, reports and browser games,\u201dwrote the official Grok account on X. \u201cGrok Studio will open your content in a separate window, allowing both you and Grok to collaborate on the content together.\u201d\nToday, we are releasing the first version of Grok studio, adding code execution and google drive support.\nGrok StudioGrok can now generate documents, code, reports, and browser games. Grok Studio will open your content in a separate window, allowing both you and Grok to\u2026pic.twitter.com/lyQh06F8eP\n\u2014 Grok (@grok)April 16, 2025\n\nGrok is the latest chatbot to get a dedicated workspace for tinkering with software and writing projects. OpenAI launched a similar capability,Canvas, for ChatGPT in October. Anthropic was one of the first to the punch, withArtifactsfor Claude.\nGrok Studio doesn\u2019t seem materially different from the canvas-like tools that\u2019ve come before it. It lets you preview HTML snippets and run code in programming languages like Python, C++, and JavaScript. All content opens in a window to the right-hand side of Grok\u2019s responses.\nGrok Studio is made potentially more useful by another Grok upgrade announced today: integration with Google Drive. Now, you can attach files from a Google Drive account to a Grok prompt. Grok can work with documents, spreadsheets and slides, according to xAI.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/nvidia-h20-chip-exports-hit-with-license-requirement-by-us-government/",
        "date_extracted": "2025-04-16T17:26:44.288285",
        "title": "Nvidia H20 chip exports hit with license requirement by US government",
        "author": null,
        "publication_date": null,
        "content": "Semiconductor giant Nvidia is facing unexpected new U.S. export controls on its H20 chips.\nIn a filing Tuesday, Nvidia said it was informed by the U.S. government that it will need a license to export its H20 AI chips to China. This license will be required indefinitely, according to the filing \u2014 the U.S. government cited \u201crisk that the [H20] may be used in [\u2026] a supercomputer in China.\u201d\nNvidia anticipates $5.5 billion in related charges in its Q1 2026 fiscal year, which ends April 27. The company\u2019s stock was down around 6% in extended trading.\nThe H20 is the most advanced AI chip Nvidia can export to China under the U.S.\u2019 current and previous export rules. Last week,NPRreported that CEO Jensen Huang might havetalked his way outof new H20 restrictions during a dinner at President Donald Trump\u2019s Mar-a-Lago resort, in part by committing that Nvidia would invest in AI data centers in the U.S.\nPerhaps not-so-coincidentally, Nvidiaannounced on Mondaythat it would spend hundreds of millions of dollars over the next four years manufacturing some AI chips in the U.S.Punditswere quick to point out that the company\u2019s commitment was light on the details.\nMultiple government officials had been calling for stronger export controls on the H20 because the chip was allegedly used to train models from China-based AI startup DeepSeek, including the R1 \u201creasoning\u201d model that threw the U.S. AI market for a loop in January.\nNvidia declined to comment.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/telli-a-yc-alum-raises-pre-seed-funding-for-its-ai-voice-agents/",
        "date_extracted": "2025-04-16T17:26:46.752292",
        "title": "Telli, a YC alum, raises pre-seed funding for its AI voice agents",
        "author": null,
        "publication_date": null,
        "content": "Former Y Combinator startupTelliis helping companies alleviate the bottleneck that occurs when a high-volume of customers try to, for example, book appointments. Its AI voice agents kick in and handle basic operations while handing off more-complex processes to human operators. The Berlin-based startup has now raised $3.6 million in a pre-seed funding\u00a0round led by Berlin\u2019s Cherry Ventures and Y Combinator.\nTelli\u00a0says its AI voice agents can perform a number of tasks, including automated callbacks and even closing deals.\nThe startup, which was founded by\u00a0Seb Hapte-Selassie, Philipp Baumanns, and Finn zur M\u00fchlen, has concentrated on making its agents blend into company operations.\nIt\u2019s now claiming to have reached revenue growth of more than 50% month over month and has processed close to a million phone calls (and all with only a six-person team) out of the Berlin office.\u00a0Customers are spread across Germany, the U.K., Latin America, and the U.S., with plans for further expansion.\nCEO zur M\u00fchlen told TechCrunch that the founders got the idea after working at German unicorn Enpal, one of Germany\u2019s biggest startup successes: \u201cWe scaled the customer service people, and we saw firsthand how difficult call automation for customer acquisition is and how difficult it is to manage performance.\u201d\nHe said that Telli\u2019s AI agents \u201cactually achieve outcomes like booking appointments, prequalifying leads, making product suggestions, and so on.\u201d The voices are created by hired voice actors, whose voices are then cloned using the ElevenLabs or Cartesian AI voice-cloning platforms, he said.\nThe underlying AI models Telli uses vary between OpenAI, Claude, and others: \u201cWe switch around. Our goal is always to give our customers the best solutions that are out there right now,\u201d he said.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/openai-says-it-may-adjust-its-safety-requirements-if-a-rival-lab-releases-high-risk-ai/",
        "date_extracted": "2025-04-16T17:26:49.179585",
        "title": "OpenAI may \u2018adjust\u2019 its safeguards if rivals release \u2018high-risk\u2019 AI",
        "author": null,
        "publication_date": null,
        "content": "OpenAI hasupdatedits Preparedness Framework \u2014 the internal system it uses to assess the safety of AI models and determine necessary safeguards during development and deployment. In the update, OpenAI stated that it may \u201cadjust\u201d its safety requirements if a competing AI lab releases a \u201chigh-risk\u201d system without similar protections in place.\nThe change reflects the increasing competitive pressures on commercial AI developers to deploy models quickly. OpenAI has beenaccused of lowering safety standardsin favor of faster releases, and of failing to delivertimely reports detailing its safety testing.\u00a0Last week, 12 former OpenAI employeesfiled a briefin Elon Musk\u2019s case against OpenAI, arguing the company would be encouraged to cuteven morecorners on safety should it complete its planned corporate restructuring.\nPerhaps anticipating criticism, OpenAI claims that it wouldn\u2019t make these policy adjustments lightly, and that it would keep its safeguards at \u201ca level more protective.\u201d\n\u201cIf another frontier AI developer releases a high-risk system without comparable safeguards, we may adjust our requirements,\u201d wrote OpenAI in ablog postpublished Tuesday afternoon. \u201cHowever, we would first rigorously confirm that the risk landscape has actually changed, publicly acknowledge that we are making an adjustment, assess that the adjustment does not meaningfully increase the overall risk of severe harm, and still keep safeguards at a level more protective.\u201d\nThe refreshed Preparedness Framework also makes clear that OpenAI is relying more heavily on automated evaluations to speed up product development. The company says that while it hasn\u2019t abandoned human-led testing altogether, it has built \u201ca growing suite of automated evaluations\u201d that can supposedly \u201ckeep up with [a] faster [release] cadence.\u201d\nSome reports contradict this.According to the Financial Times, OpenAI gave testers less than a week for safety checks for an upcoming major model \u2014 a compressed timeline compared to previous releases. The publication\u2019s sources also alleged that many of OpenAI\u2019s safety tests are now conducted on earlier versions of models rather than the versions released to the public.\nIn statements, OpenAI has disputed the notion that it\u2019s compromising on safety.\nOpenAI is quietly reducing its safety commitments.\nOmitted from OpenAI\u2019s list of Preparedness Framework changes:\nNo longer requiring safety tests of finetuned modelshttps://t.co/oTmEiAtSjS\n\u2014 Steven Adler (@sjgadler)April 15, 2025\n\nOther changes to OpenAI\u2019s framework pertain to how the company categorizes models according to risk, including models that can conceal their capabilities, evade safeguards, prevent their shutdown, and even self-replicate. OpenAI says that it\u2019ll now focus on whether models meet one of two thresholds: \u201chigh\u201d capability or \u201ccritical\u201d capability.\nOpenAI\u2019s definition of the former is a model that could \u201camplify existing pathways to severe harm.\u201d The latter are models that \u201cintroduce unprecedented new pathways to severe harm,\u201d per the company.\n\u201cCovered systems that reach high capability must have safeguards that sufficiently minimize the associated risk of severe harm before they are deployed,\u201d wrote OpenAI in its blog post. \u201cSystems that reach critical capability also require safeguards that sufficiently minimize associated risks during development.\u201d\nThe updates are the first OpenAI has made to the Preparedness Framework since 2023.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/figma-sent-a-cease-and-desist-letter-to-lovable-over-the-term-dev-mode/",
        "date_extracted": "2025-04-16T17:26:51.724969",
        "title": "Figma sent a cease-and-desist letter to Lovable over the term \u2018Dev Mode\u2019",
        "author": null,
        "publication_date": null,
        "content": "We may be witnessing the makings of a new tech industry feud between competitors. Figma has sent a cease-and-desist letter to popular no-code AI startup Lovable, Figma confirmed to TechCrunch.\nThe letter tells Lovable to stop using the term \u201cDev Mode\u201d for a new product feature. Figma, which also has a feature called Dev Mode, successfully trademarked that term last year, accordingto the U.S. Patent and Trademark office.\nWhat\u2019s wild is that \u201cdev mode\u201d is a common term used in many products that cater to software programmers. It\u2019s like an edit mode. Software products from giant companies likeApple\u2019s iOS,Google\u2019s Chrome,Microsoft\u2019s Xboxhave features formally called \u201cdeveloper mode\u201d that then get nicknamed \u201cdev mode\u201d in reference materials.\nEven \u201cdev mode\u201d itself is commonly used. For instanceAtlassian used it in products that pre-date Figma\u2019s copyright by years. And it\u2019sa common feature namein countless open source software projects.\nFigma tells TechCrunch that its trademark refers only to the shortcut \u201cDev Mode\u201d \u2013 not the full term \u201cdeveloper mode.\u201d Still, it\u2019s a bit like trademarking the term \u201cbug\u201d to refer to \u201cdebugging.\u201d\nSince Figma wants to own the term, it has little choice but send cease-and-desist letters. (The letter, as manyon X pointed out, was very polite, too.) If Figma doesn\u2019t defend the term, it could be absorbed as a generic term and the trademarked becomes unenforceable.\nSome on the internet argue that this term is already generic, should never have been allowed to be trademarked, and say Lovable should fight.\nLovable\u2019s co-founder and CEO, Anton Osika, tells TechCrunch that, for now, his company has no intention of honoring Figma\u2019s demand and changing the feature\u2019s name.\nWe\u2019ll see if Figma escalates. It also has other things on its mind. On Tuesday,Figma announced it had filed confidential paperwork for an IPO.However, should Figma pursue legal action, taking on an international legal battle might be pricey for the early-stage Swedish startup, Lovable,which raised a $15 million seed round in February.\nWhat\u2019s more interesting is that Lovable is one of the rising stars of so-called \u201cvibe coding.\u201d That\u2019s where\u00a0users can describe what they want in a text prompt and the product builds it \u2013 complete with code. Its \u201cdev mode\u201d feature was launched a few weeks ago to allow users to edit that code.\nLovable advertises itself as a competitor to Figma, declaring onits homepagethat designers can use Lovable \u201cwithout tedious prototyping work in tools like Figma.\u201d\u00a0 And manynewly launched startups are doing just that.\nSo this isn\u2019t just a trademark dispute. It is also a bigger competitor cracking its knuckles at a pesky upstart. Figma wasvalued at $12.5 billionabout a year ago.\nA Figma spokesperson almost admits as much. The person told TechCrunch that Figma has not sent cease-and-desist letters to other tech companies over the term, like Microsoft, because their products are \u201cin a different category of goods and services.\u201d\nAnd Lovable\u2019s Osika is ready to throw a few punches of his own telling TechCrunch that he thinks \u201cFigma should focus on making their product great\u201d and not on trademark marketing. He also tells TechCrunch that Lovable is successfully winning customers away from Figma and other such design tools created in the era before LLMs.\nAs for the overall threat of vibe coding products,in a conversationlast month with Y Combinator\u2019s Garry Tan, Figma co-founder CEO Dylan Field naturally pooh-poohed the idea.\nField said that even though people like vibe coding for its speed, \u201cyou also want to give people a way to not just get started and prototype rapidly but also get to the finish line. That\u2019s where the disconnect is, and not just for design, but also for code.\u201d\nStill Osika also seems ready to compete. When he shared a copy of the Figma\u2019s letter on X, he usedthe grinning emoji.\nNote: This story has been updated with comments from Lovable.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/openai-hires-team-behind-gv-backed-ai-eval-platform-context-ai/",
        "date_extracted": "2025-04-16T17:26:54.424188",
        "title": "OpenAI hires team behind GV-backed AI eval platform Context.ai",
        "author": null,
        "publication_date": null,
        "content": "Context.ai, a startup building evaluations and analytics for AI models, announced Tuesday that its co-founders will join OpenAI.\nContext.ai plans to wind down its products following the acqui-hire, per a message on the company\u2019s website. When reached for comment, OpenAI declined to reveal the terms of the deal.\n\u201cEvals are a requirement to building high-performing AI applications, but they\u2019re hard to get right today,\u201d reads the message. \u201cWe spent two years building evals and analytics for [models] at Context.ai \u2014 with a few pivots along the way. We couldn\u2019t be more excited for this next chapter of our journey at OpenAI and are grateful to everyone who played a part.\u201d\nContext.ai was founded in 2023 by former Googlers Henry Scott-Green (CEO) and Alex Gamble (CTO). The startup raised$3.5 million in seed fundingfrom GV and Theory Ventures that same year.\nOne of Context.ai\u2019s flagship products was a dashboard customers could use to dig into the data generated by a model and figure out if it\u2019s producing content that truly helps answer queries. Context.ai users could share transcripts via an API, which Context.ai would then analyze to group and tag based on subject.\n\u201cThe phrase that I always hear is that \u2018my model is a black box,\u2019\u201d Scott-Green told TechCrunch in a 2023 interview. \u201cWe\u2019ve spoken to hundreds of developers who are building [models], and they have a really consistent set of problems. Those problems are that they don\u2019t understand how people are using their model, and they don\u2019t understand how their model is performing.\u201d\nContext.ai had six employees as of August 2023. It\u2019s unclear how large the team is today, and whether every staffer will be offered a job at OpenAI.\nIn apost on X, Scott-Green said that he and Gamble will be creating \u201cthe tools developers need to succeed\u201d at OpenAI, with a focus on model evaluations. According toScott-Green\u2019s LinkedIn profile, he\u2019s now a product manager at OpenAI \u201cbuilding evals.\u201d\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/anthropic-forms-a-new-team-to-grow-its-aws-business/",
        "date_extracted": "2025-04-16T17:26:56.726923",
        "title": "Anthropic forms a new team to grow its AWS business",
        "author": null,
        "publication_date": null,
        "content": "In a sign of Anthropic\u2019s increasingly cozy relationship with Amazon, Anthropic has formed a new team to recruit AWS customers to use its AI products.\nThe team, which Anthropic appears to have begun hiring several months ago, aims to \u201caccelerate\u201d the adoption of Anthropic\u2019s AI among AWS accounts by \u201cbuilding programs that [\u2026] scale across global markets and segments.\u201d That\u2019s according tojoblistingsonAnthropic\u2019s websiteand job boards around the web.\n\u201c[Y]ou will own and scale one of our most significant strategic relationships, leading a team responsible for multi-billion dollar revenue opportunities through our AWS partnership,\u201d reads alisting for a Head of Amazon GTM Partnership role. \u201cYou will work closely with senior leadership across both organizations to drive joint success [and] shape strategy.\u201d\nAmazon is a major backer of Anthropic,having committed $8 billionin capital to the startup to date. While the company has no governance rights and is a minority investor, Amazon is Anthropic\u2019s \u201cprimary\u201d training partner,providing in-house chipsto help Anthropic develop its AI models.\nAnthropic has also optimized its models to run on AWS infrastructure,releasing models with capabilities exclusive to Bedrock, AWS\u2019 AI development platform. And the company has launched collaborations with Amazon partners, including Accenture andPalantir, to facilitate access to its AI tech through AWS.\nAnthropic CEO Dario Amodei said in November that Anthropic\u2019s Claude family of models was being used by \u201ctens of thousands\u201d of Bedrock customers.\nAmazon, which is leveraging Anthropic technology to power components of its revamped Alexa experience,Alexa+, no doubt sees Anthropic as important to its overall AI business\u2019 growth. Amazon CEO Andy Jassy recentlyclaimedthat Amazon\u2019s AI revenue is growing at \u201ctriple-digit\u201d year-over-year percentages\u00a0and represents a \u201cmulti-billion-dollar annual revenue run rate.\u201d\nAnthropic, meanwhile, stands to benefit from AWS\u2019 reach as it looks to grow its own revenue. The startup isreportedlyaiming to notch $12 billion in revenue in 2027, up from a projected $2.2 billion this year.\nAmazon\u2019s dealings with Anthropic have attracted some regulatory scrutiny.\nThe FTC last year sent a letter to Amazon, as well as to Microsoft and Google,requiringthe companies to explain the impacts their investments in startups such as Anthropic have on the competitive AI landscape. Google has alsoinvestedin Anthropic, pouring billions into the company over multiple funding rounds.\nThe U.K.\u2019s Competition and Markets Authority (CMA) has also investigated Amazon\u2019s partnership with Anthropic, looking at whether key aspects would result in \u201cAmazon having material influence\u201d over the latter.\nThe FTCthis year published a report findingthat AI investments by Big Tech firms can create lock-in and reveal sensitive information that can undermine competition, but stopped short of recommending enforcement action. The CMA, for its part,concludedthat Amazon\u2019s partnership and equity investment in Anthropic can\u2019t be investigated under current merger rules due to the size and scope of the deal.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/anthropics-claude-now-read-your-gmail/",
        "date_extracted": "2025-04-16T17:26:59.124500",
        "title": "Anthropic\u2019s Claude can now read your Gmail",
        "author": null,
        "publication_date": null,
        "content": "Anthropic announced on Tuesday that its AI chatbot, Claude, now integrates with Google Workspace, allowing it to search and reference your emails in Gmail, scheduled events in Google Calendar, and documents in Google Docs.\nThe integration is rolling out in beta first to subscribers to Anthropic\u2019s Max, Team, Enterprise, and Pro plans. Administrators managing multi-user accounts must enable the integration on their end before users can connect their Google Workspace and Claude accounts, according to Anthropic.\nGoogle DeepMind\u2019sGemini chatbot also integrates with Workspace, and OpenAI\u2019s ChatGPT integrates with Google Drive. However, Anthropic is one of the first third-party AI companies to offer a way to closely connect to Google\u2019s productivity suite.\nAnthropic\u2019s team-up with Google aims to give Claude more personally tailored responses without requiring users to repeatedly upload files or craft detailed prompts. OpenAI and Google have tried achieving the same effect via different approaches, such as addingmemory featuresthat allow chatbots to reference past conversations in their replies.\nIn a press release, Anthropic says Claude\u2019s new integration can help users organize their professional and personal lives. For example, Anthropic claims the feature can assist parents by scanning \u201cemails and calendar events to highlight important commitments, while searching the web for updated school calendars, local community events, and weather forecasts that might affect family plans.\u201d\nClaude will provide in-line citations when it references Workspace content, showing users exactly where specific information originated, says Anthropic.\nWhile the integration doesn\u2019t give Claude the ability to schedule calendar events or send emails, it may raise security concerns among some users. It\u2019s unclear how extensively Claude will search through a person\u2019s Google Workspace, or whether users have to direct Claude to look at a particular email or calendar event depending on the nature of their request. It\u2019s also not clear whether users can ask Claude not to search across certain sensitive emails or files.\nResponding to the above, an Anthropic spokesperson told TechCrunch that the company doesn\u2019t train models on user data by default and has implemented \u201cstrict authentication and access control mechanisms\u201d for external services like Workspace.\n\u201cEach user or organization\u2019s connections to external services (like Google Drive, Gmail, etc.) are properly authenticated and authorized for only that specific user or organization,\u201d the spokesperson said in a statement. \u201cClaude doesn\u2019t have the ability to access or transfer data between different users\u2019 connected services, as each connection is bound to the specific authentication credentials of that individual user or organization.\u201d\nAnthropic also announced on Tuesday the launch of Claude Research, a new feature that conducts multiple web searches to generate detailed answers. Positioned as a competitor to OpenAI and Google\u2019s \u201cdeep research\u201d agents, Claude Research offers an \u201coptimal tradeoff\u201d between speed and comprehensiveness, Anthropic says.\nClaude Research typically runs for less than a minute to compile info, according to an Anthropic spokesperson \u2014 faster than some rival deep research agents. However, Claude Research doesn\u2019t use a custom model, instead leveraging Claude\u2019s recently launched web search capabilities.\nThe company is rolling out Claude Research to subscribers to its Max, Team, and Enterprise plans in the United States, Japan, and Brazil. It\u2019ll come to Pro customers soon, Anthropic says.\nThese updates are part of Anthropic\u2019s broader effort to attract users to its AI subscription plans with features that make Claude more capable and useful. WhileClaude is growing in popularity, reaching 3.3 million web users in March, according to data compiled by SimilarWeb, Anthropic\u2019s user base is still dwarfed by ChatGPT\u2019s.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/googles-veo-2-video-generator-comes-to-gemini/",
        "date_extracted": "2025-04-16T17:27:01.418273",
        "title": "Google\u2019s Veo 2 video generating model comes to Gemini",
        "author": null,
        "publication_date": null,
        "content": "Google is bringing itsVeo 2video-generating AI model to users who pay for Gemini Advanced, the company\u2019s premium AI plan.\nThe expansion comes as Google looks to deliver an answer to OpenAI\u2019s Sora video generation platform, and as competition in the space grows fiercer. Two weeks ago, one of the more formidable synthetic media companies, Runway, released thefourth generation of its video generatorandraised more than $300 millionin new capital.\nStarting Tuesday, Gemini Advanced subscribers will be able to select Veo\u00a02\u00a0from the model drop-down menu in Google\u2019sGeminiapps. Users can create eight-second video clips at 720p resolution with a 16:9 aspect ratio, and upload these clips to TikTok, YouTube, and more via Gemini\u2019s \u201cshare\u201d button. Veo 2-generated videos can also be downloaded as MP4 files, watermarked with Google\u2019s SynthID tech.\nThere\u2019s a limit to how many videos users can create each month, and the Google Workspace business and education plans aren\u2019t supported at the moment, the company says.\nGoogle is also integrating Veo 2 with Whisk, an experimental feature in Google Labs that lets you use images as prompts with Gemini to create new images. A new feature, Whisk Animate, lets users take images they\u2019ve generated and turn them into eight-second, Veo 2-generated videos. (Google Labs is Google\u2019s platform for early-stage AI products, gated behind the company\u2019s $20-per-month Google One AI Premium subscription.)\nGoogle\u2019s applications of Veo 2 may seem fairly basic at the moment. But the CEO of Google DeepMind, Demis Hassabis,recently saidthat the company plans to eventually combine itsGeminiAI models withVeotoimprove the former\u2019s understanding of the physical world.\nIn the meantime, many artists and creators are wary of video generators like Veo 2, which threaten to upend entire creative industries. A 2024studycommissioned by the Animation Guild, a union representing Hollywood animators and cartoonists, estimates that more than 100,000 U.S.-based film, television, and animation jobs will be disrupted by AI by 2026.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/ezgif-1ad44b32058578.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/witness-a-dynamic-dialogue-between-two-visionary-ceos/",
        "date_extracted": "2025-04-16T17:27:04.040492",
        "title": "Witness a dynamic dialogue between two visionary CEOs",
        "author": null,
        "publication_date": null,
        "content": "Step into an extraordinary fireside chat featuring Ali Ghodsi, the visionary co-founder and CEO of Databricks, alongside Dario Amodei, the innovative co-founder and CEO of Anthropic. Discover how their groundbreaking partnership is set to accelerate the evolution of domain-specific AI agents.\nDuring thisfree, virtual event, you\u2019ll also gain exclusive access to three additional sessions that expand on the groundbreaking CEO discussion:\nWhat you\u2019ll learn:\nShowtimes vary by time zone:",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/2025-02-ve-techcrunch-dsml-anthropic-speakers-email-banner-600x220-2x-1.png",
            "https://techcrunch.com/wp-content/uploads/2025/04/databricks-article-post-1-3-speakers.jpg"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/openai-is-reportedly-developing-its-own-x-like-social-media-platform/",
        "date_extracted": "2025-04-16T17:27:06.791094",
        "title": "OpenAI is reportedly developing its own X-like social media platform",
        "author": null,
        "publication_date": null,
        "content": "OpenAI is building its own X-like social media network, according to a new report fromThe Verge. The project is still in the early stages, but there\u2019s an internal prototype focused on\u00a0ChatGPT\u2019s image generation that contains a social feed.\nThe report states that it\u2019s unknown if OpenAI plans to launch the social network as a standalone app or if it plans to integrate it within the ChatGPT app.\nWith this new social network, OpenAI would be taking on Elon Musk\u2019s X and Meta\u2019s social platforms, Facebook and Instagram. The new app would also allow OpenAI to access real-time data to train its AI models, something that both X and Meta already have.\nOpenAI CEO Sam Altman has reportedly been privately asking outsiders for feedback about the social network.\nAt this point, it\u2019s not clear whether the project will ever launch publicly, but the existence of a prototype shows that OpenAI is looking to expand beyond its current offerings.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/openai-ships-gpt-4-1-without-a-safety-report/",
        "date_extracted": "2025-04-16T17:27:09.575774",
        "title": "OpenAI ships GPT-4.1 without a safety report",
        "author": null,
        "publication_date": null,
        "content": "On Monday, OpenAIlaunched a new family of AI models, GPT-4.1, which the company said outperformed some of its existing models on certain tests, particularly benchmarks for programming. However, GPT-4.1 didn\u2019t ship with the safety report that typically accompanies OpenAI\u2019s model releases, known as a model or system card.\nAs of Tuesday morning, OpenAI had yet to publish a safety report for GPT-4.1 \u2014 and it seems it doesn\u2019t plan to. In a statement to TechCrunch, OpenAI spokesperson Shaokyi Amdo said that \u201cGPT-4.1 is not a frontier model, so there won\u2019t be a separate system card released for it.\u201d\nIt\u2019s fairly standard for AI labs to release safety reports showing the types of tests they conducted internally and with third-party partners to evaluate the safety of particular models. These reports occasionally reveal unflattering information, like thata model tends to deceive humansor isdangerously persuasive. By and large, the AI community perceives these reports as good-faith efforts by AI labs to support independent research and red teaming.\nBut over the past several months, leading AI labs appear to have lowered their reporting standards, prompting backlash from safety researchers. Some,likeGoogle, havedragged their feeton safety reports, while others have published reportslacking in the usual detail.\nOpenAI\u2019s recent track record isn\u2019t exceptional either. In December, the company drew criticism for releasing a safety reportcontaining benchmark results for a model differentfrom the version it deployed into production. Last month, OpenAIlaunched a model, deep research, weeks prior to publishing the system card for that model.\nSteven Adler, a former OpenAI safety researcher, noted to TechCrunch that safety reports aren\u2019t mandated by any law or regulation \u2014 they\u2019re voluntary. Yet OpenAI has made several commitments to governments to increase transparency around its models. Ahead of the U.K. AI Safety Summit in 2023, OpenAI in a blog postcalled system cards\u201ca key part\u201d of its approach to accountability. And leading up to the Paris AI Action Summit in 2025, OpenAI said system cards provide valuable insightsinto a model\u2019s risks.\n\u201cSystem cards are the AI industry\u2019s main tool for transparency and for describing what safety testing was done,\u201d Adler told TechCrunch in an email. \u201cToday\u2019s transparency norms and commitments are ultimately voluntary, so it is up to each AI company to decide whether or when to release a system card for a given model.\u201d\nGPT-4.1 is shipping without a system card at a time when current and former employees are raising concerns over OpenAI\u2019s safety practices. Last week, Adler and 11 other ex-OpenAI employees filed a proposed amicus brief in Elon Musk\u2019s case against OpenAI, arguing that a for-profit OpenAI might cut corners on safety work. The Financial Times recently reportedthat the ChatGPT maker, spurred by competitive pressures, has slashed the amount of time and resourcesit allocates to safety testers.\nWhile GPT-4.1 isn\u2019t the highest-performing AI model in OpenAI\u2019s roster, it does make substantial gains in the efficiency and latency departments. Thomas Woodside, co-founder and policy analyst at Secure AI Project, told TechCrunch that the performance improvements make a safety report all the more critical. The more sophisticated the model, the higher the risk it could pose, he said.\nMany AI labs have batted down efforts to codify safety reporting requirements into law. For example,OpenAI opposed California\u2019s SB 1047, which would have required many AI developers to audit and publish safety evaluations on models that they make public.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/former-tesla-supply-chain-leaders-create-atomic-an-ai-inventory-solution/",
        "date_extracted": "2025-04-16T17:27:12.257200",
        "title": "Former Tesla supply chain leaders create Atomic, an AI inventory solution",
        "author": null,
        "publication_date": null,
        "content": "Tesla famously struggled to scale up production of the Model 3 sedan in 2018 \u2014 so much so that CEO Elon Musk said his company wasweeks away from collapsing. That near-death experience helped spawn a whole new company called Atomic that\u2019s built around using AI to streamline supply chains.\nCo-founded by former Tesla employees Michael Rossiter and Neal Suidan,Atomicwas created inside DVx Ventures, the firm run by former Tesla president Jon McNeill. Rossiter is also a partner at DVx, which has led a $3 million seed round for Atomic, with Seattle-based Madrona Ventures joining.\n\u201cMichael and Neil experienced this pain firsthand as leaders at Tesla in the supply chain, and I saw that work firsthand \u2014 because they worked for me,\u201d McNeill said in an interview with TechCrunch.\nAtomic plans to deploy its agentic AI with customers to make inventory planning faster and easier. It\u2019s already been working with pilot customers. In one case, the customer was able to cut inventory levels in half while maintaining a 99% in-stock rate.\nBeing able to strike a balance like that frees up working capital that a business can use in other places, while also reducing risk, McNeill said.\n\u201cIf you have too much capital tied up in inventory, you could really harm the business. And if you have too little, where you don\u2019t have the right things in stock when the customer is ready to purchase, then you\u2019re costing yourself big time,\u201d he said.\nMore broadly, Atomic\u2019s early customers have been in the consumer packaged goods, food and beverage, and apparel industries. The company claims it has helped those customers reduce inventory costs by 20% to 50%.\nWith so much uncertainty in the world right now, there\u2019s big demand for solutions like Atomic\u2019s because existing ones aren\u2019t built for this kind of volatility, Suidan said in an interview.\nCurrently, \u201cplanners will, like, lock themselves in a room for a week trying to put together different scenarios, present those back to the leadership, and get a question they weren\u2019t anticipating,\u201d Suidan said. Then they \u201chave to go back to these documents, spend a few days, and it\u2019s becomes this process that can be all consuming for them, because they don\u2019t have the tools available to manage the uncertainty with confidence.\u201d\nAtomic\u2019s software pulls information from those same source documents but lets inventory planners and supply chain team members quickly simulate multiple scenarios \u2014 something that would normally take hours or days.\nRossiter and Suidan pride themselves on being able to get up and running with a customer quickly, and with adaptability.\n\u201cYou can\u2019t be writing a custom application for every customer. You need a flexible data model that\u2019s generalized, that can apply to everyone, because then you can be up and running really, really quickly,\u201d Suidan said. \u201cAnd you need to give precision control to the planner so that they feel true ownership over the plan, and they can explain it inside and out, and can pull all the levers in the plan. And if you can combine those two things, which has been our total focus, then you solve the problem for the planner.\u201d\nMany Tesla employees have gone on to found their own startups, including former CTO JB Straubel (Redwood Materials) and, most recently, former SVP Drew Baglino (Heron).\nBut Atomic is different. Instead of just taking skills learned at Tesla and applying them to new problems, Suidan and Rossiter are building Atomic around a philosophy they developed together at the automaker.\n\u201cThey built the end-to-end supply chain orchestration system from scratch\u201d at Tesla, McNeill said.\nSuidan said the value of what they built at Tesla was just as much about the solution as it was changing the process.\n\u201cThe way the business was planned when we started was a dozen different teams working in isolation, passing these spreadsheets around, trying to tie it together once a week to present executives some summary of a plan, and then spending most of the rest of the week, chasing our tail, trying to figure out why one part didn\u2019t work or the other part didn\u2019t work,\u201d Suidan said. \u201cOur jobs became to build a system that could thrive and drive this company, keep its dynamism, keep its ability to hit these business targets.\u201d\nSuidan said the planning system they built inside Tesla resulted in a \u201ccomplete transformation\u201d in the day-to-day operations. While Rossiter left Tesla shortly after the ramp-up of the Model 3, Suidan stuck around until 2022.\nIn 2023 Suidan said the two put their heads together and asked: \u201cHow could this kind of transformation work for everybody, all businesses?\u201d And they set out to create Atomic inside DVx.\nIn typical Tesla fashion, they really are aiming that high. \u201cOur ambition, our vision, is to support every company that sells physical goods,\u201d Rossiter said.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/host-your-very-own-side-event-during-techcrunch-sessions-ai/",
        "date_extracted": "2025-04-16T17:27:14.543144",
        "title": "Reach 1,000+ AI leaders: Host a Side Event during TechCrunch Sessions: AI",
        "author": null,
        "publication_date": null,
        "content": "Looking to position your brand in front of the brightest minds in artificial intelligence? Hosting aSide Eventduring TechCrunch Sessions: AI Week is your opportunity to do just that. Reach 1,200+ attendees and the surrounding Berkeley tech scene.\nFrom June 1 to June 7, TechCrunch invites startups, investors, and builders to bring unique and engaging Side Events to life alongsideTC Sessions: AI, taking place June 5 in Zellerbach Hall at UC Berkeley. Whether you\u2019re planning a networking happy hour, an industry meetup, a dynamic workshop, or a cocktail hour, we\u2019re welcoming creative formats that complement the week\u2019s main event.\nTC Sessions: AI delivers a comprehensive look at the latest AI trends and advancements through curated programming, live demos, and high-value networking. By hosting a Side Event, your brand becomes part of the narrative \u2014 and benefits from broad exposure to the AI community.\nScore an exclusive discount code for you and your network \u2014 and let TechCrunch amplify your event with full-on promotion to our entire audience and the TC Sessions: AI crowd. Perks include:\nYou\u2019re in charge of your event \u2014 meaning logistics, costs, promo, and everything in between. There\u2019s no fee to join the Side Event lineup, but we do have a few guidelines:\nSide Events are a standout opportunity to connect with the AI community and gain valuable brand visibility.Apply here and make your mark at TC Sessions: AI before the deadline.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/notion-releases-its-ai-driven-email-inbox/",
        "date_extracted": "2025-04-16T17:27:16.839290",
        "title": "Notion releases an AI-powered email client for Gmail",
        "author": null,
        "publication_date": null,
        "content": "Notion releasedNotion Mail, an AI-powered email client for Gmail that integrates with the rest of Notion\u2019s workflow management platform, on Tuesday.\nNotion Mail connects to Notion users\u2019 Gmail accounts and uses AI to help users organize their emails, draft responses, schedule meetings, and search across messages. Any Notion user can sign up, and Notion Mail\u2019s AI capabilities are free with monthly usage limits or unlimited through a paid tier.\nNotion Mail enters an increasingly crowded category of companies looking to improve email inboxes with AI.Superhuman, one of the larger players, has raised $108 million in venture funding for its client that isn\u2019t tied to legacy email providers like Gmail or Microsoft Outlook.Fyxer, which connects to Gmail and Outlook, raised $10 million last month.\nIt\u2019s also worth noting that many of the features Notion Mail is offering are also available from providers like Gmail, which uses AI to sort emails, craft responses, and suggest meetings.\nJason Ginsberg, Notion Mail lead, told TechCrunch that the idea behind Notion Mail wasn\u2019t to attach AI to an existing inbox, but rather give users the ability to use AI to build a custom inbox organized and configured how they want.\n\u201cThe way we built Notion Mail is almost down to the building blocks, or the fundamentals of how email works,\u201d Ginsberg said. \u201cIt\u2019s really modular. And what that means is, like, instead of just going to settings and there\u2019s just what we\u2019ve decided, you actually can configure Notion Mail in ways we can\u2019t even imagine \u2014 all different permutations, so that it actually works the way you prefer.\u201d\nNotion Mail\u2019s infrastructure came from Skiff, an end-to-end encrypted collaboration platformNotion acquired in 2024for an undisclosed sum. Ginsberg co-founded Skiff, which also included an email product.\nAccording to Ginsberg, one of Notion Mail\u2019s more notable features is the ability for users to separate their inbox into \u201cviews\u201d or folders. The feature uses Notion AI to auto-label emails on a particular topic and move them into a separate topic-specific inbox.\nGinsberg imagines users will use the capability to organize emails for a specific purpose, like keeping track of job applications. He said he uses the feature himself to quickly check customer feedback from Notion Mail\u2019s beta customers.\nNotion Mail connects with other Notion products like the platform\u2019s calendar app, Notion Calendar, and its internal knowledge base. This unlocks time-saving shortcuts. If someone in an email exchange suggests scheduling a meeting, Notion\u2019s AI will check a user\u2019s calendar, suggest times they\u2019re free, and prompt them to schedule it.\nGinsberg said that a lot of the innovation around incorporating AI into email has thus far focused mainly on writing emails. He thinks Notion Mail offers something different because of its emphasis on building a customized inbox.\n\u201cI think our focus has really been on, how can AI help organize your email for you?\u201d Ginsberg said. \u201cThe big change there is it\u2019s no longer feeling like a burden where you are going through the same never-ending list, one-size-fits-all inbox and manually triaging emails. Our focus is not to have you work faster in the old way of things. It\u2019s really a new way and a new approach.\u201d\nGinsberg said that in the future, Notion hopes to be able to offer more product integrations and additional ways to access Notion Mail, like an iOS app. The Notion team also wants to be able to offer multiple inboxes in one view down the line.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/apple-details-how-it-plans-to-improve-its-ai-models-by-privately-analyzing-user-data/",
        "date_extracted": "2025-04-16T17:27:19.171504",
        "title": "Apple details how it plans to improve its AI models by privately analyzing user data",
        "author": null,
        "publication_date": null,
        "content": "In the wake of criticism over the underwhelming performance of its AI products, especially in areas likenotificationsummaries, Apple on Mondaydetailedhow it is trying to improve its AI models by analyzing user data privately with the aid of synthetic data.\nUsing an approach called \u201cdifferential privacy,\u201d the company said it would first generate synthetic data and then poll users\u2019 devices (provided they\u2019ve opted-in to share device analytics with Apple) with snippets of the generated synthetic data to compare how accurate its models are, and subsequently improve them.\n\u201cSynthetic data are created to mimic the format and important properties of user data, but do not contain any actual user generated content,\u201d the company wrote in the blog post. \u201cTo curate a representative set of synthetic emails, we start by creating a large set of synthetic messages on a variety of topics [\u2026] We then derive a representation, called an embedding, of each synthetic message that captures some of the key dimensions of the message like language, topic, and length.\u201d\nThe company said these embeddings are then sent to a small number of user devices that have opted in to Device Analytics, and the devices then compare them with a sample of emails to tell Apple which embeddings are most accurate.\nThe company said it is using this approach to improve its Genmoji models, and would in the future use synthetic data for Image Playground, Image Wand, Memories Creation, and Writing Tools, as well as Visual Intelligence. Apple said it would also poll users who opt in to share device analytics with synthetic data to improve email summaries.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/rlwrld-raises-14-4m-to-build-foundation-model-for-robotics/",
        "date_extracted": "2025-04-16T17:27:21.620740",
        "title": "RLWRLD raises $14.8M to build a foundational model for robotics",
        "author": null,
        "publication_date": null,
        "content": "As robotics has advanced, industry has steadily adopted more robots to automate many kinds of grunt work. More than 540,000 new industrial robots were installed worldwide in 2023, taking the number of total industrial robots active to above 4 million, perIFR.\nIndustrial robots typically excel at repetitive tasks, but they find it challenging to perform precise tasks, handle delicate materials, and adjust to changing conditions \u2014 a robot in a restaurant\u2019s kitchen would get in the way more than be helpful, for example. That is why many industrial processes are still manual.\nSouth Korean startupRLWRLDaims to solve this problem with a foundational AI model that it has built specifically for robotics by combining large language models with traditional robotics software. The company says this model will enable robots to make quick and agile movements and perform some amount of \u201clogical reasoning\u201d as well.\n\u201cUsing RLWRLD\u2019s foundation model, processes that require a lot of manual work can be completely automated by learning and copying human expertise, making work environments more efficient,\u201d Jung-Hee Ryu, founder and CEO of RLWRLD, said in an exclusive interview with TechCrunch.\nThe startup is now coming out of stealth with 21 billion KRW (about $14.8 million) in seed funding. The round was led by venture capital firm Hashed; Mirae Asset Venture Investment and Global Brain also invested.\nNotably, RLWRLD has attracted a long list of big strategic investors \u2014 Ana Group, PKSHA, Mitsui Chemical, Shimadzu, and KDDI from Japan; LG Electronics and SK Telecom from Korea; and Amber Manufacturing from India.\nRLWRLD said the seed funding will be used to fund proof-of-concept projects with its strategic investors; secure computing infrastructure like GPUs, purchase robots, and obtain devices to collect extensive data; and hire\u00a0top research talent. The startup will also use the new money to develop advanced hand movements involving five fingers \u2014 a capability that\u2019s not yet been demonstrated by its competitors like Tesla, Figure AI, and 1X, Ryu said.\nRyu said RLWRLD is also working with its strategic investors to explore ways to automate differenthuman-centric workflowsusing its AI model. They are together preparing a humanoid-based autonomous action demonstration, scheduled for later this year, Ryu said. In addition, the company is working to develop a platform that can support various kinds of robots, including industrial, collaborative, autonomous mobile robots, and humanoids.\nFounded in 2024, RLWRLD is Ryu\u2019s third startup. His second startup,Olaworks, was acquired by Intel in 2012, and eventually became Intel\u2019s Korea R&D center within its computer vision division. And in 2015, he foundeda startup accelerator, Future Play, that focuses on deep tech companies.\nWhen asked what inspired him to start a new company again, Ryu said he noticed how quickly AI startups were increasing in number in the U.S., Europe, and China, while comparable AI startups in Korea and Japan were relatively absent.\nHe spoke with over 30 AI professors from Korea and Japan about their challenges \u2014 everything from the lack of infrastructure like data and GPUs, and the obstacles that discouraged them to launch a venture \u2014 and the opportunities available.\n\u201cI determined that it would be strategically beneficial to prioritize robotics foundation models (RFM) over the technologically saturated field of LLMs, capitalizing on Korea and Japan\u2019s notable global strengths in manufacturing,\u201d he said.\nSoon afterward, he brought on board six professors from top-ranked institutions in South Korea, including KAIST, SNU, and POSTECH, along with their research teams, to launch RLWRLD.\nRLWRLD isn\u2019t alone in tackling this problem. Startups likeSkild AIandPhysical Intelligenceare building similar foundational models for robotics, as are larger firms like Tesla,Google DeepMind, andNvidia.\nBut Ryu believes his startup has a good start, as it already has the AI and robotics experts it needs to develop foundational models for robotics, as well as humanoid robots with high degree of freedom (DoF).\n\u201cAdditionally, [such companies] typically rely on low-DoF robots such as two-fingered grippers. RLWRLD has already secured a high-DoF reference robot, and therefore expects superior performance outcomes,\u201d he said.\nRyu also said that thanks to its strategic investors, RLWRLD can quickly gather valuable data from manufacturing sites located nearby. In 2024,a reportindicated that Japan and South Korea collectively accounted for 9.2% of worldwide manufacturing production.\nRLWRLD aims to generate revenue as early as this year through proof-of-concept (PoC) projects and collaboration demonstrations with strategic partners.\nThe startup\u2019s long-term goal is to cater to factories, logistics centers, and retail stores, and even robots that can be used in domestic environments to help with household chores. In the meantime, the priority is to target industrials since they are willing to pay the most and have strong demand for automation.\nThe startup has 13 employees.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/DSC05786.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/debates-over-ai-benchmarking-have-reached-pokemon/",
        "date_extracted": "2025-04-16T17:27:24.110154",
        "title": "Debates over AI benchmarking have reached Pok\u00e9mon",
        "author": null,
        "publication_date": null,
        "content": "Not even Pok\u00e9mon is safe from AI benchmarking controversy.\nLast week, apost on Xwent viral, claiming that Google\u2019s latest Gemini model surpassed Anthropic\u2019s flagship Claude model in the original Pok\u00e9mon video game trilogy. Reportedly, Gemini had reached Lavender Town in a developer\u2019s Twitch stream; Claude wasstuck at Mount Moonas of late February.\nGemini is literally ahead of Claude atm in pokemon after reaching Lavender Town\n119 live views only btw, incredibly underrated streampic.twitter.com/8AvSovAI4x\n\u2014 Jush (@Jush21e8)April 10, 2025\n\nBut what the post failed to mention is that Gemini had an advantage.\nAsusers on Redditpointed out, the developer who maintains the Gemini stream built a custom minimap that helps the model identify \u201ctiles\u201d in the game like cuttable trees. This reduces the need for Gemini to analyze screenshots before it makes gameplay decisions.\nNow, Pok\u00e9mon is a semi-serious AI benchmark at best \u2014 few would argue it\u2019s a very informative test of a model\u2019s capabilities. But itisan instructive example of how different implementations of a benchmark can influence the results.\nFor example, Anthropicreportedtwo scores for its recent Anthropic 3.7 Sonnet model on the benchmark SWE-bench Verified, which is designed to evaluate a model\u2019s coding abilities. Claude 3.7 Sonnet achieved 62.3% accuracy on SWE-bench Verified, but 70.3% with a \u201ccustom scaffold\u201d that Anthropic developed.\nMore recently, Metafine-tuneda version of one of its newer models, Llama 4 Maverick, to perform well on a particular benchmark, LM Arena. Thevanilla versionof the model scores significantly worse on the same evaluation.\nGiven that AI benchmarks \u2014 Pok\u00e9mon included \u2014 areimperfect measuresto begin with, custom and non-standard implementations threaten to muddy the waters even further. That is to say, it doesn\u2019t seem likely that it\u2019ll get any easier to compare models as they\u2019re released.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/openais-new-gpt-4-1-models-focus-on-coding/",
        "date_extracted": "2025-04-16T17:27:26.902069",
        "title": "OpenAI\u2019s new GPT-4.1 AI models focus on coding",
        "author": null,
        "publication_date": null,
        "content": "OpenAI on Monday launched a new family of models called GPT-4.1. Yes, \u201c4.1\u201d \u2014 as if the company\u2019s nomenclature wasn\u2019t confusing enough already.\nThere\u2019s GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano, all of which OpenAI says \u201cexcel\u201d at coding and instruction following. Available through OpenAI\u2019s API but notChatGPT, the multimodal models have a 1-million-token context window, meaning they can take in roughly 750,000 words in one go (longer than \u201cWar and Peace\u201d).\nGPT-4.1 arrives as OpenAI rivals like Google and Anthropic ratchet up efforts to build sophisticated programming models. Google\u2019s recently releasedGemini 2.5 Pro, which also has a 1-million-token context window, ranks highly on popular coding benchmarks. So do Anthropic\u2019sClaude 3.7 Sonnetand Chinese AI startupDeepSeek\u2019s upgraded V3.\nIt\u2019s the goal of many tech giants, including OpenAI, to train AI coding models capable of performing complex software engineering tasks. OpenAI\u2019s grand ambition is to create an \u201cagentic software engineer,\u201d asCFO Sarah Friar put itduring a tech summit in London last month. The company asserts its future models will be able to program entire apps end-to-end, handling aspects such as quality assurance, bug testing, and documentation writing.\nGPT-4.1 is a step in this direction.\n\u201cWe\u2019ve optimized GPT-4.1 for real-world use based on direct feedback to improve in areas that developers care most about: frontend coding, making fewer extraneous edits, following formats reliably, adhering to response structure and ordering, consistent tool usage, and more,\u201d an OpenAI spokesperson told TechCrunch via email. \u201cThese improvements enable developers to build agents that are considerably better at real-world software engineering tasks.\u201d\nOpenAI claims the full GPT-4.1 model outperforms itsGPT-4o and GPT-4o minimodels on coding benchmarks, including SWE-bench. GPT-4.1 mini and nano are said to be more efficient and faster at the cost of some accuracy, with OpenAI saying GPT-4.1 nano is its speediest \u2014 and cheapest \u2014 model ever.\nGPT-4.1 costs $2 per million input tokens and $8 per million output tokens. GPT-4.1 mini is $0.40/million input tokens and $1.60/million output tokens, and GPT-4.1 nano is $0.10/million input tokens and $0.40/million output tokens.\nAccording to OpenAI\u2019s internal testing, GPT-4.1, which can generate more tokens at once than GPT-4o (32,768 versus 16,384), scored between 52% and 54.6% on SWE-bench Verified, a human-validated subset of SWE-bench. (OpenAI noted in a blog post that some solutions to SWE-bench Verified problems couldn\u2019t run on its infrastructure, hence the range of scores.) Those figures are slightly under the scores reported by Google and Anthropic for Gemini 2.5 Pro (63.8%) and Claude 3.7 Sonnet (62.3%), respectively, on the same benchmark.\nIn a separate evaluation, OpenAI probed GPT-4.1 using Video-MME, which is designed to measure the ability of a model to \u201cunderstand\u201d content in videos. GPT-4.1 reached a chart-topping 72% accuracy on the \u201clong, no subtitles\u201d video category, claims OpenAI.\nWhile GPT-4.1 scores reasonably well on benchmarks and has a more recent \u201cknowledge cutoff,\u201d giving it a better frame of reference for current events (up to June 2024), it\u2019s important to keep in mind that even some of the best models today struggle with tasks that wouldn\u2019t trip up experts. For example,manystudieshaveshownthat code-generating models often fail to fix, and even introduce, security vulnerabilities and bugs.\nOpenAI acknowledges, too, that GPT-4.1 becomes less reliable (i.e., likelier to make mistakes) the more input tokens it has to deal with. On one of the company\u2019s own tests, OpenAI-MRCR, the model\u2019s accuracy decreased from around 84% with 8,000 tokens to 50% with 1 million tokens. GPT-4.1 also tended to be more \u201cliteral\u201d than GPT-4o, says the company, sometimes necessitating more specific, explicit prompts.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/openai-plans-to-wind-down-gpt-4-5-its-largest-ever-ai-model-in-its-api/",
        "date_extracted": "2025-04-16T17:27:29.405457",
        "title": "OpenAI plans to phase out GPT-4.5, its largest-ever AI model, from its API",
        "author": null,
        "publication_date": null,
        "content": "OpenAI said on Monday that it would soon wind down the availability ofGPT-4.5, its largest-ever AI model, via its API. GPT-4.5 was released only in late February.\nDevelopers will have access to GPT-4.5 via OpenAI\u2019s API until July 14, after which they\u2019ll have to transition to another model in OpenAI\u2019s catalog, the company says. OpenAI is positioningGPT-4.1, which launched Monday, as the preferred replacement.\n\u201c[GPT-4.1] offers similar or improved performance than GPT-4.5 in key areas at a much lower cost,\u201d an OpenAI spokesperson told TechCrunch via email. \u201c[W]e will [be] deprecating GPT-4.5 to prioritize building future models.\u201d\nTo be clear, GPT-4.5 isn\u2019t leaving ChatGPT, where it\u2019s available in research preview for paying customers. OpenAI is only phasing it out of the API.\nGPT-4.5,code-named Orion, was trained using more computing power and data than any of OpenAI\u2019s previous releases. It improves upon its predecessor,GPT-4o, in areas such as writing andpersuasiveness, but despite its scale, GPT-4.5 falls short of \u201cfrontier level\u201d on a number of industry benchmarks.\nGPT-4.5 is also very expensive to run, OpenAI admits \u2014 so expensive that the company warned in February that it was evaluating whether to serve GPT-4.5 via its API in the long term. The model\u2019s pricing reflects this: GPT-4.5 costs $75 for every million input tokens (roughly 750,000 words) and $150 per million output tokens, making it one of OpenAI\u2019s costliest offerings.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/googles-newest-ai-model-is-designed-to-help-study-dolphin-speech/",
        "date_extracted": "2025-04-16T17:27:31.724773",
        "title": "Google\u2019s newest AI model is designed to help study dolphin \u2018speech\u2019",
        "author": null,
        "publication_date": null,
        "content": "Google\u2019s AI research lab, Google DeepMind, says that it hascreated an AI modelthat can help decipher dolphin vocalizations, supporting research efforts to better understand how dolphins communicate.\nThe model, called DolphinGemma, was trained using data from the Wild Dolphin Project (WDP), a nonprofit that studies Atlantic spotted dolphins and their behaviors. Built on Google\u2019s open Gemma series of models, DolphinGemma, which can generate \u201cdolphin-like\u201d sound sequences, is efficient enough to run on phones, Google says.\nThis summer, WDP plans to use Google\u2019s Pixel 9 smartphone to power a platform that can create synthetic dolphin vocalizations and listen to dolphin sounds for a matching \u201creply.\u201d WDP previously was using the Pixel 6 to conduct this work, Google says, and upgrading to the Pixel 9 will enable researchers at the organization to run AI models and template-matching algorithms at the same time, according to Google.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/google-classroom-gives-teachers-an-ai-feature-for-quiz-questions/",
        "date_extracted": "2025-04-16T17:27:34.439122",
        "title": "Google Classroom gives teachers an AI feature for quiz questions",
        "author": null,
        "publication_date": null,
        "content": "Google Classroomintroduceda new AI-powered feature designed to help teachers generate questions. Launched on Monday, this tool lets educators create a list of questions based on specific text input.\nUsing this text-dependent question-generation tool, which utilizes Gemini, teachers can either upload files from Google Drive or manually enter text for the AI to generate questions.\u00a0They can then export the questions into a Google Doc or Google Form.\nEducators can choose from a variety of filters, including the grade level, the number of questions, and the type of questions (such as multiple choice or open-ended). Additionally, there is an option for teachers to specify the skills they want their students to demonstrate, such as the use of figurative language or the ability to evaluate arguments.\nThis feature is available only to Google Workspace for Education subscribers who have either the Gemini Education add-on ($24 per user) or Gemini Education Premium ($36 per user).\nGoogle initially launched Gemini to Classroom in 2024 and has since expanded its capabilities. The recent update included a tool for creatingvocabulary lists. It can also generate lesson plan ideas and summarize a range of materials, from class notes to student feedback.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/Text-dependent-questions.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/meta-to-start-training-its-ai-models-on-public-content-in-the-eu/",
        "date_extracted": "2025-04-16T17:27:37.206986",
        "title": "Meta to start training its AI models on public content in the EU",
        "author": null,
        "publication_date": null,
        "content": "Metaannouncedon Monday that it\u2019s going to train its AI models on public content, such as posts and comments on Facebook and Instagram, in the EU after previouslypausing its plans to do soin response to regulatory pressure due to data privacy concerns. The company will start training its AI on users\u2019 content in the EU this week, it said. Users\u2019 interactions with Meta AI will also be used to train its models.\nThe announcement comes after a limited version ofMeta AI launched in the EUlast month, well after its debut in the U.S. and other global markets.\nWhile Meta has beentraining its AIon user-generated content in the U.S. for years, it has faced resistance in the EU due to the bloc\u2019s strict privacy laws, particularly the General Data Protection Regulation (GDPR), which requires a clear legal basis for processing personal data to train AI models.\nMeta saidback in June 2024that it would pause plans to start training its AI systems using user data in the EU and U.K. following pushback from the Irish Data Protection Commission (DPC). The DPC regulates Meta in the EU and was acting on behalf of several data protection authorities across the bloc. InSeptember 2024, Meta said it was restarting efforts to train its AI systems using public\u00a0posts from its U.K. user base.\nFast-forward to today; Meta has announced that it will do so with public posts from its EU user base as well.\n\u201cLast year, we delayed training our large language models using public content while regulators clarified legal requirements,\u201d Meta said in its blog post. \u201cWe welcome the opinion provided by the EDPB in December, which affirmed that our original approach met our legal obligations. Since then, we have engaged constructively with the IDPC and look forward to continuing to bring the full benefits of generative AI to people in Europe.\u201d\nStarting this week, users in the EU will start receiving in-app and email notifications to explain that Meta will start using public data and interactions with Meta AI to train its models. These notifications will include a link to a form that will allow users to opt out of their data being used. Meta says it will honor all objection forms it has already received, as well as newly submitted ones.\nMeta notes that it doesn\u2019t use private messages, nor public data from users under the age of 18 in the EU, to train its models.\n\u201cWe believe we have a responsibility to build AI that\u2019s not just available to Europeans, but is actually built for them,\u201d Meta says. \u201cThat\u2019s why it\u2019s so important for our generative AI models to be trained on a variety of data so they can understand the incredible and diverse nuances and complexities that make up European communities. That means everything from dialects and colloquialisms, to hyper-local knowledge and the distinct ways different countries use humor and sarcasm on our products.\u201d\nMeta says it\u2019s following the example set by companies like Google and OpenAI, both of which have already used data from European users to train their AI models.\nMeanwhile, the DPC is not moving on entirely from scrutinizing how large language model creators are training their AI services. Last week, the regulatorannouncedit was investigating xAI\u2019s training of Grok.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/hugging-face-buys-a-humanoid-robotics-startup/",
        "date_extracted": "2025-04-16T17:27:39.532739",
        "title": "Hugging Face buys a humanoid robotics startup",
        "author": null,
        "publication_date": null,
        "content": "AI dev platform Hugging Face has acquired Pollen Robotics, a robotics startup based in France, for an undisclosed amount.Wired reportsthat Hugging Face plans to sell Pollen\u2019s humanoid robot, Reachy 2, and let developers download and suggest improvements to its code.\nPollen Robotics, which aims to bring affordable humanoid robots to the home, was founded in 2016 by Matthieu Lapeyre and Pierre Rouanet. The company managed to raise \u20ac2.5 million (around $2.83 million) from investors, including Bpifrance, prior to its exit,according to Crunchbase.\nIf you\u2019ve followed the progress of robotics in the past 18 months, you\u2019ve likely noticed how robotics is increasingly becoming the next frontier that AI will unlock.\nAt Hugging Face\u2014in robotics and across all AI fields\u2014we believe in a future where AI and robots are open-source,\u2026\n\u2014 Thomas Wolf (@Thom_Wolf)April 14, 2025\n\nThe acquisition marks an expansion of Hugging Faces\u2019 robotics efforts, with which Pollen was closely involved. Last year, Hugging Face teamed up with Pollen to build \u201cLe Robot,\u201d an open source robot trained to do a variety of household chores. Hugging Face also established a robotics team led by Remi Cadene, a former robotics engineer from Tesla\u2019s Optimus program.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/nvidia-says-it-plans-to-manufacture-some-ai-chips-in-the-u-s/",
        "date_extracted": "2025-04-16T17:27:42.082758",
        "title": "Nvidia says it plans to manufacture some AI chips in the US",
        "author": null,
        "publication_date": null,
        "content": "Nvidiasaid on Monday that it has commissionedmore than a million square feet of manufacturing space to build and test AI chips in Arizona and Texas as part of an effort to move a portion of its production to the U.S.\nThe chipmaker said the production of its Blackwell chips has started at TSMC\u2019s chip plants in Phoenix, Arizona, and that Nvidia is building \u201csupercomputer\u201d manufacturing plants in Texas \u2014 with Foxconn in Houston and with Wistron in Dallas. In Arizona, Nvidia is partnering with Amkor and SPIL for packaging and testing operations, the company added.\nMass production at the Houston and Dallas plants is expected to ramp up in the next 12-15 months, and within the next four years, the company aims to produce up to half-a-trillion dollars of AI infrastructure in the U.S.\n\u201cThe engines of the world\u2019s AI infrastructure are being built in the United States for the first time,\u201d said Nvidia CEO Jensen Huang in a statement. \u201cAdding American manufacturing helps us better meet the incredible and growing demand for AI chips and supercomputers, strengthens our supply chain, and boosts our resiliency.\u201d\nThe announcement comes days afterNvidia reportedly narrowly avoided export controlson its H20 chip after striking a domestic manufacturing deal with the Trump administration.According to NPR, the H20, Nvidia\u2019s most advanced chip that can still be exported to China, was spared thanks to a promise from Huang to pour capital into components for U.S.-based AI data centers.\nMany other AI companies have leaned into Trump\u2019s\u201cAmerica-first\u201d approach to AIin bids to curry favor with the administration. OpenAI teamed up with SoftBank and Oracle for a $500 billion U.S. data center initiative dubbedthe Stargate Projectin January, whileMicrosoft pledged $80 billionto build AI data centers in its 2025 fiscal year, with 50% of that earmarked for the U.S.\nTrump has strong-armed certain partners to get his desired outcome in recent months. Hereportedlytold TSMC that it would have to pay a tax of up to 100% if the company didn\u2019t build new chip factories in the U.S.\nNvidia claimed its U.S. chip manufacturing initiatives could create \u201chundreds of thousands\u201d of jobs and drive \u201ctrillions of dollars\u201d in economic activity over the coming decades. But programs to ramp up the domestic chipmaking industry face formidable \u2014 and growing \u2014 challenges.\nRetaliatory tariffs and trade restrictions from Chinathreaten the supply of necessary raw materials to build chips in the U.S., and there\u2019s asevere shortage of skilled frontline workersfor assembling chips. Meanwhile, the Trump administration\u2019s moves to undermine the Chips Act, a bill passed in 2022 to dole out billions in grants to chipmakers,could deter future investmentsfrom semiconductor giants.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/13/access-to-future-ai-models-in-openais-api-may-require-a-verified-id/",
        "date_extracted": "2025-04-16T17:27:44.789045",
        "title": "Access to future AI models in OpenAI\u2019s API may require a verified ID",
        "author": null,
        "publication_date": null,
        "content": "OpenAI may soon require organizations to complete an ID verification process in order to access certain future AI models,according to a support pagepublished to the company\u2019s website last week.\nThe verification process, called Verified Organization, is \u201ca new way for developers to unlock access to the most advanced models and capabilities on the OpenAI platform,\u201d reads the page. Verification requires a government-issued ID from one of the countries supported by OpenAI\u2019s API. An ID can only verify one organization every 90 days, and not all organizations will be eligible for verification, says OpenAI.\n\u201cAt OpenAI, we take our responsibility seriously to ensure that AI is both broadly accessible and used safely,\u201d reads the page. \u201cUnfortunately, a small minority of developers intentionally use the OpenAI APIs in violation of our usage policies. We\u2019re adding the verification process to mitigate unsafe use of AI while continuing to make advanced models available to the broader developer community.\u201d\nOpenAI released a new Verified Organization status as a new way for developers to unlock access to the most advanced models and capabilities on the platform, and to be ready for the \u201cnext exciting model release\u201d\n\u2013 Verification takes a few minutes and requires a valid\u2026pic.twitter.com/zWZs1Oj8vE\n\u2014 Tibor Blaho (@btibor91)April 12, 2025\n\nThe new verification process could be intended to beef up security around OpenAI\u2019s products as they become more sophisticated and capable. The company haspublished several reportson its efforts to detect and mitigate malicious use of its models, including by groups allegedly based in North Korea.\nIt may also be aimed at preventing IP theft. According to a report from Bloomberg earlier this year,OpenAI was investigating whethera group linked with DeepSeek, the China-based AI lab, exfiltrated large amounts of data through its API in late 2024, possibly for training models \u2014 a violation of OpenAI\u2019s terms.\nOpenAIblocked accessto its services in China last summer.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/12/openai-co-founder-ilya-sutskevers-safe-superintelligence-reportedly-valued-at-32b/",
        "date_extracted": "2025-04-16T17:27:47.204548",
        "title": "OpenAI co-founder Ilya Sutskever\u2019s Safe Superintelligence reportedly valued at $32B",
        "author": null,
        "publication_date": null,
        "content": "Safe Superintelligence (SSI), the AI startup led by OpenAI\u2019s co-founder and former chief scientist Ilya Sutskever, has raised an additional $2 billion in funding at a $32 billion valuation,according to the Financial Times.\nThe startup had alreadyraised $1 billion, and there were reports thatan additional $1 billion roundwas in the works. SSI did not comment on the new funding, which was reportedly led by Greenoaks.\nSutskeverleft OpenAI in May 2024after he appeared to play a role inan ultimately failed attempt to oust CEO Sam Altman. Hefounded SSIwith Daniel Gross and Daniel Levy, and they said the company had \u201cone goal and one product: a safe superintelligence.\u201d\nThat product is presumably still in the works, withSSI\u2019s websitelittle more than a placeholder with a mission statement.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/12/the-xai-x-merger-is-a-good-deal-if-youre-betting-on-musks-empire/",
        "date_extracted": "2025-04-16T17:27:50.121613",
        "title": "The xAI\u2013X merger is a good deal \u2014 if you\u2019re betting on Musk\u2019s empire",
        "author": null,
        "publication_date": null,
        "content": "When Elon Musk announced that his AI startup, xAI, had acquired his social media company, X, in anall-stock deal, it raised some eyebrows. But in many ways, the deal made sense. Grok, xAI\u2019s chatbot, was already deeply integrated with X, which wasfloundering financially, and Musk needed a way to make his $44 billion Twitter acquisition look less like an impulsive takeover and more like a strategic play forAGIdominance.\nIt also pointed to something deeper about how Musk\u2019s empire works: Investing in any one of his companies isn\u2019t about a quick return on investment. It\u2019s about buying into the mysticism around Musk and swallowing whole a narrative of success that outpaces the actual numbers.\nSome call it agrift, pointing to Musk\u2019s history ofoverpromising and underdelivering. But the market is increasingly more tolerant \u2014 welcoming, even \u2014 of narrative-led investments, particularly when the thread that ties the tale together is one of the president\u2019s right-hand men.\n\u201cAll of Elon\u2019s companies today are basically one company,\u201d Yoni Rechtman, a principal at Slow Ventures, told TechCrunch. \u201cIt\u2019s all already Elon, Inc. There are people who work across multiple companies simultaneously. They share a web of capital connections. They do business with one another, and he treats them all effectively as one company. So [the xAI-X merger] just ends some of the fiction that the two businesses were separate.\u201d\nThe thinking among Musk bulls like Ron Baron, the founder of investment management firm Baron Capital, is that \u201cevery single thing [Musk] does is helping everything else he does,\u201d as Baronphrased it. Other businesses under Musk\u2019s control include Tesla, SpaceX, The Boring Company, and Neuralink \u2014 some of whichreportedly share resources. Baron says:\nWhen [Musk] bought Twitter, did he have in his mind that there\u2019s an opportunity to have this data, a tremendous value for licensing? When he decided he wanted to go to Mars with SpaceX, did he really think initially that there\u2019s a real opportunity here for the internet around the world, and there\u2019s gonna be hundreds of billions of dollars of revenue opportunity? When he started off with EVs for Tesla, did he really think that this is gonna merge into self-driving, where you can make hundreds of billions of dollars a year of extra profits, and Grok\u00a0\u2026 and you\u2019re gonna have connected cars all around the world?\u00a0\u2026 All these businesses link up. It\u2019s the ecosystem. It\u2019s the Elon ecosystem, and I think it\u2019s really interesting when you look at it that way.\nBaron Capital has invested across Musk\u2019s ecosystem, an example of the investor crossover between the billionaire\u2019s various companies. Firms like 8VC, Andreessen Horowitz, DFJ Growth, Fidelity Investments, Manhattan Venture Partners, Saudi Arabia\u2019s PIF, Sequoia Capital, Vy Capital, and others also hold positions throughout Musk\u2019s corporate web.\nThat brings us back to the xAI-X deal. Pundits questioned how the acquisition could value X at $33 billion,more than triple its valuationjust a few months ago, and how it could value xAI at $80 billion considering the AI companyreportedlyhas little in the way of revenue. But valuations aren\u2019t always based on what exists today. Rather, they take into account what investors are hoping for \u2014 and that\u2019s particularly true when it comes to Musk\u2019s ventures.\nJust look at Tesla. The electric vehicle maker has been treated like a tech stock for years even though it hasautomaker margins, based largely on the belief that Tesla will one day unlock groundbreaking autonomy in the form of self-driving cars and humanoid robots.\n\u201cThe reason why [Tesla\u2019s] stock trades at 80 times earnings and the comp group trades at 25 times earnings is that people are making a bet on the long term, and it\u2019s not about what happens to numbers this year,\u201d Gene Munster, managing partner at Deepwater Asset Management, told TechCrunch. \u201cThat\u2019s one of Elon\u2019s superpowers, this ability to keep investors engaged for the long term.\u201d\nMunster\u2019s firm has invested in X, xAI, and Tesla. It\u2019s exactly the type of all-in Musk backer that stands to benefit the most from a deal like xAI buying X, assuming Musk can indeed deliver on his pledge of marrying X\u2019s real-time data trove and distribution platform with xAI\u2019s infrastructure and AI expertise.\nOf course, consolidated value also comes with increased risk.\nDan Wang, a professor at Columbia Business School whose research lies at the intersection of business and society, told TechCrunch that the biggest immediate risk factor for investors is the ongoing lawsuit that X is facing from the Securities and Exchange Commission (SEC). The suit accuses Musk of misleading investors by delaying the disclosure of his previous investments in Twitter. The SEC has argued that this allowed Musk to buy more Twitter shares at artificially low prices.\nWang listed a few other risk considerations, such as anticompetition and user privacy concerns, particularly regarding how X quietly opted all users into data collection for AI model training. The opt-in change has already raised the ire of one regulator,Ireland\u2019s DPC, which recently began investigating it as a potential breach of Europe\u2019s GDPR law.\n\u201cAnother kind of risk here is that there isn\u2019t a consensus framework for how the AI market is going to be regulated, but you\u2019re already seeing traces of this in Europe and, up until recently, in California,\u201d Wang said. \u201cA lot of these frameworks have to do with how AI models are deployed in terms of distributing information\u00a0\u2026  They ascribe responsibility to the companies that are creating AI models, as well as providing access to those models.\u201d\nMusk might also simply lose interest in a project, Rechtman said.\n\u201cI think that is what a lot of Tesla shareholders are feeling right now,\u201d he said, \u201cwhere for the last several months, Elon\u2019s number one company has been the Trump campaign, and his other projects have languished.\u201d\nWhen asked about some of these risk factors, Munster appeared nonplussed. He suggested they\u2019re inconsequential given the enormity of, for example, xAI\u2019s value proposition and potential to become a dominant player in AI.\n\u201cWe\u2019re betting the firm on the belief that AI is going to be more transformative than what people think,\u201d he said. \u201cWhat is the value\u00a0\u2026 of one of the four brains that the world is going to run on?\u201d\nRechtman said that Musk bulls aren\u2019t blindly loyal, per se, but simply trust in Musk\u2019s superpower to \u201cbend capital markets to his will\u201d in a way that allows him to do things and build businesses that nobody else can.\n\u201cThe people who are in these businesses have just gone long Elon, and they will continue to go long Elon,\u201d Rechtman said. \u201cSo it\u2019s not surprising to me that they will just continue to tell you that the emperor is wearing clothes.\u201d\nNot for nothing, buying into Musk\u2019s more speculative bets, like X, is one way to potentially unlock more investment opportunities in the Muskverse, Rechtman said.\n\u201cSpaceX is a real thing, and it will never go public,\u201d he said. \u201cSo the only way to invest in SpaceX is to get access to the tenders. And the only way to get access to the tenders is to be in Elon\u2019s good graces.\u201d",
        "tags": [],
        "images": []
    }
]