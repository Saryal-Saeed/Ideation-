[
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/16/hammerspace-an-unstructured-data-wrangler-used-by-nvidia-meta-and-tesla-raises-100m-at-500m-valuation/",
        "date_extracted": "2025-04-16T17:26:36.679624",
        "title": "Hammerspace, an unstructured data wrangler used by Nvidia, Meta and Tesla, raises $100M at $500M+ valuation",
        "author": null,
        "publication_date": null,
        "content": "Artificial intelligence services at their heart are massive data plays: you need data \u2014 a lot of it \u2014 to build the models, and then the models need efficient ways to ingest and output data to work.\nA company calledHammerspacehas built a system to help AI and other organisations tap into data troves with minimal heavy lifting, and it\u2019s been seeing impressive adoption. Now, withcustomersincluding NVIDIA, Meta, Tesla, Palantir and the Department of Defense as well as other very recognisable names, Hammerspace is announcing $100 million in funding to expand its business.\nThe funding is being described as a \u201cstrategic venture round,\u201d and it values Hammerspace at over $500 million, sources close to the company told TechCrunch. Its backers include Altimeter Capital and ARK Invest, alongside strategic investors that are not being disclosed. The investors are being described as \u201chighly participatory.\u201d\nThe funding is notable because it points to the ecosystem developing around the value that the market sees in AI companies, which are raising billions of dollars both to build their capital-intensive businesses and meet massive demand.\nBut as Jamin Ball, a partner at Altimeter, noted, \u201cYou don\u2019t have an AI strategy without a data strategy.\u201d So a company that is building a platform to enable that data strategy can itself become very valuable, too.\nHammerspace said much of its growth so far has been through word-of-mouth. It will be using a portion of this funding to expand on that more proactively with sales and marketing.\nHammerspacepreviously raised $56 millionfrom Prosperity7 Ventures (the venture arm of Saudi Aramco), ARK Invest, Pier 88 Hedge Fund, and other unnamed investors. Prior to that, it was self-funded by its CEO and co-founderDavid Flynn, the pioneer technologist known for his early work on Linux, supercomputers and flash computing.\nThere are a vast number of companies that have set out to plug the big gap that exists in the data market today. \u201cVast\u201d is an operative word here, as it is one of the companies that competes with Hammerspace, along with Dell, Pure Storage, Weka and many others in the worlds of data orchestration, file management, data pipeline, and data management.\nThat gap goes something like this: The apps and other digital services we use to work and do everything else in life these days produce a lot of potentially valuable data. But data troves exist in silos \u2014 they\u2019re fragmented, stored across multiple (competing) clouds and other environments, and are often unstructured. That makes them a challenge to use.\nThis gap applies across a wide range of enterprise use cases, but perhaps the biggest of these at the moment is AI.\n\u201cAI has been the perfect storm for needing what I have built,\u201d Flynn said in an interview.\nHammerspace, as we\u2019ve noted before, is named afterthe conceptfirst coined from cartoons and comics, where characters pull objects they need out of thin air.\nThis is, in effect, what Hammerspace does. The startup provides a way of making large amounts of data, regardless of where it lives or how it is used, accessible and available to an organization just when they need it, and keeping it out of the way when they do not.\nAs Flynn describes it, typically the way that enterprises would have worked with data would be to port it from wherever it is to where it needs to be processed. \u201cYou need to install stuff on every system,\u201d he said. \u201cIt\u2019s a mess.\u201d\nIt\u2019s also slow. \u201cThe AI arms race is such a sprint,\u201d he said. With \u201ctime to value\u201d now a key priority for these companies, Hammerspace is signing up a lot of customers that are anxious about idle time.\nFlynn\u2019s background in flash computing is central to Hammerspace\u2019s breakthrough. Built on Linux, ubiquitous in the database world, he could see that the key to organising data across disparate locations was to create a file system to do so.\nThe heart of this is the Linux kernel NFS client, ubiquitous across many of the data systems. Hammerspace\u2019s co-founder and CTOTrond Myklebustwas the lead developer of the Linux kernel NFS client, and the startup remains its lead maintainer. The \u201cfile system\u201d that the company has built for managing, moving and orchestrating data is based on a particular implementation in Linux that taps this. What it does, Flynn said, \u201cis unique across the industry.\u201d\nLonger term, Flynnsaid last yearthat Hammerspace may go public as early as this year.\u00a0That timeline has changed now but the direction has not.\u00a0\u201cYes, IPO is absolutely the Hammerspace intended strategy,\u201d Flynn said. \u201cWe likely are still approximately two years out (dependent on market conditions).\u201d\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/16/google-used-ai-to-suspend-over-39m-ad-accounts-committing-fraud/",
        "date_extracted": "2025-04-16T17:26:39.115854",
        "title": "Google used AI to suspend over 39M ad accounts suspected of fraud",
        "author": null,
        "publication_date": null,
        "content": "Google on Wednesday said it suspended 39.2 million advertiser accounts on its platform in 2024  \u2014\u00a0more than triple the number from the previous year \u2014\u00a0in its latest crackdown on ad fraud.\nBy leveraging large language models (LLMs) and using signals such as business impersonation and illegitimate payment details, the search giant said it could suspend a \u201cvast majority\u201d of ad accounts before they ever served an ad.\nLast year, Google launched over 50 LLM enhancements to enhance its safety enforcement mechanisms across all its platforms.\n\u201cWhile these AI models are very, very important to us and have delivered a series of impressive improvements, we still have humans involved throughout the process,\u201d said Alex Rodriguez, a general manager for Ads Safety at Google, in a virtual media roundtable.\nThe executive told reporters that a team of over 100 experts assembled across Google, including members from the Ads Safety team, the Trust and Safety division, and researchers from DeepMind. They analyzed deepfake ad scams involving public figure impersonations and developed countermeasures.\nThe company introduced technical countermeasures and over 30 ads and publisher policy updates last year. These moves helped suspend over 700,000 offending advertising accounts, leading to a 90% drop in reports of deepfake ads, the company claims.\nIn the U.S. alone, Google said it suspended 39.2 million advertiser accounts and took down 1.8 billion ads last year, with key violations tied to ad network abuse, trademark misuse, healthcare claims, personalized ads, and misrepresentation.\nIndia, the world\u2019s most populous country and the second biggest internet market after China in terms of users, saw 2.9 million account suspensions last year, Google said, making it the second-highest after the U.S. The company also removed 247.4 million ads in India, with the top five policy violations related to financial services, trademark misuse, ad network abuse, personalized ads, and gambling and games.\nOf all the advertiser account suspensions, Google said it suspended 5 million accounts for scam-related violations.\nOverall, the company removed almost half a billion ads related to scams.\nGoogle also verified more than 8,900 new election advertisers in 2024, which saw half of the world\u2019s population go to the polls, and removed 10.7 million election ads. However, Rodriguez noted that the volume of election ads compared to Google\u2019s overall ad numbers was relatively small and would not significantly impact its safety metrics this year.\nIn total, Google said it blocked 5.1 billion ads last year and removed 1.3 billion pages. In comparison, itblockedover 5.5 billion ads and took action against 2.1 billion publisher pages in 2023.\nGoogle told TechCrunch that the decreasing numbers indicated improvements in its prevention efforts. By improving early detection and suspension of malicious accounts, fewer harmful ads are produced or reach the platform, the company said.\nThe company also restricted 9.1 billion ads last year, it said.\nImportantly, large-scale suspensions sometimes spark concerns over how fairly a company applies its rules. Google said it offers an appeal process that includes human reviews to ensure it took \u201cappropriate action.\u201d\n\u201cOftentimes, some of our message wasn\u2019t as clear and transparent about specifics, about what the rationale was, or reasoning, and sometimes that left the advertiser a little more confused. We ended up updating a bunch of our policies as it related to that, a bunch of our transparency capabilities in terms of the messaging around what and why to help the advertiser\u2026It\u2019s been a big focus for the team as part of 2024 and into 2025,\u201d Rodriguez said.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/ad-account-suspensions-20241.jpg",
            "https://techcrunch.com/wp-content/uploads/2025/04/google-ad-blocked-20241.jpg"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/grok-gains-a-canvas-like-tool-for-creating-docs-and-apps/",
        "date_extracted": "2025-04-16T17:26:41.852368",
        "title": "Grok gains a canvas-like tool for creating docs and apps",
        "author": null,
        "publication_date": null,
        "content": "Grok, the chatbot from Elon Musk\u2019s AI company, xAI, has gained a canvas-like feature for editing and creating documents and basic apps.\nCalled Grok Studio, the feature was announced on X late Tuesday. It\u2019s available for both free and paying Grok users on Grok.com\n\u201cGrok can now generate documents, code, reports and browser games,\u201dwrote the official Grok account on X. \u201cGrok Studio will open your content in a separate window, allowing both you and Grok to collaborate on the content together.\u201d\nToday, we are releasing the first version of Grok studio, adding code execution and google drive support.\nGrok StudioGrok can now generate documents, code, reports, and browser games. Grok Studio will open your content in a separate window, allowing both you and Grok to\u2026pic.twitter.com/lyQh06F8eP\n\u2014 Grok (@grok)April 16, 2025\n\nGrok is the latest chatbot to get a dedicated workspace for tinkering with software and writing projects. OpenAI launched a similar capability,Canvas, for ChatGPT in October. Anthropic was one of the first to the punch, withArtifactsfor Claude.\nGrok Studio doesn\u2019t seem materially different from the canvas-like tools that\u2019ve come before it. It lets you preview HTML snippets and run code in programming languages like Python, C++, and JavaScript. All content opens in a window to the right-hand side of Grok\u2019s responses.\nGrok Studio is made potentially more useful by another Grok upgrade announced today: integration with Google Drive. Now, you can attach files from a Google Drive account to a Grok prompt. Grok can work with documents, spreadsheets and slides, according to xAI.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/nvidia-h20-chip-exports-hit-with-license-requirement-by-us-government/",
        "date_extracted": "2025-04-16T17:26:44.288285",
        "title": "Nvidia H20 chip exports hit with license requirement by US government",
        "author": null,
        "publication_date": null,
        "content": "Semiconductor giant Nvidia is facing unexpected new U.S. export controls on its H20 chips.\nIn a filing Tuesday, Nvidia said it was informed by the U.S. government that it will need a license to export its H20 AI chips to China. This license will be required indefinitely, according to the filing \u2014 the U.S. government cited \u201crisk that the [H20] may be used in [\u2026] a supercomputer in China.\u201d\nNvidia anticipates $5.5 billion in related charges in its Q1 2026 fiscal year, which ends April 27. The company\u2019s stock was down around 6% in extended trading.\nThe H20 is the most advanced AI chip Nvidia can export to China under the U.S.\u2019 current and previous export rules. Last week,NPRreported that CEO Jensen Huang might havetalked his way outof new H20 restrictions during a dinner at President Donald Trump\u2019s Mar-a-Lago resort, in part by committing that Nvidia would invest in AI data centers in the U.S.\nPerhaps not-so-coincidentally, Nvidiaannounced on Mondaythat it would spend hundreds of millions of dollars over the next four years manufacturing some AI chips in the U.S.Punditswere quick to point out that the company\u2019s commitment was light on the details.\nMultiple government officials had been calling for stronger export controls on the H20 because the chip was allegedly used to train models from China-based AI startup DeepSeek, including the R1 \u201creasoning\u201d model that threw the U.S. AI market for a loop in January.\nNvidia declined to comment.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/telli-a-yc-alum-raises-pre-seed-funding-for-its-ai-voice-agents/",
        "date_extracted": "2025-04-16T17:26:46.752292",
        "title": "Telli, a YC alum, raises pre-seed funding for its AI voice agents",
        "author": null,
        "publication_date": null,
        "content": "Former Y Combinator startupTelliis helping companies alleviate the bottleneck that occurs when a high-volume of customers try to, for example, book appointments. Its AI voice agents kick in and handle basic operations while handing off more-complex processes to human operators. The Berlin-based startup has now raised $3.6 million in a pre-seed funding\u00a0round led by Berlin\u2019s Cherry Ventures and Y Combinator.\nTelli\u00a0says its AI voice agents can perform a number of tasks, including automated callbacks and even closing deals.\nThe startup, which was founded by\u00a0Seb Hapte-Selassie, Philipp Baumanns, and Finn zur M\u00fchlen, has concentrated on making its agents blend into company operations.\nIt\u2019s now claiming to have reached revenue growth of more than 50% month over month and has processed close to a million phone calls (and all with only a six-person team) out of the Berlin office.\u00a0Customers are spread across Germany, the U.K., Latin America, and the U.S., with plans for further expansion.\nCEO zur M\u00fchlen told TechCrunch that the founders got the idea after working at German unicorn Enpal, one of Germany\u2019s biggest startup successes: \u201cWe scaled the customer service people, and we saw firsthand how difficult call automation for customer acquisition is and how difficult it is to manage performance.\u201d\nHe said that Telli\u2019s AI agents \u201cactually achieve outcomes like booking appointments, prequalifying leads, making product suggestions, and so on.\u201d The voices are created by hired voice actors, whose voices are then cloned using the ElevenLabs or Cartesian AI voice-cloning platforms, he said.\nThe underlying AI models Telli uses vary between OpenAI, Claude, and others: \u201cWe switch around. Our goal is always to give our customers the best solutions that are out there right now,\u201d he said.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/openai-says-it-may-adjust-its-safety-requirements-if-a-rival-lab-releases-high-risk-ai/",
        "date_extracted": "2025-04-16T17:26:49.179585",
        "title": "OpenAI may \u2018adjust\u2019 its safeguards if rivals release \u2018high-risk\u2019 AI",
        "author": null,
        "publication_date": null,
        "content": "OpenAI hasupdatedits Preparedness Framework \u2014 the internal system it uses to assess the safety of AI models and determine necessary safeguards during development and deployment. In the update, OpenAI stated that it may \u201cadjust\u201d its safety requirements if a competing AI lab releases a \u201chigh-risk\u201d system without similar protections in place.\nThe change reflects the increasing competitive pressures on commercial AI developers to deploy models quickly. OpenAI has beenaccused of lowering safety standardsin favor of faster releases, and of failing to delivertimely reports detailing its safety testing.\u00a0Last week, 12 former OpenAI employeesfiled a briefin Elon Musk\u2019s case against OpenAI, arguing the company would be encouraged to cuteven morecorners on safety should it complete its planned corporate restructuring.\nPerhaps anticipating criticism, OpenAI claims that it wouldn\u2019t make these policy adjustments lightly, and that it would keep its safeguards at \u201ca level more protective.\u201d\n\u201cIf another frontier AI developer releases a high-risk system without comparable safeguards, we may adjust our requirements,\u201d wrote OpenAI in ablog postpublished Tuesday afternoon. \u201cHowever, we would first rigorously confirm that the risk landscape has actually changed, publicly acknowledge that we are making an adjustment, assess that the adjustment does not meaningfully increase the overall risk of severe harm, and still keep safeguards at a level more protective.\u201d\nThe refreshed Preparedness Framework also makes clear that OpenAI is relying more heavily on automated evaluations to speed up product development. The company says that while it hasn\u2019t abandoned human-led testing altogether, it has built \u201ca growing suite of automated evaluations\u201d that can supposedly \u201ckeep up with [a] faster [release] cadence.\u201d\nSome reports contradict this.According to the Financial Times, OpenAI gave testers less than a week for safety checks for an upcoming major model \u2014 a compressed timeline compared to previous releases. The publication\u2019s sources also alleged that many of OpenAI\u2019s safety tests are now conducted on earlier versions of models rather than the versions released to the public.\nIn statements, OpenAI has disputed the notion that it\u2019s compromising on safety.\nOpenAI is quietly reducing its safety commitments.\nOmitted from OpenAI\u2019s list of Preparedness Framework changes:\nNo longer requiring safety tests of finetuned modelshttps://t.co/oTmEiAtSjS\n\u2014 Steven Adler (@sjgadler)April 15, 2025\n\nOther changes to OpenAI\u2019s framework pertain to how the company categorizes models according to risk, including models that can conceal their capabilities, evade safeguards, prevent their shutdown, and even self-replicate. OpenAI says that it\u2019ll now focus on whether models meet one of two thresholds: \u201chigh\u201d capability or \u201ccritical\u201d capability.\nOpenAI\u2019s definition of the former is a model that could \u201camplify existing pathways to severe harm.\u201d The latter are models that \u201cintroduce unprecedented new pathways to severe harm,\u201d per the company.\n\u201cCovered systems that reach high capability must have safeguards that sufficiently minimize the associated risk of severe harm before they are deployed,\u201d wrote OpenAI in its blog post. \u201cSystems that reach critical capability also require safeguards that sufficiently minimize associated risks during development.\u201d\nThe updates are the first OpenAI has made to the Preparedness Framework since 2023.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/figma-sent-a-cease-and-desist-letter-to-lovable-over-the-term-dev-mode/",
        "date_extracted": "2025-04-16T17:26:51.724969",
        "title": "Figma sent a cease-and-desist letter to Lovable over the term \u2018Dev Mode\u2019",
        "author": null,
        "publication_date": null,
        "content": "We may be witnessing the makings of a new tech industry feud between competitors. Figma has sent a cease-and-desist letter to popular no-code AI startup Lovable, Figma confirmed to TechCrunch.\nThe letter tells Lovable to stop using the term \u201cDev Mode\u201d for a new product feature. Figma, which also has a feature called Dev Mode, successfully trademarked that term last year, accordingto the U.S. Patent and Trademark office.\nWhat\u2019s wild is that \u201cdev mode\u201d is a common term used in many products that cater to software programmers. It\u2019s like an edit mode. Software products from giant companies likeApple\u2019s iOS,Google\u2019s Chrome,Microsoft\u2019s Xboxhave features formally called \u201cdeveloper mode\u201d that then get nicknamed \u201cdev mode\u201d in reference materials.\nEven \u201cdev mode\u201d itself is commonly used. For instanceAtlassian used it in products that pre-date Figma\u2019s copyright by years. And it\u2019sa common feature namein countless open source software projects.\nFigma tells TechCrunch that its trademark refers only to the shortcut \u201cDev Mode\u201d \u2013 not the full term \u201cdeveloper mode.\u201d Still, it\u2019s a bit like trademarking the term \u201cbug\u201d to refer to \u201cdebugging.\u201d\nSince Figma wants to own the term, it has little choice but send cease-and-desist letters. (The letter, as manyon X pointed out, was very polite, too.) If Figma doesn\u2019t defend the term, it could be absorbed as a generic term and the trademarked becomes unenforceable.\nSome on the internet argue that this term is already generic, should never have been allowed to be trademarked, and say Lovable should fight.\nLovable\u2019s co-founder and CEO, Anton Osika, tells TechCrunch that, for now, his company has no intention of honoring Figma\u2019s demand and changing the feature\u2019s name.\nWe\u2019ll see if Figma escalates. It also has other things on its mind. On Tuesday,Figma announced it had filed confidential paperwork for an IPO.However, should Figma pursue legal action, taking on an international legal battle might be pricey for the early-stage Swedish startup, Lovable,which raised a $15 million seed round in February.\nWhat\u2019s more interesting is that Lovable is one of the rising stars of so-called \u201cvibe coding.\u201d That\u2019s where\u00a0users can describe what they want in a text prompt and the product builds it \u2013 complete with code. Its \u201cdev mode\u201d feature was launched a few weeks ago to allow users to edit that code.\nLovable advertises itself as a competitor to Figma, declaring onits homepagethat designers can use Lovable \u201cwithout tedious prototyping work in tools like Figma.\u201d\u00a0 And manynewly launched startups are doing just that.\nSo this isn\u2019t just a trademark dispute. It is also a bigger competitor cracking its knuckles at a pesky upstart. Figma wasvalued at $12.5 billionabout a year ago.\nA Figma spokesperson almost admits as much. The person told TechCrunch that Figma has not sent cease-and-desist letters to other tech companies over the term, like Microsoft, because their products are \u201cin a different category of goods and services.\u201d\nAnd Lovable\u2019s Osika is ready to throw a few punches of his own telling TechCrunch that he thinks \u201cFigma should focus on making their product great\u201d and not on trademark marketing. He also tells TechCrunch that Lovable is successfully winning customers away from Figma and other such design tools created in the era before LLMs.\nAs for the overall threat of vibe coding products,in a conversationlast month with Y Combinator\u2019s Garry Tan, Figma co-founder CEO Dylan Field naturally pooh-poohed the idea.\nField said that even though people like vibe coding for its speed, \u201cyou also want to give people a way to not just get started and prototype rapidly but also get to the finish line. That\u2019s where the disconnect is, and not just for design, but also for code.\u201d\nStill Osika also seems ready to compete. When he shared a copy of the Figma\u2019s letter on X, he usedthe grinning emoji.\nNote: This story has been updated with comments from Lovable.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/openai-hires-team-behind-gv-backed-ai-eval-platform-context-ai/",
        "date_extracted": "2025-04-16T17:26:54.424188",
        "title": "OpenAI hires team behind GV-backed AI eval platform Context.ai",
        "author": null,
        "publication_date": null,
        "content": "Context.ai, a startup building evaluations and analytics for AI models, announced Tuesday that its co-founders will join OpenAI.\nContext.ai plans to wind down its products following the acqui-hire, per a message on the company\u2019s website. When reached for comment, OpenAI declined to reveal the terms of the deal.\n\u201cEvals are a requirement to building high-performing AI applications, but they\u2019re hard to get right today,\u201d reads the message. \u201cWe spent two years building evals and analytics for [models] at Context.ai \u2014 with a few pivots along the way. We couldn\u2019t be more excited for this next chapter of our journey at OpenAI and are grateful to everyone who played a part.\u201d\nContext.ai was founded in 2023 by former Googlers Henry Scott-Green (CEO) and Alex Gamble (CTO). The startup raised$3.5 million in seed fundingfrom GV and Theory Ventures that same year.\nOne of Context.ai\u2019s flagship products was a dashboard customers could use to dig into the data generated by a model and figure out if it\u2019s producing content that truly helps answer queries. Context.ai users could share transcripts via an API, which Context.ai would then analyze to group and tag based on subject.\n\u201cThe phrase that I always hear is that \u2018my model is a black box,\u2019\u201d Scott-Green told TechCrunch in a 2023 interview. \u201cWe\u2019ve spoken to hundreds of developers who are building [models], and they have a really consistent set of problems. Those problems are that they don\u2019t understand how people are using their model, and they don\u2019t understand how their model is performing.\u201d\nContext.ai had six employees as of August 2023. It\u2019s unclear how large the team is today, and whether every staffer will be offered a job at OpenAI.\nIn apost on X, Scott-Green said that he and Gamble will be creating \u201cthe tools developers need to succeed\u201d at OpenAI, with a focus on model evaluations. According toScott-Green\u2019s LinkedIn profile, he\u2019s now a product manager at OpenAI \u201cbuilding evals.\u201d\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/anthropic-forms-a-new-team-to-grow-its-aws-business/",
        "date_extracted": "2025-04-16T17:26:56.726923",
        "title": "Anthropic forms a new team to grow its AWS business",
        "author": null,
        "publication_date": null,
        "content": "In a sign of Anthropic\u2019s increasingly cozy relationship with Amazon, Anthropic has formed a new team to recruit AWS customers to use its AI products.\nThe team, which Anthropic appears to have begun hiring several months ago, aims to \u201caccelerate\u201d the adoption of Anthropic\u2019s AI among AWS accounts by \u201cbuilding programs that [\u2026] scale across global markets and segments.\u201d That\u2019s according tojoblistingsonAnthropic\u2019s websiteand job boards around the web.\n\u201c[Y]ou will own and scale one of our most significant strategic relationships, leading a team responsible for multi-billion dollar revenue opportunities through our AWS partnership,\u201d reads alisting for a Head of Amazon GTM Partnership role. \u201cYou will work closely with senior leadership across both organizations to drive joint success [and] shape strategy.\u201d\nAmazon is a major backer of Anthropic,having committed $8 billionin capital to the startup to date. While the company has no governance rights and is a minority investor, Amazon is Anthropic\u2019s \u201cprimary\u201d training partner,providing in-house chipsto help Anthropic develop its AI models.\nAnthropic has also optimized its models to run on AWS infrastructure,releasing models with capabilities exclusive to Bedrock, AWS\u2019 AI development platform. And the company has launched collaborations with Amazon partners, including Accenture andPalantir, to facilitate access to its AI tech through AWS.\nAnthropic CEO Dario Amodei said in November that Anthropic\u2019s Claude family of models was being used by \u201ctens of thousands\u201d of Bedrock customers.\nAmazon, which is leveraging Anthropic technology to power components of its revamped Alexa experience,Alexa+, no doubt sees Anthropic as important to its overall AI business\u2019 growth. Amazon CEO Andy Jassy recentlyclaimedthat Amazon\u2019s AI revenue is growing at \u201ctriple-digit\u201d year-over-year percentages\u00a0and represents a \u201cmulti-billion-dollar annual revenue run rate.\u201d\nAnthropic, meanwhile, stands to benefit from AWS\u2019 reach as it looks to grow its own revenue. The startup isreportedlyaiming to notch $12 billion in revenue in 2027, up from a projected $2.2 billion this year.\nAmazon\u2019s dealings with Anthropic have attracted some regulatory scrutiny.\nThe FTC last year sent a letter to Amazon, as well as to Microsoft and Google,requiringthe companies to explain the impacts their investments in startups such as Anthropic have on the competitive AI landscape. Google has alsoinvestedin Anthropic, pouring billions into the company over multiple funding rounds.\nThe U.K.\u2019s Competition and Markets Authority (CMA) has also investigated Amazon\u2019s partnership with Anthropic, looking at whether key aspects would result in \u201cAmazon having material influence\u201d over the latter.\nThe FTCthis year published a report findingthat AI investments by Big Tech firms can create lock-in and reveal sensitive information that can undermine competition, but stopped short of recommending enforcement action. The CMA, for its part,concludedthat Amazon\u2019s partnership and equity investment in Anthropic can\u2019t be investigated under current merger rules due to the size and scope of the deal.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/anthropics-claude-now-read-your-gmail/",
        "date_extracted": "2025-04-16T17:26:59.124500",
        "title": "Anthropic\u2019s Claude can now read your Gmail",
        "author": null,
        "publication_date": null,
        "content": "Anthropic announced on Tuesday that its AI chatbot, Claude, now integrates with Google Workspace, allowing it to search and reference your emails in Gmail, scheduled events in Google Calendar, and documents in Google Docs.\nThe integration is rolling out in beta first to subscribers to Anthropic\u2019s Max, Team, Enterprise, and Pro plans. Administrators managing multi-user accounts must enable the integration on their end before users can connect their Google Workspace and Claude accounts, according to Anthropic.\nGoogle DeepMind\u2019sGemini chatbot also integrates with Workspace, and OpenAI\u2019s ChatGPT integrates with Google Drive. However, Anthropic is one of the first third-party AI companies to offer a way to closely connect to Google\u2019s productivity suite.\nAnthropic\u2019s team-up with Google aims to give Claude more personally tailored responses without requiring users to repeatedly upload files or craft detailed prompts. OpenAI and Google have tried achieving the same effect via different approaches, such as addingmemory featuresthat allow chatbots to reference past conversations in their replies.\nIn a press release, Anthropic says Claude\u2019s new integration can help users organize their professional and personal lives. For example, Anthropic claims the feature can assist parents by scanning \u201cemails and calendar events to highlight important commitments, while searching the web for updated school calendars, local community events, and weather forecasts that might affect family plans.\u201d\nClaude will provide in-line citations when it references Workspace content, showing users exactly where specific information originated, says Anthropic.\nWhile the integration doesn\u2019t give Claude the ability to schedule calendar events or send emails, it may raise security concerns among some users. It\u2019s unclear how extensively Claude will search through a person\u2019s Google Workspace, or whether users have to direct Claude to look at a particular email or calendar event depending on the nature of their request. It\u2019s also not clear whether users can ask Claude not to search across certain sensitive emails or files.\nResponding to the above, an Anthropic spokesperson told TechCrunch that the company doesn\u2019t train models on user data by default and has implemented \u201cstrict authentication and access control mechanisms\u201d for external services like Workspace.\n\u201cEach user or organization\u2019s connections to external services (like Google Drive, Gmail, etc.) are properly authenticated and authorized for only that specific user or organization,\u201d the spokesperson said in a statement. \u201cClaude doesn\u2019t have the ability to access or transfer data between different users\u2019 connected services, as each connection is bound to the specific authentication credentials of that individual user or organization.\u201d\nAnthropic also announced on Tuesday the launch of Claude Research, a new feature that conducts multiple web searches to generate detailed answers. Positioned as a competitor to OpenAI and Google\u2019s \u201cdeep research\u201d agents, Claude Research offers an \u201coptimal tradeoff\u201d between speed and comprehensiveness, Anthropic says.\nClaude Research typically runs for less than a minute to compile info, according to an Anthropic spokesperson \u2014 faster than some rival deep research agents. However, Claude Research doesn\u2019t use a custom model, instead leveraging Claude\u2019s recently launched web search capabilities.\nThe company is rolling out Claude Research to subscribers to its Max, Team, and Enterprise plans in the United States, Japan, and Brazil. It\u2019ll come to Pro customers soon, Anthropic says.\nThese updates are part of Anthropic\u2019s broader effort to attract users to its AI subscription plans with features that make Claude more capable and useful. WhileClaude is growing in popularity, reaching 3.3 million web users in March, according to data compiled by SimilarWeb, Anthropic\u2019s user base is still dwarfed by ChatGPT\u2019s.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/googles-veo-2-video-generator-comes-to-gemini/",
        "date_extracted": "2025-04-16T17:27:01.418273",
        "title": "Google\u2019s Veo 2 video generating model comes to Gemini",
        "author": null,
        "publication_date": null,
        "content": "Google is bringing itsVeo 2video-generating AI model to users who pay for Gemini Advanced, the company\u2019s premium AI plan.\nThe expansion comes as Google looks to deliver an answer to OpenAI\u2019s Sora video generation platform, and as competition in the space grows fiercer. Two weeks ago, one of the more formidable synthetic media companies, Runway, released thefourth generation of its video generatorandraised more than $300 millionin new capital.\nStarting Tuesday, Gemini Advanced subscribers will be able to select Veo\u00a02\u00a0from the model drop-down menu in Google\u2019sGeminiapps. Users can create eight-second video clips at 720p resolution with a 16:9 aspect ratio, and upload these clips to TikTok, YouTube, and more via Gemini\u2019s \u201cshare\u201d button. Veo 2-generated videos can also be downloaded as MP4 files, watermarked with Google\u2019s SynthID tech.\nThere\u2019s a limit to how many videos users can create each month, and the Google Workspace business and education plans aren\u2019t supported at the moment, the company says.\nGoogle is also integrating Veo 2 with Whisk, an experimental feature in Google Labs that lets you use images as prompts with Gemini to create new images. A new feature, Whisk Animate, lets users take images they\u2019ve generated and turn them into eight-second, Veo 2-generated videos. (Google Labs is Google\u2019s platform for early-stage AI products, gated behind the company\u2019s $20-per-month Google One AI Premium subscription.)\nGoogle\u2019s applications of Veo 2 may seem fairly basic at the moment. But the CEO of Google DeepMind, Demis Hassabis,recently saidthat the company plans to eventually combine itsGeminiAI models withVeotoimprove the former\u2019s understanding of the physical world.\nIn the meantime, many artists and creators are wary of video generators like Veo 2, which threaten to upend entire creative industries. A 2024studycommissioned by the Animation Guild, a union representing Hollywood animators and cartoonists, estimates that more than 100,000 U.S.-based film, television, and animation jobs will be disrupted by AI by 2026.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/ezgif-1ad44b32058578.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/witness-a-dynamic-dialogue-between-two-visionary-ceos/",
        "date_extracted": "2025-04-16T17:27:04.040492",
        "title": "Witness a dynamic dialogue between two visionary CEOs",
        "author": null,
        "publication_date": null,
        "content": "Step into an extraordinary fireside chat featuring Ali Ghodsi, the visionary co-founder and CEO of Databricks, alongside Dario Amodei, the innovative co-founder and CEO of Anthropic. Discover how their groundbreaking partnership is set to accelerate the evolution of domain-specific AI agents.\nDuring thisfree, virtual event, you\u2019ll also gain exclusive access to three additional sessions that expand on the groundbreaking CEO discussion:\nWhat you\u2019ll learn:\nShowtimes vary by time zone:",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/2025-02-ve-techcrunch-dsml-anthropic-speakers-email-banner-600x220-2x-1.png",
            "https://techcrunch.com/wp-content/uploads/2025/04/databricks-article-post-1-3-speakers.jpg"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/openai-is-reportedly-developing-its-own-x-like-social-media-platform/",
        "date_extracted": "2025-04-16T17:27:06.791094",
        "title": "OpenAI is reportedly developing its own X-like social media platform",
        "author": null,
        "publication_date": null,
        "content": "OpenAI is building its own X-like social media network, according to a new report fromThe Verge. The project is still in the early stages, but there\u2019s an internal prototype focused on\u00a0ChatGPT\u2019s image generation that contains a social feed.\nThe report states that it\u2019s unknown if OpenAI plans to launch the social network as a standalone app or if it plans to integrate it within the ChatGPT app.\nWith this new social network, OpenAI would be taking on Elon Musk\u2019s X and Meta\u2019s social platforms, Facebook and Instagram. The new app would also allow OpenAI to access real-time data to train its AI models, something that both X and Meta already have.\nOpenAI CEO Sam Altman has reportedly been privately asking outsiders for feedback about the social network.\nAt this point, it\u2019s not clear whether the project will ever launch publicly, but the existence of a prototype shows that OpenAI is looking to expand beyond its current offerings.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/openai-ships-gpt-4-1-without-a-safety-report/",
        "date_extracted": "2025-04-16T17:27:09.575774",
        "title": "OpenAI ships GPT-4.1 without a safety report",
        "author": null,
        "publication_date": null,
        "content": "On Monday, OpenAIlaunched a new family of AI models, GPT-4.1, which the company said outperformed some of its existing models on certain tests, particularly benchmarks for programming. However, GPT-4.1 didn\u2019t ship with the safety report that typically accompanies OpenAI\u2019s model releases, known as a model or system card.\nAs of Tuesday morning, OpenAI had yet to publish a safety report for GPT-4.1 \u2014 and it seems it doesn\u2019t plan to. In a statement to TechCrunch, OpenAI spokesperson Shaokyi Amdo said that \u201cGPT-4.1 is not a frontier model, so there won\u2019t be a separate system card released for it.\u201d\nIt\u2019s fairly standard for AI labs to release safety reports showing the types of tests they conducted internally and with third-party partners to evaluate the safety of particular models. These reports occasionally reveal unflattering information, like thata model tends to deceive humansor isdangerously persuasive. By and large, the AI community perceives these reports as good-faith efforts by AI labs to support independent research and red teaming.\nBut over the past several months, leading AI labs appear to have lowered their reporting standards, prompting backlash from safety researchers. Some,likeGoogle, havedragged their feeton safety reports, while others have published reportslacking in the usual detail.\nOpenAI\u2019s recent track record isn\u2019t exceptional either. In December, the company drew criticism for releasing a safety reportcontaining benchmark results for a model differentfrom the version it deployed into production. Last month, OpenAIlaunched a model, deep research, weeks prior to publishing the system card for that model.\nSteven Adler, a former OpenAI safety researcher, noted to TechCrunch that safety reports aren\u2019t mandated by any law or regulation \u2014 they\u2019re voluntary. Yet OpenAI has made several commitments to governments to increase transparency around its models. Ahead of the U.K. AI Safety Summit in 2023, OpenAI in a blog postcalled system cards\u201ca key part\u201d of its approach to accountability. And leading up to the Paris AI Action Summit in 2025, OpenAI said system cards provide valuable insightsinto a model\u2019s risks.\n\u201cSystem cards are the AI industry\u2019s main tool for transparency and for describing what safety testing was done,\u201d Adler told TechCrunch in an email. \u201cToday\u2019s transparency norms and commitments are ultimately voluntary, so it is up to each AI company to decide whether or when to release a system card for a given model.\u201d\nGPT-4.1 is shipping without a system card at a time when current and former employees are raising concerns over OpenAI\u2019s safety practices. Last week, Adler and 11 other ex-OpenAI employees filed a proposed amicus brief in Elon Musk\u2019s case against OpenAI, arguing that a for-profit OpenAI might cut corners on safety work. The Financial Times recently reportedthat the ChatGPT maker, spurred by competitive pressures, has slashed the amount of time and resourcesit allocates to safety testers.\nWhile GPT-4.1 isn\u2019t the highest-performing AI model in OpenAI\u2019s roster, it does make substantial gains in the efficiency and latency departments. Thomas Woodside, co-founder and policy analyst at Secure AI Project, told TechCrunch that the performance improvements make a safety report all the more critical. The more sophisticated the model, the higher the risk it could pose, he said.\nMany AI labs have batted down efforts to codify safety reporting requirements into law. For example,OpenAI opposed California\u2019s SB 1047, which would have required many AI developers to audit and publish safety evaluations on models that they make public.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/former-tesla-supply-chain-leaders-create-atomic-an-ai-inventory-solution/",
        "date_extracted": "2025-04-16T17:27:12.257200",
        "title": "Former Tesla supply chain leaders create Atomic, an AI inventory solution",
        "author": null,
        "publication_date": null,
        "content": "Tesla famously struggled to scale up production of the Model 3 sedan in 2018 \u2014 so much so that CEO Elon Musk said his company wasweeks away from collapsing. That near-death experience helped spawn a whole new company called Atomic that\u2019s built around using AI to streamline supply chains.\nCo-founded by former Tesla employees Michael Rossiter and Neal Suidan,Atomicwas created inside DVx Ventures, the firm run by former Tesla president Jon McNeill. Rossiter is also a partner at DVx, which has led a $3 million seed round for Atomic, with Seattle-based Madrona Ventures joining.\n\u201cMichael and Neil experienced this pain firsthand as leaders at Tesla in the supply chain, and I saw that work firsthand \u2014 because they worked for me,\u201d McNeill said in an interview with TechCrunch.\nAtomic plans to deploy its agentic AI with customers to make inventory planning faster and easier. It\u2019s already been working with pilot customers. In one case, the customer was able to cut inventory levels in half while maintaining a 99% in-stock rate.\nBeing able to strike a balance like that frees up working capital that a business can use in other places, while also reducing risk, McNeill said.\n\u201cIf you have too much capital tied up in inventory, you could really harm the business. And if you have too little, where you don\u2019t have the right things in stock when the customer is ready to purchase, then you\u2019re costing yourself big time,\u201d he said.\nMore broadly, Atomic\u2019s early customers have been in the consumer packaged goods, food and beverage, and apparel industries. The company claims it has helped those customers reduce inventory costs by 20% to 50%.\nWith so much uncertainty in the world right now, there\u2019s big demand for solutions like Atomic\u2019s because existing ones aren\u2019t built for this kind of volatility, Suidan said in an interview.\nCurrently, \u201cplanners will, like, lock themselves in a room for a week trying to put together different scenarios, present those back to the leadership, and get a question they weren\u2019t anticipating,\u201d Suidan said. Then they \u201chave to go back to these documents, spend a few days, and it\u2019s becomes this process that can be all consuming for them, because they don\u2019t have the tools available to manage the uncertainty with confidence.\u201d\nAtomic\u2019s software pulls information from those same source documents but lets inventory planners and supply chain team members quickly simulate multiple scenarios \u2014 something that would normally take hours or days.\nRossiter and Suidan pride themselves on being able to get up and running with a customer quickly, and with adaptability.\n\u201cYou can\u2019t be writing a custom application for every customer. You need a flexible data model that\u2019s generalized, that can apply to everyone, because then you can be up and running really, really quickly,\u201d Suidan said. \u201cAnd you need to give precision control to the planner so that they feel true ownership over the plan, and they can explain it inside and out, and can pull all the levers in the plan. And if you can combine those two things, which has been our total focus, then you solve the problem for the planner.\u201d\nMany Tesla employees have gone on to found their own startups, including former CTO JB Straubel (Redwood Materials) and, most recently, former SVP Drew Baglino (Heron).\nBut Atomic is different. Instead of just taking skills learned at Tesla and applying them to new problems, Suidan and Rossiter are building Atomic around a philosophy they developed together at the automaker.\n\u201cThey built the end-to-end supply chain orchestration system from scratch\u201d at Tesla, McNeill said.\nSuidan said the value of what they built at Tesla was just as much about the solution as it was changing the process.\n\u201cThe way the business was planned when we started was a dozen different teams working in isolation, passing these spreadsheets around, trying to tie it together once a week to present executives some summary of a plan, and then spending most of the rest of the week, chasing our tail, trying to figure out why one part didn\u2019t work or the other part didn\u2019t work,\u201d Suidan said. \u201cOur jobs became to build a system that could thrive and drive this company, keep its dynamism, keep its ability to hit these business targets.\u201d\nSuidan said the planning system they built inside Tesla resulted in a \u201ccomplete transformation\u201d in the day-to-day operations. While Rossiter left Tesla shortly after the ramp-up of the Model 3, Suidan stuck around until 2022.\nIn 2023 Suidan said the two put their heads together and asked: \u201cHow could this kind of transformation work for everybody, all businesses?\u201d And they set out to create Atomic inside DVx.\nIn typical Tesla fashion, they really are aiming that high. \u201cOur ambition, our vision, is to support every company that sells physical goods,\u201d Rossiter said.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/host-your-very-own-side-event-during-techcrunch-sessions-ai/",
        "date_extracted": "2025-04-16T17:27:14.543144",
        "title": "Reach 1,000+ AI leaders: Host a Side Event during TechCrunch Sessions: AI",
        "author": null,
        "publication_date": null,
        "content": "Looking to position your brand in front of the brightest minds in artificial intelligence? Hosting aSide Eventduring TechCrunch Sessions: AI Week is your opportunity to do just that. Reach 1,200+ attendees and the surrounding Berkeley tech scene.\nFrom June 1 to June 7, TechCrunch invites startups, investors, and builders to bring unique and engaging Side Events to life alongsideTC Sessions: AI, taking place June 5 in Zellerbach Hall at UC Berkeley. Whether you\u2019re planning a networking happy hour, an industry meetup, a dynamic workshop, or a cocktail hour, we\u2019re welcoming creative formats that complement the week\u2019s main event.\nTC Sessions: AI delivers a comprehensive look at the latest AI trends and advancements through curated programming, live demos, and high-value networking. By hosting a Side Event, your brand becomes part of the narrative \u2014 and benefits from broad exposure to the AI community.\nScore an exclusive discount code for you and your network \u2014 and let TechCrunch amplify your event with full-on promotion to our entire audience and the TC Sessions: AI crowd. Perks include:\nYou\u2019re in charge of your event \u2014 meaning logistics, costs, promo, and everything in between. There\u2019s no fee to join the Side Event lineup, but we do have a few guidelines:\nSide Events are a standout opportunity to connect with the AI community and gain valuable brand visibility.Apply here and make your mark at TC Sessions: AI before the deadline.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/notion-releases-its-ai-driven-email-inbox/",
        "date_extracted": "2025-04-16T17:27:16.839290",
        "title": "Notion releases an AI-powered email client for Gmail",
        "author": null,
        "publication_date": null,
        "content": "Notion releasedNotion Mail, an AI-powered email client for Gmail that integrates with the rest of Notion\u2019s workflow management platform, on Tuesday.\nNotion Mail connects to Notion users\u2019 Gmail accounts and uses AI to help users organize their emails, draft responses, schedule meetings, and search across messages. Any Notion user can sign up, and Notion Mail\u2019s AI capabilities are free with monthly usage limits or unlimited through a paid tier.\nNotion Mail enters an increasingly crowded category of companies looking to improve email inboxes with AI.Superhuman, one of the larger players, has raised $108 million in venture funding for its client that isn\u2019t tied to legacy email providers like Gmail or Microsoft Outlook.Fyxer, which connects to Gmail and Outlook, raised $10 million last month.\nIt\u2019s also worth noting that many of the features Notion Mail is offering are also available from providers like Gmail, which uses AI to sort emails, craft responses, and suggest meetings.\nJason Ginsberg, Notion Mail lead, told TechCrunch that the idea behind Notion Mail wasn\u2019t to attach AI to an existing inbox, but rather give users the ability to use AI to build a custom inbox organized and configured how they want.\n\u201cThe way we built Notion Mail is almost down to the building blocks, or the fundamentals of how email works,\u201d Ginsberg said. \u201cIt\u2019s really modular. And what that means is, like, instead of just going to settings and there\u2019s just what we\u2019ve decided, you actually can configure Notion Mail in ways we can\u2019t even imagine \u2014 all different permutations, so that it actually works the way you prefer.\u201d\nNotion Mail\u2019s infrastructure came from Skiff, an end-to-end encrypted collaboration platformNotion acquired in 2024for an undisclosed sum. Ginsberg co-founded Skiff, which also included an email product.\nAccording to Ginsberg, one of Notion Mail\u2019s more notable features is the ability for users to separate their inbox into \u201cviews\u201d or folders. The feature uses Notion AI to auto-label emails on a particular topic and move them into a separate topic-specific inbox.\nGinsberg imagines users will use the capability to organize emails for a specific purpose, like keeping track of job applications. He said he uses the feature himself to quickly check customer feedback from Notion Mail\u2019s beta customers.\nNotion Mail connects with other Notion products like the platform\u2019s calendar app, Notion Calendar, and its internal knowledge base. This unlocks time-saving shortcuts. If someone in an email exchange suggests scheduling a meeting, Notion\u2019s AI will check a user\u2019s calendar, suggest times they\u2019re free, and prompt them to schedule it.\nGinsberg said that a lot of the innovation around incorporating AI into email has thus far focused mainly on writing emails. He thinks Notion Mail offers something different because of its emphasis on building a customized inbox.\n\u201cI think our focus has really been on, how can AI help organize your email for you?\u201d Ginsberg said. \u201cThe big change there is it\u2019s no longer feeling like a burden where you are going through the same never-ending list, one-size-fits-all inbox and manually triaging emails. Our focus is not to have you work faster in the old way of things. It\u2019s really a new way and a new approach.\u201d\nGinsberg said that in the future, Notion hopes to be able to offer more product integrations and additional ways to access Notion Mail, like an iOS app. The Notion team also wants to be able to offer multiple inboxes in one view down the line.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/15/apple-details-how-it-plans-to-improve-its-ai-models-by-privately-analyzing-user-data/",
        "date_extracted": "2025-04-16T17:27:19.171504",
        "title": "Apple details how it plans to improve its AI models by privately analyzing user data",
        "author": null,
        "publication_date": null,
        "content": "In the wake of criticism over the underwhelming performance of its AI products, especially in areas likenotificationsummaries, Apple on Mondaydetailedhow it is trying to improve its AI models by analyzing user data privately with the aid of synthetic data.\nUsing an approach called \u201cdifferential privacy,\u201d the company said it would first generate synthetic data and then poll users\u2019 devices (provided they\u2019ve opted-in to share device analytics with Apple) with snippets of the generated synthetic data to compare how accurate its models are, and subsequently improve them.\n\u201cSynthetic data are created to mimic the format and important properties of user data, but do not contain any actual user generated content,\u201d the company wrote in the blog post. \u201cTo curate a representative set of synthetic emails, we start by creating a large set of synthetic messages on a variety of topics [\u2026] We then derive a representation, called an embedding, of each synthetic message that captures some of the key dimensions of the message like language, topic, and length.\u201d\nThe company said these embeddings are then sent to a small number of user devices that have opted in to Device Analytics, and the devices then compare them with a sample of emails to tell Apple which embeddings are most accurate.\nThe company said it is using this approach to improve its Genmoji models, and would in the future use synthetic data for Image Playground, Image Wand, Memories Creation, and Writing Tools, as well as Visual Intelligence. Apple said it would also poll users who opt in to share device analytics with synthetic data to improve email summaries.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/rlwrld-raises-14-4m-to-build-foundation-model-for-robotics/",
        "date_extracted": "2025-04-16T17:27:21.620740",
        "title": "RLWRLD raises $14.8M to build a foundational model for robotics",
        "author": null,
        "publication_date": null,
        "content": "As robotics has advanced, industry has steadily adopted more robots to automate many kinds of grunt work. More than 540,000 new industrial robots were installed worldwide in 2023, taking the number of total industrial robots active to above 4 million, perIFR.\nIndustrial robots typically excel at repetitive tasks, but they find it challenging to perform precise tasks, handle delicate materials, and adjust to changing conditions \u2014 a robot in a restaurant\u2019s kitchen would get in the way more than be helpful, for example. That is why many industrial processes are still manual.\nSouth Korean startupRLWRLDaims to solve this problem with a foundational AI model that it has built specifically for robotics by combining large language models with traditional robotics software. The company says this model will enable robots to make quick and agile movements and perform some amount of \u201clogical reasoning\u201d as well.\n\u201cUsing RLWRLD\u2019s foundation model, processes that require a lot of manual work can be completely automated by learning and copying human expertise, making work environments more efficient,\u201d Jung-Hee Ryu, founder and CEO of RLWRLD, said in an exclusive interview with TechCrunch.\nThe startup is now coming out of stealth with 21 billion KRW (about $14.8 million) in seed funding. The round was led by venture capital firm Hashed; Mirae Asset Venture Investment and Global Brain also invested.\nNotably, RLWRLD has attracted a long list of big strategic investors \u2014 Ana Group, PKSHA, Mitsui Chemical, Shimadzu, and KDDI from Japan; LG Electronics and SK Telecom from Korea; and Amber Manufacturing from India.\nRLWRLD said the seed funding will be used to fund proof-of-concept projects with its strategic investors; secure computing infrastructure like GPUs, purchase robots, and obtain devices to collect extensive data; and hire\u00a0top research talent. The startup will also use the new money to develop advanced hand movements involving five fingers \u2014 a capability that\u2019s not yet been demonstrated by its competitors like Tesla, Figure AI, and 1X, Ryu said.\nRyu said RLWRLD is also working with its strategic investors to explore ways to automate differenthuman-centric workflowsusing its AI model. They are together preparing a humanoid-based autonomous action demonstration, scheduled for later this year, Ryu said. In addition, the company is working to develop a platform that can support various kinds of robots, including industrial, collaborative, autonomous mobile robots, and humanoids.\nFounded in 2024, RLWRLD is Ryu\u2019s third startup. His second startup,Olaworks, was acquired by Intel in 2012, and eventually became Intel\u2019s Korea R&D center within its computer vision division. And in 2015, he foundeda startup accelerator, Future Play, that focuses on deep tech companies.\nWhen asked what inspired him to start a new company again, Ryu said he noticed how quickly AI startups were increasing in number in the U.S., Europe, and China, while comparable AI startups in Korea and Japan were relatively absent.\nHe spoke with over 30 AI professors from Korea and Japan about their challenges \u2014 everything from the lack of infrastructure like data and GPUs, and the obstacles that discouraged them to launch a venture \u2014 and the opportunities available.\n\u201cI determined that it would be strategically beneficial to prioritize robotics foundation models (RFM) over the technologically saturated field of LLMs, capitalizing on Korea and Japan\u2019s notable global strengths in manufacturing,\u201d he said.\nSoon afterward, he brought on board six professors from top-ranked institutions in South Korea, including KAIST, SNU, and POSTECH, along with their research teams, to launch RLWRLD.\nRLWRLD isn\u2019t alone in tackling this problem. Startups likeSkild AIandPhysical Intelligenceare building similar foundational models for robotics, as are larger firms like Tesla,Google DeepMind, andNvidia.\nBut Ryu believes his startup has a good start, as it already has the AI and robotics experts it needs to develop foundational models for robotics, as well as humanoid robots with high degree of freedom (DoF).\n\u201cAdditionally, [such companies] typically rely on low-DoF robots such as two-fingered grippers. RLWRLD has already secured a high-DoF reference robot, and therefore expects superior performance outcomes,\u201d he said.\nRyu also said that thanks to its strategic investors, RLWRLD can quickly gather valuable data from manufacturing sites located nearby. In 2024,a reportindicated that Japan and South Korea collectively accounted for 9.2% of worldwide manufacturing production.\nRLWRLD aims to generate revenue as early as this year through proof-of-concept (PoC) projects and collaboration demonstrations with strategic partners.\nThe startup\u2019s long-term goal is to cater to factories, logistics centers, and retail stores, and even robots that can be used in domestic environments to help with household chores. In the meantime, the priority is to target industrials since they are willing to pay the most and have strong demand for automation.\nThe startup has 13 employees.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/DSC05786.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/debates-over-ai-benchmarking-have-reached-pokemon/",
        "date_extracted": "2025-04-16T17:27:24.110154",
        "title": "Debates over AI benchmarking have reached Pok\u00e9mon",
        "author": null,
        "publication_date": null,
        "content": "Not even Pok\u00e9mon is safe from AI benchmarking controversy.\nLast week, apost on Xwent viral, claiming that Google\u2019s latest Gemini model surpassed Anthropic\u2019s flagship Claude model in the original Pok\u00e9mon video game trilogy. Reportedly, Gemini had reached Lavender Town in a developer\u2019s Twitch stream; Claude wasstuck at Mount Moonas of late February.\nGemini is literally ahead of Claude atm in pokemon after reaching Lavender Town\n119 live views only btw, incredibly underrated streampic.twitter.com/8AvSovAI4x\n\u2014 Jush (@Jush21e8)April 10, 2025\n\nBut what the post failed to mention is that Gemini had an advantage.\nAsusers on Redditpointed out, the developer who maintains the Gemini stream built a custom minimap that helps the model identify \u201ctiles\u201d in the game like cuttable trees. This reduces the need for Gemini to analyze screenshots before it makes gameplay decisions.\nNow, Pok\u00e9mon is a semi-serious AI benchmark at best \u2014 few would argue it\u2019s a very informative test of a model\u2019s capabilities. But itisan instructive example of how different implementations of a benchmark can influence the results.\nFor example, Anthropicreportedtwo scores for its recent Anthropic 3.7 Sonnet model on the benchmark SWE-bench Verified, which is designed to evaluate a model\u2019s coding abilities. Claude 3.7 Sonnet achieved 62.3% accuracy on SWE-bench Verified, but 70.3% with a \u201ccustom scaffold\u201d that Anthropic developed.\nMore recently, Metafine-tuneda version of one of its newer models, Llama 4 Maverick, to perform well on a particular benchmark, LM Arena. Thevanilla versionof the model scores significantly worse on the same evaluation.\nGiven that AI benchmarks \u2014 Pok\u00e9mon included \u2014 areimperfect measuresto begin with, custom and non-standard implementations threaten to muddy the waters even further. That is to say, it doesn\u2019t seem likely that it\u2019ll get any easier to compare models as they\u2019re released.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/openais-new-gpt-4-1-models-focus-on-coding/",
        "date_extracted": "2025-04-16T17:27:26.902069",
        "title": "OpenAI\u2019s new GPT-4.1 AI models focus on coding",
        "author": null,
        "publication_date": null,
        "content": "OpenAI on Monday launched a new family of models called GPT-4.1. Yes, \u201c4.1\u201d \u2014 as if the company\u2019s nomenclature wasn\u2019t confusing enough already.\nThere\u2019s GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano, all of which OpenAI says \u201cexcel\u201d at coding and instruction following. Available through OpenAI\u2019s API but notChatGPT, the multimodal models have a 1-million-token context window, meaning they can take in roughly 750,000 words in one go (longer than \u201cWar and Peace\u201d).\nGPT-4.1 arrives as OpenAI rivals like Google and Anthropic ratchet up efforts to build sophisticated programming models. Google\u2019s recently releasedGemini 2.5 Pro, which also has a 1-million-token context window, ranks highly on popular coding benchmarks. So do Anthropic\u2019sClaude 3.7 Sonnetand Chinese AI startupDeepSeek\u2019s upgraded V3.\nIt\u2019s the goal of many tech giants, including OpenAI, to train AI coding models capable of performing complex software engineering tasks. OpenAI\u2019s grand ambition is to create an \u201cagentic software engineer,\u201d asCFO Sarah Friar put itduring a tech summit in London last month. The company asserts its future models will be able to program entire apps end-to-end, handling aspects such as quality assurance, bug testing, and documentation writing.\nGPT-4.1 is a step in this direction.\n\u201cWe\u2019ve optimized GPT-4.1 for real-world use based on direct feedback to improve in areas that developers care most about: frontend coding, making fewer extraneous edits, following formats reliably, adhering to response structure and ordering, consistent tool usage, and more,\u201d an OpenAI spokesperson told TechCrunch via email. \u201cThese improvements enable developers to build agents that are considerably better at real-world software engineering tasks.\u201d\nOpenAI claims the full GPT-4.1 model outperforms itsGPT-4o and GPT-4o minimodels on coding benchmarks, including SWE-bench. GPT-4.1 mini and nano are said to be more efficient and faster at the cost of some accuracy, with OpenAI saying GPT-4.1 nano is its speediest \u2014 and cheapest \u2014 model ever.\nGPT-4.1 costs $2 per million input tokens and $8 per million output tokens. GPT-4.1 mini is $0.40/million input tokens and $1.60/million output tokens, and GPT-4.1 nano is $0.10/million input tokens and $0.40/million output tokens.\nAccording to OpenAI\u2019s internal testing, GPT-4.1, which can generate more tokens at once than GPT-4o (32,768 versus 16,384), scored between 52% and 54.6% on SWE-bench Verified, a human-validated subset of SWE-bench. (OpenAI noted in a blog post that some solutions to SWE-bench Verified problems couldn\u2019t run on its infrastructure, hence the range of scores.) Those figures are slightly under the scores reported by Google and Anthropic for Gemini 2.5 Pro (63.8%) and Claude 3.7 Sonnet (62.3%), respectively, on the same benchmark.\nIn a separate evaluation, OpenAI probed GPT-4.1 using Video-MME, which is designed to measure the ability of a model to \u201cunderstand\u201d content in videos. GPT-4.1 reached a chart-topping 72% accuracy on the \u201clong, no subtitles\u201d video category, claims OpenAI.\nWhile GPT-4.1 scores reasonably well on benchmarks and has a more recent \u201cknowledge cutoff,\u201d giving it a better frame of reference for current events (up to June 2024), it\u2019s important to keep in mind that even some of the best models today struggle with tasks that wouldn\u2019t trip up experts. For example,manystudieshaveshownthat code-generating models often fail to fix, and even introduce, security vulnerabilities and bugs.\nOpenAI acknowledges, too, that GPT-4.1 becomes less reliable (i.e., likelier to make mistakes) the more input tokens it has to deal with. On one of the company\u2019s own tests, OpenAI-MRCR, the model\u2019s accuracy decreased from around 84% with 8,000 tokens to 50% with 1 million tokens. GPT-4.1 also tended to be more \u201cliteral\u201d than GPT-4o, says the company, sometimes necessitating more specific, explicit prompts.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/openai-plans-to-wind-down-gpt-4-5-its-largest-ever-ai-model-in-its-api/",
        "date_extracted": "2025-04-16T17:27:29.405457",
        "title": "OpenAI plans to phase out GPT-4.5, its largest-ever AI model, from its API",
        "author": null,
        "publication_date": null,
        "content": "OpenAI said on Monday that it would soon wind down the availability ofGPT-4.5, its largest-ever AI model, via its API. GPT-4.5 was released only in late February.\nDevelopers will have access to GPT-4.5 via OpenAI\u2019s API until July 14, after which they\u2019ll have to transition to another model in OpenAI\u2019s catalog, the company says. OpenAI is positioningGPT-4.1, which launched Monday, as the preferred replacement.\n\u201c[GPT-4.1] offers similar or improved performance than GPT-4.5 in key areas at a much lower cost,\u201d an OpenAI spokesperson told TechCrunch via email. \u201c[W]e will [be] deprecating GPT-4.5 to prioritize building future models.\u201d\nTo be clear, GPT-4.5 isn\u2019t leaving ChatGPT, where it\u2019s available in research preview for paying customers. OpenAI is only phasing it out of the API.\nGPT-4.5,code-named Orion, was trained using more computing power and data than any of OpenAI\u2019s previous releases. It improves upon its predecessor,GPT-4o, in areas such as writing andpersuasiveness, but despite its scale, GPT-4.5 falls short of \u201cfrontier level\u201d on a number of industry benchmarks.\nGPT-4.5 is also very expensive to run, OpenAI admits \u2014 so expensive that the company warned in February that it was evaluating whether to serve GPT-4.5 via its API in the long term. The model\u2019s pricing reflects this: GPT-4.5 costs $75 for every million input tokens (roughly 750,000 words) and $150 per million output tokens, making it one of OpenAI\u2019s costliest offerings.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/googles-newest-ai-model-is-designed-to-help-study-dolphin-speech/",
        "date_extracted": "2025-04-16T17:27:31.724773",
        "title": "Google\u2019s newest AI model is designed to help study dolphin \u2018speech\u2019",
        "author": null,
        "publication_date": null,
        "content": "Google\u2019s AI research lab, Google DeepMind, says that it hascreated an AI modelthat can help decipher dolphin vocalizations, supporting research efforts to better understand how dolphins communicate.\nThe model, called DolphinGemma, was trained using data from the Wild Dolphin Project (WDP), a nonprofit that studies Atlantic spotted dolphins and their behaviors. Built on Google\u2019s open Gemma series of models, DolphinGemma, which can generate \u201cdolphin-like\u201d sound sequences, is efficient enough to run on phones, Google says.\nThis summer, WDP plans to use Google\u2019s Pixel 9 smartphone to power a platform that can create synthetic dolphin vocalizations and listen to dolphin sounds for a matching \u201creply.\u201d WDP previously was using the Pixel 6 to conduct this work, Google says, and upgrading to the Pixel 9 will enable researchers at the organization to run AI models and template-matching algorithms at the same time, according to Google.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/google-classroom-gives-teachers-an-ai-feature-for-quiz-questions/",
        "date_extracted": "2025-04-16T17:27:34.439122",
        "title": "Google Classroom gives teachers an AI feature for quiz questions",
        "author": null,
        "publication_date": null,
        "content": "Google Classroomintroduceda new AI-powered feature designed to help teachers generate questions. Launched on Monday, this tool lets educators create a list of questions based on specific text input.\nUsing this text-dependent question-generation tool, which utilizes Gemini, teachers can either upload files from Google Drive or manually enter text for the AI to generate questions.\u00a0They can then export the questions into a Google Doc or Google Form.\nEducators can choose from a variety of filters, including the grade level, the number of questions, and the type of questions (such as multiple choice or open-ended). Additionally, there is an option for teachers to specify the skills they want their students to demonstrate, such as the use of figurative language or the ability to evaluate arguments.\nThis feature is available only to Google Workspace for Education subscribers who have either the Gemini Education add-on ($24 per user) or Gemini Education Premium ($36 per user).\nGoogle initially launched Gemini to Classroom in 2024 and has since expanded its capabilities. The recent update included a tool for creatingvocabulary lists. It can also generate lesson plan ideas and summarize a range of materials, from class notes to student feedback.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/Text-dependent-questions.gif?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/meta-to-start-training-its-ai-models-on-public-content-in-the-eu/",
        "date_extracted": "2025-04-16T17:27:37.206986",
        "title": "Meta to start training its AI models on public content in the EU",
        "author": null,
        "publication_date": null,
        "content": "Metaannouncedon Monday that it\u2019s going to train its AI models on public content, such as posts and comments on Facebook and Instagram, in the EU after previouslypausing its plans to do soin response to regulatory pressure due to data privacy concerns. The company will start training its AI on users\u2019 content in the EU this week, it said. Users\u2019 interactions with Meta AI will also be used to train its models.\nThe announcement comes after a limited version ofMeta AI launched in the EUlast month, well after its debut in the U.S. and other global markets.\nWhile Meta has beentraining its AIon user-generated content in the U.S. for years, it has faced resistance in the EU due to the bloc\u2019s strict privacy laws, particularly the General Data Protection Regulation (GDPR), which requires a clear legal basis for processing personal data to train AI models.\nMeta saidback in June 2024that it would pause plans to start training its AI systems using user data in the EU and U.K. following pushback from the Irish Data Protection Commission (DPC). The DPC regulates Meta in the EU and was acting on behalf of several data protection authorities across the bloc. InSeptember 2024, Meta said it was restarting efforts to train its AI systems using public\u00a0posts from its U.K. user base.\nFast-forward to today; Meta has announced that it will do so with public posts from its EU user base as well.\n\u201cLast year, we delayed training our large language models using public content while regulators clarified legal requirements,\u201d Meta said in its blog post. \u201cWe welcome the opinion provided by the EDPB in December, which affirmed that our original approach met our legal obligations. Since then, we have engaged constructively with the IDPC and look forward to continuing to bring the full benefits of generative AI to people in Europe.\u201d\nStarting this week, users in the EU will start receiving in-app and email notifications to explain that Meta will start using public data and interactions with Meta AI to train its models. These notifications will include a link to a form that will allow users to opt out of their data being used. Meta says it will honor all objection forms it has already received, as well as newly submitted ones.\nMeta notes that it doesn\u2019t use private messages, nor public data from users under the age of 18 in the EU, to train its models.\n\u201cWe believe we have a responsibility to build AI that\u2019s not just available to Europeans, but is actually built for them,\u201d Meta says. \u201cThat\u2019s why it\u2019s so important for our generative AI models to be trained on a variety of data so they can understand the incredible and diverse nuances and complexities that make up European communities. That means everything from dialects and colloquialisms, to hyper-local knowledge and the distinct ways different countries use humor and sarcasm on our products.\u201d\nMeta says it\u2019s following the example set by companies like Google and OpenAI, both of which have already used data from European users to train their AI models.\nMeanwhile, the DPC is not moving on entirely from scrutinizing how large language model creators are training their AI services. Last week, the regulatorannouncedit was investigating xAI\u2019s training of Grok.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/hugging-face-buys-a-humanoid-robotics-startup/",
        "date_extracted": "2025-04-16T17:27:39.532739",
        "title": "Hugging Face buys a humanoid robotics startup",
        "author": null,
        "publication_date": null,
        "content": "AI dev platform Hugging Face has acquired Pollen Robotics, a robotics startup based in France, for an undisclosed amount.Wired reportsthat Hugging Face plans to sell Pollen\u2019s humanoid robot, Reachy 2, and let developers download and suggest improvements to its code.\nPollen Robotics, which aims to bring affordable humanoid robots to the home, was founded in 2016 by Matthieu Lapeyre and Pierre Rouanet. The company managed to raise \u20ac2.5 million (around $2.83 million) from investors, including Bpifrance, prior to its exit,according to Crunchbase.\nIf you\u2019ve followed the progress of robotics in the past 18 months, you\u2019ve likely noticed how robotics is increasingly becoming the next frontier that AI will unlock.\nAt Hugging Face\u2014in robotics and across all AI fields\u2014we believe in a future where AI and robots are open-source,\u2026\n\u2014 Thomas Wolf (@Thom_Wolf)April 14, 2025\n\nThe acquisition marks an expansion of Hugging Faces\u2019 robotics efforts, with which Pollen was closely involved. Last year, Hugging Face teamed up with Pollen to build \u201cLe Robot,\u201d an open source robot trained to do a variety of household chores. Hugging Face also established a robotics team led by Remi Cadene, a former robotics engineer from Tesla\u2019s Optimus program.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/14/nvidia-says-it-plans-to-manufacture-some-ai-chips-in-the-u-s/",
        "date_extracted": "2025-04-16T17:27:42.082758",
        "title": "Nvidia says it plans to manufacture some AI chips in the US",
        "author": null,
        "publication_date": null,
        "content": "Nvidiasaid on Monday that it has commissionedmore than a million square feet of manufacturing space to build and test AI chips in Arizona and Texas as part of an effort to move a portion of its production to the U.S.\nThe chipmaker said the production of its Blackwell chips has started at TSMC\u2019s chip plants in Phoenix, Arizona, and that Nvidia is building \u201csupercomputer\u201d manufacturing plants in Texas \u2014 with Foxconn in Houston and with Wistron in Dallas. In Arizona, Nvidia is partnering with Amkor and SPIL for packaging and testing operations, the company added.\nMass production at the Houston and Dallas plants is expected to ramp up in the next 12-15 months, and within the next four years, the company aims to produce up to half-a-trillion dollars of AI infrastructure in the U.S.\n\u201cThe engines of the world\u2019s AI infrastructure are being built in the United States for the first time,\u201d said Nvidia CEO Jensen Huang in a statement. \u201cAdding American manufacturing helps us better meet the incredible and growing demand for AI chips and supercomputers, strengthens our supply chain, and boosts our resiliency.\u201d\nThe announcement comes days afterNvidia reportedly narrowly avoided export controlson its H20 chip after striking a domestic manufacturing deal with the Trump administration.According to NPR, the H20, Nvidia\u2019s most advanced chip that can still be exported to China, was spared thanks to a promise from Huang to pour capital into components for U.S.-based AI data centers.\nMany other AI companies have leaned into Trump\u2019s\u201cAmerica-first\u201d approach to AIin bids to curry favor with the administration. OpenAI teamed up with SoftBank and Oracle for a $500 billion U.S. data center initiative dubbedthe Stargate Projectin January, whileMicrosoft pledged $80 billionto build AI data centers in its 2025 fiscal year, with 50% of that earmarked for the U.S.\nTrump has strong-armed certain partners to get his desired outcome in recent months. Hereportedlytold TSMC that it would have to pay a tax of up to 100% if the company didn\u2019t build new chip factories in the U.S.\nNvidia claimed its U.S. chip manufacturing initiatives could create \u201chundreds of thousands\u201d of jobs and drive \u201ctrillions of dollars\u201d in economic activity over the coming decades. But programs to ramp up the domestic chipmaking industry face formidable \u2014 and growing \u2014 challenges.\nRetaliatory tariffs and trade restrictions from Chinathreaten the supply of necessary raw materials to build chips in the U.S., and there\u2019s asevere shortage of skilled frontline workersfor assembling chips. Meanwhile, the Trump administration\u2019s moves to undermine the Chips Act, a bill passed in 2022 to dole out billions in grants to chipmakers,could deter future investmentsfrom semiconductor giants.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/13/access-to-future-ai-models-in-openais-api-may-require-a-verified-id/",
        "date_extracted": "2025-04-16T17:27:44.789045",
        "title": "Access to future AI models in OpenAI\u2019s API may require a verified ID",
        "author": null,
        "publication_date": null,
        "content": "OpenAI may soon require organizations to complete an ID verification process in order to access certain future AI models,according to a support pagepublished to the company\u2019s website last week.\nThe verification process, called Verified Organization, is \u201ca new way for developers to unlock access to the most advanced models and capabilities on the OpenAI platform,\u201d reads the page. Verification requires a government-issued ID from one of the countries supported by OpenAI\u2019s API. An ID can only verify one organization every 90 days, and not all organizations will be eligible for verification, says OpenAI.\n\u201cAt OpenAI, we take our responsibility seriously to ensure that AI is both broadly accessible and used safely,\u201d reads the page. \u201cUnfortunately, a small minority of developers intentionally use the OpenAI APIs in violation of our usage policies. We\u2019re adding the verification process to mitigate unsafe use of AI while continuing to make advanced models available to the broader developer community.\u201d\nOpenAI released a new Verified Organization status as a new way for developers to unlock access to the most advanced models and capabilities on the platform, and to be ready for the \u201cnext exciting model release\u201d\n\u2013 Verification takes a few minutes and requires a valid\u2026pic.twitter.com/zWZs1Oj8vE\n\u2014 Tibor Blaho (@btibor91)April 12, 2025\n\nThe new verification process could be intended to beef up security around OpenAI\u2019s products as they become more sophisticated and capable. The company haspublished several reportson its efforts to detect and mitigate malicious use of its models, including by groups allegedly based in North Korea.\nIt may also be aimed at preventing IP theft. According to a report from Bloomberg earlier this year,OpenAI was investigating whethera group linked with DeepSeek, the China-based AI lab, exfiltrated large amounts of data through its API in late 2024, possibly for training models \u2014 a violation of OpenAI\u2019s terms.\nOpenAIblocked accessto its services in China last summer.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/12/openai-co-founder-ilya-sutskevers-safe-superintelligence-reportedly-valued-at-32b/",
        "date_extracted": "2025-04-16T17:27:47.204548",
        "title": "OpenAI co-founder Ilya Sutskever\u2019s Safe Superintelligence reportedly valued at $32B",
        "author": null,
        "publication_date": null,
        "content": "Safe Superintelligence (SSI), the AI startup led by OpenAI\u2019s co-founder and former chief scientist Ilya Sutskever, has raised an additional $2 billion in funding at a $32 billion valuation,according to the Financial Times.\nThe startup had alreadyraised $1 billion, and there were reports thatan additional $1 billion roundwas in the works. SSI did not comment on the new funding, which was reportedly led by Greenoaks.\nSutskeverleft OpenAI in May 2024after he appeared to play a role inan ultimately failed attempt to oust CEO Sam Altman. Hefounded SSIwith Daniel Gross and Daniel Levy, and they said the company had \u201cone goal and one product: a safe superintelligence.\u201d\nThat product is presumably still in the works, withSSI\u2019s websitelittle more than a placeholder with a mission statement.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/12/the-xai-x-merger-is-a-good-deal-if-youre-betting-on-musks-empire/",
        "date_extracted": "2025-04-16T17:27:50.121613",
        "title": "The xAI\u2013X merger is a good deal \u2014 if you\u2019re betting on Musk\u2019s empire",
        "author": null,
        "publication_date": null,
        "content": "When Elon Musk announced that his AI startup, xAI, had acquired his social media company, X, in anall-stock deal, it raised some eyebrows. But in many ways, the deal made sense. Grok, xAI\u2019s chatbot, was already deeply integrated with X, which wasfloundering financially, and Musk needed a way to make his $44 billion Twitter acquisition look less like an impulsive takeover and more like a strategic play forAGIdominance.\nIt also pointed to something deeper about how Musk\u2019s empire works: Investing in any one of his companies isn\u2019t about a quick return on investment. It\u2019s about buying into the mysticism around Musk and swallowing whole a narrative of success that outpaces the actual numbers.\nSome call it agrift, pointing to Musk\u2019s history ofoverpromising and underdelivering. But the market is increasingly more tolerant \u2014 welcoming, even \u2014 of narrative-led investments, particularly when the thread that ties the tale together is one of the president\u2019s right-hand men.\n\u201cAll of Elon\u2019s companies today are basically one company,\u201d Yoni Rechtman, a principal at Slow Ventures, told TechCrunch. \u201cIt\u2019s all already Elon, Inc. There are people who work across multiple companies simultaneously. They share a web of capital connections. They do business with one another, and he treats them all effectively as one company. So [the xAI-X merger] just ends some of the fiction that the two businesses were separate.\u201d\nThe thinking among Musk bulls like Ron Baron, the founder of investment management firm Baron Capital, is that \u201cevery single thing [Musk] does is helping everything else he does,\u201d as Baronphrased it. Other businesses under Musk\u2019s control include Tesla, SpaceX, The Boring Company, and Neuralink \u2014 some of whichreportedly share resources. Baron says:\nWhen [Musk] bought Twitter, did he have in his mind that there\u2019s an opportunity to have this data, a tremendous value for licensing? When he decided he wanted to go to Mars with SpaceX, did he really think initially that there\u2019s a real opportunity here for the internet around the world, and there\u2019s gonna be hundreds of billions of dollars of revenue opportunity? When he started off with EVs for Tesla, did he really think that this is gonna merge into self-driving, where you can make hundreds of billions of dollars a year of extra profits, and Grok\u00a0\u2026 and you\u2019re gonna have connected cars all around the world?\u00a0\u2026 All these businesses link up. It\u2019s the ecosystem. It\u2019s the Elon ecosystem, and I think it\u2019s really interesting when you look at it that way.\nBaron Capital has invested across Musk\u2019s ecosystem, an example of the investor crossover between the billionaire\u2019s various companies. Firms like 8VC, Andreessen Horowitz, DFJ Growth, Fidelity Investments, Manhattan Venture Partners, Saudi Arabia\u2019s PIF, Sequoia Capital, Vy Capital, and others also hold positions throughout Musk\u2019s corporate web.\nThat brings us back to the xAI-X deal. Pundits questioned how the acquisition could value X at $33 billion,more than triple its valuationjust a few months ago, and how it could value xAI at $80 billion considering the AI companyreportedlyhas little in the way of revenue. But valuations aren\u2019t always based on what exists today. Rather, they take into account what investors are hoping for \u2014 and that\u2019s particularly true when it comes to Musk\u2019s ventures.\nJust look at Tesla. The electric vehicle maker has been treated like a tech stock for years even though it hasautomaker margins, based largely on the belief that Tesla will one day unlock groundbreaking autonomy in the form of self-driving cars and humanoid robots.\n\u201cThe reason why [Tesla\u2019s] stock trades at 80 times earnings and the comp group trades at 25 times earnings is that people are making a bet on the long term, and it\u2019s not about what happens to numbers this year,\u201d Gene Munster, managing partner at Deepwater Asset Management, told TechCrunch. \u201cThat\u2019s one of Elon\u2019s superpowers, this ability to keep investors engaged for the long term.\u201d\nMunster\u2019s firm has invested in X, xAI, and Tesla. It\u2019s exactly the type of all-in Musk backer that stands to benefit the most from a deal like xAI buying X, assuming Musk can indeed deliver on his pledge of marrying X\u2019s real-time data trove and distribution platform with xAI\u2019s infrastructure and AI expertise.\nOf course, consolidated value also comes with increased risk.\nDan Wang, a professor at Columbia Business School whose research lies at the intersection of business and society, told TechCrunch that the biggest immediate risk factor for investors is the ongoing lawsuit that X is facing from the Securities and Exchange Commission (SEC). The suit accuses Musk of misleading investors by delaying the disclosure of his previous investments in Twitter. The SEC has argued that this allowed Musk to buy more Twitter shares at artificially low prices.\nWang listed a few other risk considerations, such as anticompetition and user privacy concerns, particularly regarding how X quietly opted all users into data collection for AI model training. The opt-in change has already raised the ire of one regulator,Ireland\u2019s DPC, which recently began investigating it as a potential breach of Europe\u2019s GDPR law.\n\u201cAnother kind of risk here is that there isn\u2019t a consensus framework for how the AI market is going to be regulated, but you\u2019re already seeing traces of this in Europe and, up until recently, in California,\u201d Wang said. \u201cA lot of these frameworks have to do with how AI models are deployed in terms of distributing information\u00a0\u2026  They ascribe responsibility to the companies that are creating AI models, as well as providing access to those models.\u201d\nMusk might also simply lose interest in a project, Rechtman said.\n\u201cI think that is what a lot of Tesla shareholders are feeling right now,\u201d he said, \u201cwhere for the last several months, Elon\u2019s number one company has been the Trump campaign, and his other projects have languished.\u201d\nWhen asked about some of these risk factors, Munster appeared nonplussed. He suggested they\u2019re inconsequential given the enormity of, for example, xAI\u2019s value proposition and potential to become a dominant player in AI.\n\u201cWe\u2019re betting the firm on the belief that AI is going to be more transformative than what people think,\u201d he said. \u201cWhat is the value\u00a0\u2026 of one of the four brains that the world is going to run on?\u201d\nRechtman said that Musk bulls aren\u2019t blindly loyal, per se, but simply trust in Musk\u2019s superpower to \u201cbend capital markets to his will\u201d in a way that allows him to do things and build businesses that nobody else can.\n\u201cThe people who are in these businesses have just gone long Elon, and they will continue to go long Elon,\u201d Rechtman said. \u201cSo it\u2019s not surprising to me that they will just continue to tell you that the emperor is wearing clothes.\u201d\nNot for nothing, buying into Musk\u2019s more speculative bets, like X, is one way to potentially unlock more investment opportunities in the Muskverse, Rechtman said.\n\u201cSpaceX is a real thing, and it will never go public,\u201d he said. \u201cSo the only way to invest in SpaceX is to get access to the tenders. And the only way to get access to the tenders is to be in Elon\u2019s good graces.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/metas-vanilla-maverick-ai-model-ranks-below-rivals-on-a-popular-chat-benchmark/",
        "date_extracted": "2025-04-16T17:27:54.094714",
        "title": "Meta\u2019s vanilla Maverick AI model ranks below rivals on a popular chat benchmark",
        "author": null,
        "publication_date": null,
        "content": "Earlier this week, Metalanded in hot waterfor using an experimental, unreleased version of its Llama 4 Maverick model to achieve a high score on a crowdsourced benchmark, LM Arena. The incidentprompted the maintainers of LM Arena to apologize, change their policies, and score the unmodified, vanilla Maverick.\nTurns out, it\u2019s not very competitive.\nThe unmodified Maverick, \u201cLlama-4-Maverick-17B-128E-Instruct,\u201dwas ranked below modelsincluding OpenAI\u2019s GPT-4o, Anthropic\u2019s Claude 3.5 Sonnet, and Google\u2019s Gemini 1.5 Pro as of Friday. Many of these models are months old.\nThe release version of Llama 4 has been added to LMArena after it was found out they cheated, but you probably didn\u2019t see it because you have to scroll down to 32nd place which is where is rankspic.twitter.com/A0Bxkdx4LX\n\u2014 \u03c1:\u0261e\u03c3n (@pigeon__s)April 11, 2025\n\nWhy the poor performance? Meta\u2019s experimental Maverick, Llama-4-Maverick-03-26-Experimental, was \u201coptimized for conversationality,\u201d the company explained in achart publishedlast Saturday. Those optimizations evidently played well to LM Arena, which has human raters compare the outputs of models and choose which they prefer.\nAs we\u2019ve written about before, for various reasons, LM Arena has never been the most reliable measure of an AI model\u2019s performance. Still, tailoring a model to a benchmark \u2014 besides being misleading \u2014 makes it challenging for developers to predict exactly how well the model will perform in different contexts.\nIn a statement, a Meta spokesperson told TechCrunch that Meta experiments with \u201call types of custom variants.\u201d\n\u201c\u2018Llama-4-Maverick-03-26-Experimental\u2019 is a chat optimized version we experimented with that also performs well on LM Arena,\u201d the spokesperson said. \u201cWe have now released our open source version and will see how developers customize Llama 4 for their own use cases. We\u2019re excited to see what they will build and look forward to their ongoing feedback.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/the-most-interesting-startups-showcased-at-google-cloud-next/",
        "date_extracted": "2025-04-16T17:27:56.616704",
        "title": "The most interesting startups showcased at Google Cloud Next",
        "author": null,
        "publication_date": null,
        "content": "Google held its Google Cloud Next conference in Las Vegas this week, where it announced dozens of new features, like itsnext generation AI processing chip, called Ironwood, and its latest AI model,Gemini 2.5 Flash.\nIt also announced a long list of AI startups that have signed to use its cloud. Among them are some of the most watched startups in the world. As we previously reported, this list includesSafe Superintelligence (SSI), the startup founded by OpenAI co-founder and former chief scientist Ilya Sutskever.\nIt also includes:\nAnysphere, which makes the uber-popular AI-powered code editor Cursor. Google says Cursor is using Anthropic\u2019s Claude models on Google Cloud. Cursor was recently valued at $10 billion,sources have told TechCrunch. Its biggest rival is probably GitHub CoPilot, so that would make Microsoft one of its top competitors.\nHebbiauses AI to search large documents and answer questions, which has made it a hit in the legal industry. Andreessen Horowitz led, while Index Ventures, Google Ventures, and Peter Thiel participated inits $130 million Series B.It is using Google\u2019s Gemini models, Google says.\nMagicis building frontier models to automate coding as well as research. Its choice of Google Cloud is likely somewhat obvious, given that its2024 $320 million fundraising roundincluded Alphabet\u2019s CapitalG and former Google CEO Eric Schmidt as investors. It\u2019s tapping Google Cloud for GPUs, according to Google.\nPhysical Intelligenceis working on developing foundational software for robots and has a who\u2019s-who roster of co-founders, including solo investor extraordinaire Lachy Groom. It raised $400 million at a $2 billion pre-money valuation in November from backers including Sequoia, Jeff Bezos, Lux Capital, and Thrive Capital. A few of its founders have deep ties to Google, having previously worked at Google DeepMind, including Karol Hausman and Chelsea Finn.\nPhotoroomis one of the hottest AI startups in Paris, Europe\u2019s center of AI. It offers AI photo editing and is using Google Cloud\u2019s Veo 2 video generating model and its text-to-image model Imagen 3.\nSynthesiais building products that make highly realistic AI avatars and is using various Google models. It raised$180 million at a $2.1 billion round in Januaryled by NEA but with GV (formerly known as Google Ventures) among the investors.\nAll in all, Google Cloud is collecting an impressive list of startups to bolster its race against Microsoft Azure, and to some extent AWS, for AI workloads.\nIn addition, Googleannounced that it added Lightspeed to VC partnersin addition to Sequoia and Y Combinator. Google Cloud grants portfolio companies from its partner investors access to its AI chips and models. Lightspeed\u2019s AI portfolio companies can qualify for $150,000 in cloud credits, Google said. So it has plans to convince even more rising star startups to join its cloud.\nHere are the rest of the AI startups that Google showcased this week:",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/law-professors-side-with-authors-battling-meta-in-ai-copyright-case/",
        "date_extracted": "2025-04-16T17:27:58.931025",
        "title": "Law professors side with authors battling Meta in AI copyright case",
        "author": null,
        "publication_date": null,
        "content": "A group of professors specializing in copyright law hasfiled an amicus briefin support of authors suing Meta for allegedly training its Llama AI models on e-books without permission.\nThe brief, filed on Friday in the U.S. District Court for the Northern District of California, San Francisco Division, calls Meta\u2019s fair use defense \u201ca breathtaking request for greater legal privileges than courts have ever granted human authors.\u201d\n\u201cThe use of copyrighted works to train generative models is not \u2018transformative,\u2019 because using works for that purpose is not relevantly different from using them to educate human authors, which is a principal original purpose of all of [authors\u2019] works,\u201d reads the brief. \u201cThat training use is also not \u2018transformative\u2019 because its purpose is to enable the creation of works that compete with the copied works in the same markets \u2013 a purpose that, when pursued by a for-profit company like Meta, also makes the use undeniably \u2018commercial.\u2019\u201d\nThe International Association of Scientific, Technical, and Medical Publishers, the global trade association for academic and professional publishers,also submitted an amicus briefin support of the authors on Friday.So did the Copyright Alliance, a nonprofit representing artistic creators across a broad range of copyright disciplines,and the Association of American Publishers.\nHours after this piece was published, a Meta spokesperson pointed TechCrunch to amicus briefs filed by a smaller group of law professors and the Electronic Frontier Foundation last weeksupportingthe tech giant\u2019s legal position.\nIn the case, Kadrey v. Meta, authors including Richard Kadrey, Sarah Silverman, and Ta-Nehisi Coates have alleged that Meta violated their intellectual property rights by using their e-books to train models, and that the company removed the copyright information from those e-books to hide the alleged infringement. Meta, meanwhile, has claimed not only that its training qualifies as fair use, but that the case should be dismissed because the authors lack standing to sue.\nEarlier this month, U.S. District Judge Vince Chhabria allowed the case to move forward, although he dismissed part of it. In his ruling, Chhabria wrote that the allegation of copyright infringement is \u201cobviously a concrete injury sufficient for standing\u201d and that the authors have also \u201cadequately alleged that Meta intentionally removed CMI [copyright management information] to conceal copyright infringement.\u201d\nThe courts are weighing a number of AI copyright lawsuits at the moment, includingThe New York Times\u2019 suit against OpenAI.\nUpdated 8:36 p.m. Pacific: Added references to additional amicus briefs filed on Friday.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/ex-openai-staff-file-amicus-brief-opposing-the-companys-for-profit-transition/",
        "date_extracted": "2025-04-16T17:28:01.403002",
        "title": "Ex-OpenAI staffers file amicus brief opposing the company\u2019s for-profit transition",
        "author": null,
        "publication_date": null,
        "content": "A group of ex-OpenAI employees on Friday filed aproposed amicus briefin support of Elon Musk in his lawsuit against OpenAI, opposing the company\u2019s planned conversion from a nonprofit to a for-profit corporation.\nThe brief, filed by Harvard law professor and Creative Commons founder Lawrence Lessig, names 12 former OpenAI employees: Steven Adler, Rosemary Campbell, Neil Chowdhury, Jacob Hilton, Daniel Kokotajlo, Gretchen Krueger, Todor Markov, Richard Ngo, Girish Sastry, William Saunders, Carrol Wainwright, and Jeffrey Wu. It makes the case that if OpenAI\u2019s non-profit ceded control of the organization\u2019s business operations, it would \u201cfundamentally violate its mission.\u201d\nSeveral of the ex-staffers have spoken out against OpenAI\u2019s practices publicly before. Kruegerhas called on the companyto improve its accountability and transparency, while Kokotajlo and Saunders previously warned that OpenAI is in a\u201creckless\u201d race for AI dominance. Wainwrighthas saidthat OpenAI \u201cshould not [be trusted] when it promises to do the right thing later.\u201d\nIn a statement, an OpenAI spokesperson said that OpenAI\u2019s nonprofit \u201cisn\u2019t going anywhere\u201d and that the organization\u2019s mission \u201cwill remain the same.\u201d\n\u201cOur board has been very clear,\u201d the spokesperson told TechCrunch via email. \u201cWe\u2019re turning our existing for-profit arm into a public benefit corporation (PBC) \u2014 the same structure as other AI labs like Anthropic \u2014 where some of these former employees now work \u2014 and [Musk\u2019s AI startup] xAI.\u201d\nOpenAI was founded as a nonprofit in 2015, but it converted to a \u201ccapped-profit\u201d in 2019, and is now trying to restructure once more into a PBC. When it transitioned to a capped-profit, OpenAI retained its nonprofit wing, which currently has a controlling stake in the organization\u2019s corporate arm.\nMusk\u2019s suit against OpenAI accuses the startup of abandoning its nonprofit mission, which aimed to ensure its AI research benefits all humanity. Musk had sought a preliminary injunction tohalt OpenAI\u2019s conversion. A federal judgedenied the request, but permitted the case to go to a jury trial in spring 2026.\nAccording to the ex-OpenAI employees\u2019 brief, OpenAI\u2019s present structure \u2014 a nonprofit controlling a group of other subsidiaries \u2014 is a \u201ccrucial part\u201d of its overall strategy and \u201ccritical\u201d to the organization\u2019s mission. Restructuring that removes the nonprofit\u2019s controlling role would not only contradict OpenAI\u2019s mission and charter commitments, but would also \u201cbreach the trust of employees, donors, and other stakeholders who joined and supported the organization based on these commitments,\u201d asserts the brief.\n\u201cOpenAI committed to several key principles for executing on [its] mission in their charter document,\u201d the brief reads. \u201cThese commitments were taken extremely seriously within the company and were repeatedly communicated and treated internally as being binding. The court should recognize that maintaining the nonprofit\u2019s governance is essential to preserving OpenAI\u2019s unique structure, which was designed to ensure that artificial general intelligence benefits humanity rather than serving narrow financial interests.\u201d\nArtificial general intelligence, or AGI, is broadly understood to mean AI that can complete any task a human can.\nAccording to the brief, OpenAI often used its structure as a recruitment tool \u2014 and repeatedly assured staff that the nonprofit control was \u201ccritical\u201d in executing its mission. The brief recounts an OpenAI all-hands meeting toward the end of 2020 during which OpenAI CEO Sam Altman allegedly stressed that the nonprofit\u2019s governance and oversight were \u201cparamount\u201d in \u201cguaranteeing that safety and broad societal benefits were prioritized over short-term financial gains.\u201d\n\u201cIn recruiting conversations with candidates, it was common to cite OpenAI\u2019s unique governance structure as a critical differentiating factor between OpenAI and competitors such as Google or Anthropic and an important reason they should consider joining the company,\u201d reads the brief. \u201cThis same reason was also often used to persuade employees who were considering leaving for competitors to stay at OpenAI \u2014 including some of us.\u201d\nThe brief warns that, should OpenAI be allowed to convert to a for-profit, it might be incentivized to \u201c[cut] corners\u201d on safety work and develop powerful AI \u201cconcentrated among its shareholders.\u201d A for-profit OpenAI would have little reason to abide by the \u201cmerge and assist\u201d clause in OpenAI\u2019s current charter, which pledges that OpenAI will stop competing with and assist any \u201cvalue-aligned, safety-conscious\u201d project that achieves AGI before it does, asserts the brief.\nThe ex-OpenAI employees, some of whom were research and policy leaders at the company, join a growing cohort voicing strong opposition to OpenAI\u2019s transition.\nEarlier this week, a group of organizations, including nonprofits and labor groups like the California Teamsters, petitioned California Attorney General Rob Bonta to stop OpenAI from becoming a for-profit. They claimed the company has \u201cfailed to protect its charitable assets\u201d and is actively \u201csubverting its charitable mission to advance safe artificial intelligence.\u201d\nEncode, a nonprofit organization that co-sponsored California\u2019sill-fatedSB 1047AI safety legislation,cited similar concerns in an amicus brieffiled in December.\nOpenAI has said that its conversionwould preserve its nonprofit armand infuse it with resources to be spent on \u201ccharitable initiatives\u201d in sectors such as healthcare, education, and science. In exchange for its controlling stake in OpenAI\u2019s enterprise, the nonprofitwould reportedly stand to reap billions of dollars.\n\u201cWe\u2019re actually getting ready to build the best-equipped nonprofit the world has ever seen \u2014 we\u2019re not converting it away,\u201d the companywrote in a series of posts on Xon Wednesday.\nThe stakes are high for OpenAI, which needs to complete its for-profit conversion by the end of this year or next, or it will\u00a0risk relinquishing some of the capital\u00a0it has raised in recent months,according toreports.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/chatgpt-became-the-most-downloaded-app-globally-in-march/",
        "date_extracted": "2025-04-16T17:28:03.987382",
        "title": "ChatGPT became the most downloaded app globally in March",
        "author": null,
        "publication_date": null,
        "content": "ChatGPT became the world\u2019s most downloaded app in March, excluding games, topping the usual contenders for the No. 1 spot, Instagram and TikTok. This is the first time the app has topped the monthly download charts and ChatGPT\u2019s biggest month ever. According to new data, ChatGPT\u2019s installs jumped 28% from February to March to reach 46 million new downloads during March, app intelligence providerAppfiguresrecently reported.\nThat put the app slightly ahead of Instagram, which fell to the No. 2 position. TikTok followed at No. 3.\nPerhaps helping to drive installs,ChatGPTsaw some notable upgrades in March, including thefirst major upgrade to its image-generation capabilitiesin over a year. This led toa viral moment for ChatGPT in late Marchand early April as users discovered they could generate images and memes in the style of Studio Ghibli, the popular Japanese animation studio behind movies like \u201cMy Neighbor Totoro\u201d and \u201cSpirited Away.\u201d\nOpenAI alsoremoved some safeguardsaround content moderation policies for images in March and upgraded ChatGPT\u2019sAI voice feature.\nAppfigures noted that ChatGPT\u2019s installs have grown 148% year-over-year when comparing the first quarter of 2021 to Q1 2025.\nHowever, the firm speculates that new features weren\u2019t the main driver behind this month\u2019s growth for the popular chatbot.\n\u201cIt\u2019s starting to feel like ChatGPT is becoming a verb, a lot like how Google did in the 2000s, to the point where many don\u2019t think \u2018AI\u2019 but rather \u2018ChatGPT,\u2019\u201d said Appfigures founder and CEO Ariel Michaeli. \u201cSo when there\u2019s excitement about AI \u2014 even about competition like Grok, Manus AI, orDeepSeek\u2014 many who are not swimming in this topic come for AI but really download ChatGPT.\u201d\nBecause of ChatGPT\u2019s brand recognition, it may be harder for other AI chatbots to take off. That\u2019s partly whyAnthropic\u2019s Claudehas poorer performance on this front than ChatGPT. It\u2019s also whyGrokcould do better than other ChatGPT rivals \u2014 not necessarily because it\u2019s better, but because it has someone famous to market it with Elon Musk, and a large platform for distribution with X.\nInstagram, meanwhile, had previously held the No. 2 spot across both the Apple App Store and Google Play in bothJanuaryandFebruaryof this year, while TikTok remained No. 1.\nTo some extent, TikTok\u2019s download growth earlier this year was driven by concerns over apotential U.S. ban, as consumers rushed to download the app in case it disappeared from the app stores. Now, that ban is on hold as President Trumpaims to cut a dealwith China, where TikTok parent ByteDance is based, to keep the app available to U.S. users.\nAhead of this, Instagram had regularly been beating out TikTok for the No. 1 position across global app stores, having been the No. 1 (non-game) app throughout 2024. Instagram\u2019s popularity in the U.S. market has been growing, remaining a fave among U.S. teens.\nFor instance, anew survey of U.S. teensby Piper Sandler released this week found that Instagram is the most-used social app, with 87% monthly usage, compared with 79% for TikTok and 72% for Snapchat.\nIn March, other social apps, including those from Meta, rounded out the top charts, with Facebook and WhatsApp filling out the top five, and others like CapCut, Telegram, Snapchat, and Meta\u2019s Threads in the top 10, alongside Temu.\nIn total, the top 10 apps were downloaded a collective 339 million times in March, higher thanFebruary\u2019s299 million.\n",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/most-downloaded-apps-worldwide-april-2025.png?w=663"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/irelands-data-regulator-investigates-xs-use-of-european-user-data-to-train-grok/",
        "date_extracted": "2025-04-16T17:28:06.392852",
        "title": "Ireland\u2019s data regulator investigates X\u2019s use of European user data to train Grok",
        "author": null,
        "publication_date": null,
        "content": "Ireland\u2019s data regulator, the Data Protection Commission (DPC), said Friday that it has opened an investigation into Elon Musk\u2019s X over the social media platform\u2019s use of personal data collected from European users to train Grok.\nThe DPC will investigate how X processes personal data \u201ccomprised\u201d in publicly accessible posts by European users for the purposes of training generative AI models,according to a Reuters report. The powerful Irish privacy regulator has issued fines to Microsoft, TikTok, and Meta in the past. Its fines to Meta total almost \u20ac3 billion (roughly $3.38 billion).\nX quietlyopted in users to sharing datawith xAI, Musk\u2019s AI company, to train its AI chatbot Grok, in 2024. Last month, Musk announced thatxAI had acquired X.\nIreland\u2019s data regulator can impose fines of up to 4% of a company\u2019s global revenue under the EU\u2019s GDPR rules, which require that companies have a valid legal basis for processing people\u2019s data.\u00a0The agency\u2019s latest inquiry comes after it sought a court order last year to restrict X from processing European user data for AI training.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/podcast/metas-llama-drama-and-how-trumps-tariffs-could-hit-moonshot-projects/",
        "date_extracted": "2025-04-16T17:28:09.171044",
        "title": "No Title Found",
        "author": null,
        "publication_date": null,
        "content": "Meta dropped three new AI modelsover the weekend: Scout, Maverick, and the still-training Behemoth, billed as the next evolution of \u201copen-ish\u201d AI. But instead of excitement, the response was mostly shrugs. Critics called the release underwhelming, saying it lacked the edge expected in today\u2019s breakneck AI race. Meta\u2019s clear attempt to claw back some attention quickly turned messy.Accusations began circulatingon X and Reddit around benchmark tampering, a mystery ex-employee, and large gaps between the models\u2019 public and private performance.\nToday, on TechCrunch\u2019sEquitypodcast, hosts Kirsten Korosec, Max Zeff, and Anthony Ha are unpacking Meta\u2019s rocky rollout, the AI industry\u2019s obsession with looking smart on paper, and why, as Kirsten put it, \u201ccreating something to do well on a test doesn\u2019t always translate to good business.\u201d\nListen to the full episode for:\nEquity will be back next week, so stay tuned!\nEquity is TechCrunch\u2019s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.\u00a0Subscribe to us onApple Podcasts,Overcast,Spotifyand all the casts. You also can follow Equity onXandThreads, at @EquityPod. For the full episode transcript, for those who prefer reading over listening, check out our full archive of episodeshere.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/less-than-a-month-to-get-your-exhibit-table-for-techcrunch-sessions-ai/",
        "date_extracted": "2025-04-16T17:28:11.609158",
        "title": "Less than a month to get your exhibit table for TechCrunch Sessions: AI",
        "author": null,
        "publication_date": null,
        "content": "TechCrunch Sessions: AIis fast approaching. So, what does that mean for you? It means exhibit tables are nearly gone \u2014 and now\u2019s your chance to grab one before they\u2019re all sold out. If you\u2019ve got a game-changing product to showcase to the AI world, don\u2019t keep it quiet.Exhibit your brandin front of the leaders and visionaries of the AI community.\nOn June 5, 1,200 AI leaders, investors, and visionaries will gather at UC Berkeley\u2019s Zellerbach Hall \u2014 and they\u2019re hungry for what\u2019s next. They\u2019re looking for the tools, solutions, and tech that\u2019ll help them move faster and think bigger.\nStep up, show off, and get your brand in front of the right people bybooking your exhibit table here.\nHere\u2019s a glimpse of what you get when you exhibit at TC Sessions: AI. For more details, check out the full offering on theTC Sessions: AI exhibit page.\nTime is running out to secure your exhibit table at TC Sessions: AI. Tables are available until they sell out or until the May 9 deadline \u2014 whichever comes first. Don\u2019t miss your chance to establish your brand in the AI community.Learn more and book your table here.\nExplore additional opportunities to showcase your brand at other TechCrunch events.\nTechCrunch All Stageis designed for 1,200+ founders and VCs at every stage of their journey \u2014 whether they\u2019re looking to launch their idea, accelerate scaling, or prepare for an exit. Showcase your brand and connect with key decision-makers who are looking for a brand like yours \u2014book your exhibit table at TC All Stage here.\nDisrupt 2025is our flagship conference, bringing together over 10,000 tech leaders, VCs, and visionaries across industries like fintech, AI, space, building, scaling, investing, and more. Get in front of thousands of key industry leaders \u2014reserve your exhibit table at Disrupt 2025 here before they sell out.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/54102067834_19faf52edb_o.jpg?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/03/Disrupt-2024-Exhibitors_Nebius.jpg?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/01/Google-Exhibit-Disrupt-2025.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/chatgpt-everything-to-know-about-the-ai-chatbot/",
        "date_extracted": "2025-04-16T17:28:14.065678",
        "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
        "author": null,
        "publication_date": null,
        "content": "ChatGPT, OpenAI\u2019s text-generating AI chatbot, has taken the world by storm since its launchin November 2022.What started as a tool to supercharge productivity through writing essays and code withshort text promptshas evolved into a behemoth with300 million weekly active users.\n2024 was a big year for OpenAI, from itspartnership with Applefor its generative AI offering,Apple Intelligence,the release ofGPT-4o with voice capabilities,and the highly-anticipated launch of itstext-to-video model Sora.\nOpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder andlongtime chief scientist Ilya SutskeverandCTO Mira Murati.OpenAI has also been hit with lawsuits fromAlden Global Capital-owned newspapersalleging copyright infringement, as well asan injunction from Elon Muskto halt OpenAI\u2019s transition to a for-profit.\nIn 2025, OpenAI is battling the perception that it\u2019s ceding ground in the AI race toChinese rivals like DeepSeek. The company has been trying to shore up itsrelationship with Washingtonas it simultaneouslypursues an ambitious data center project,and as itreportedly lays the groundworkfor one of the largest funding rounds in history.\nBelow, you\u2019ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we\u2019ve been updating throughout the year. If you have any other questions, check outour ChatGPT FAQ here.\nTo see a list of 2024 updates,go here.\n\nOpenAI may launch several new AI models, including GPT-4.1, as early as next week, The Vergereported, citing anonymous sources. GPT-4.1 would be an update of OpenAI\u2019s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.\nOpenAIstarted updating ChatGPTto enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.\nIt looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blahospotteda new \u201cImageGen\u201d watermark feature in the new beta of ChatGPT\u2019s Android app. Blaho also found mentions of other tools: \u201cStructured Thoughts,\u201d \u201cReasoning Recap,\u201d \u201cCoT Search Tool,\u201d and \u201cl1239dk1.\u201d\nOpenAI is offering its $20-per-monthChatGPT Plussubscription tier for free to all college studentsin the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI\u2019s premium service, which offers access to the company\u2019s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.\nMore than 130 million users have created over 700 million images since ChatGPT gotthe upgraded image generatoron March 25, according toCOO of OpenAI Brad Lightcap. The image generator was made availableto all ChatGPT userson March 31, and went viral for being able to create Ghibli-style photos.\nThe Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI\u2019s o3 \u201creasoning\u201d model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher,possibly around $30,000 per task.\nIn aseriesof postson X, OpenAI CEO Sam Altman said the company\u2019s new image-generation tool\u2019s popularity may cause product releases to be delayed. \u201cWe are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,\u201d he wrote.\nOpeanAIintends to release its \u201cfirst\u201d open language modelsinceGPT-2\u201cin the coming months.\u201d The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.\nOpenAImade a notable change to its content moderation policiesafter the success of its new image generator in ChatGPT, which went viral for being able to createStudio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now \u201cevolved\u201d its approach, as statedin a blog postpublished by Joanne Jang, the lead for OpenAI\u2019s model behavior.\nOpenAIwants to incorporate Anthropic\u2019s Model Context Protocol (MCP)into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEOSam Altman said.\nThe latest update of the image generator on OpenAI\u2019s ChatGPThas triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like \u201cMy Neighbor Totoro\u201d and \u201cSpirited Away.\u201d The burgeoning mass of Ghibli-esque images havesparked concerns aboutwhether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization.\nOpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloombergreported, citing an anonymous source. While the startup doesn\u2019t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said.\nOpenAI onTuesdayrolled out a major upgrade to ChatGPT\u2019s image-generation capabilities: ChatGPT can now usethe GPT-4omodel to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI\u2019s AI video-generation tool, for subscribers of the company\u2019s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company\u2019s API service. The company\u2019s CEOSam Altman said on Wednesday,however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.\nBrad Lightcap, OpenAI\u2019s chief operating officer, will lead the company\u2019s global expansion and manage corporate partnershipsas CEO Sam Altman shifts his focus to research and products, accordingto a blog postfrom OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.\nOpenAIhas updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company\u2019sofficial media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT\u2019s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are \u201cmore direct, engaging, concise, specific, and creative,\u201da spokesperson from OpenAI told TechCrunch.\nOpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country,per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI\u2019s ChatGPT. Reliance has proposed selling OpenAI\u2019s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.\nNoyb, a privacy rights advocacy group, is supporting an individual in Norwaywho was shocked to discover that ChatGPTwas providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. \u201cThe GDPR is clear. Personal data has to be accurate,\u201d said Joakim S\u00f6derberg, data protection lawyer at\u00a0Noyb, in a statement. \u201cIf it\u2019s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn\u2019t enough. You can\u2019t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.\u201d\nOpenAIhas added new transcription and voice-generating AI models to its APIs: a text-to-speech model, \u201cgpt-4o-mini-tts,\u201d that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called \u201cgpt-4o-transcribe\u201d and \u201cgpt-4o-mini-transcribe\u201d. The company claims they are improved versions of what was already there and that they hallucinate less.\nOpenAIhas introduced o1-proin its developer API. OpenAI says its o1-pro uses more computing than itso1 \u201creasoning\u201d AI modelto deliver \u201cconsistently better responses.\u201d It\u2019s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much asOpenAI\u2019s GPT-4.5for input and 10 times the price of regular o1.\nNoam Brown, who heads AI reasoning research at OpenAI,thinks that certain types of AI models for \u201creasoning\u201d could have been developed 20 years agoif researchers had understood the correct approach and algorithms.\nOpenAI CEO Sam Altman said, in apost on X, that the company hastrained a \u201cnew model\u201d that\u2019s \u201creally good\u201d at creative writing. He posted a lengthy sample from the model given the prompt \u201cPlease write a metafictional literary short story about AI and grief.\u201d OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.And it turns out that itmight not be that greatat creative writing at all.\nwe trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.PROMPT:Please write a metafictional literary short story\u2026\nOpenAIrolled out new toolsdesignedto help developers and businesses build AI agents\u2014 automated systems that can independently accomplish tasks \u2014 using the company\u2019s own AI models and frameworks. The tools are part of OpenAI\u2019s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar toOpenAI\u2019s Operator product. The Responses API effectively replacesOpenAI\u2019s Assistants API, which the company plans to discontinue in the first half of 2026.\nOpenAIintends to release several \u201cagent\u201d productstailored for different applications, including sorting and ranking sales leads and software engineering, according toa report from The Information. One, a \u201chigh-income knowledge worker\u201d agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting \u201cPhD-level research,\u201d are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It\u2019s unclear when these agentic tools might launch or which customers will be eligible to buy them.\nThe latest version of the macOS ChatGPT appallows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.\nAccording toa new reportfrom VC firm Andreessen Horowitz (a16z), OpenAI\u2019s AI chatbot, ChatGPT,experienced solid growth in the second half of 2024.It took ChatGPT nine months to increase its weekly active users from100 million in November 2023to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT\u2019s weekly active users increased to300 million by December 2024and400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model\u2019s launch.\nOpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a \u201csimplified\u201d product offering. In apost on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that \u201cintegrates a lot of [OpenAI\u2019s] technology,\u201d including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.\nAcommonly cited statis that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI\u2019s latest default model for ChatGPT, GPT-4o, as a reference, nonprofitAI research institute Epoch AIfound the average ChatGPT queryconsumes around 0.3 watt-hours.However, the analysis doesn\u2019t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.\nIn response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicatesits step-by-step \u201cthought\u201d process.ChatGPT users will see an updated \u201cchain of thought\u201d that shows more of the model\u2019s \u201creasoning\u201d steps and how it arrived at answers to questions.\nOpenAI is now allowing anyone to use ChatGPT web searchwithout having to log in.While OpenAIhad previously allowedusers to ask ChatGPT questions without signing in, responses were restricted to the chatbot\u2019s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.\nOpenAI announced a new AI \u201cagent\u201dcalled deep researchthat\u2019s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the \u201cagent\u201d is intended for instances where you don\u2019t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.\nOpenAI used the subreddit r/ChangeMyView tomeasure the persuasive abilitiesof its AI reasoning models. OpenAI says it collects userposts from the subredditand asks its AI models to write replies, in a closed environment, that would change the Reddit user\u2019s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models\u2019 responses to human replies for that same post.\nOpenAI launched a newAI \u201creasoning\u201d model, o3-mini,the newest in the company\u2019s o family of models. OpenAI firstpreviewed the model in Decemberalongside a more capable system called o3. OpenAI is pitching its new model as both \u201cpowerful\u201d and \u201caffordable.\u201d\nA new report from app analytics firm Appfigures found thatover half of ChatGPT\u2019s mobile usersare under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.\nOpenAI launched ChatGPT Govdesigned to provide U.S. government agenciesan additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI\u2019s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI\u2019s tools for the handling of non-public sensitive data.\nYounger Gen Zers are embracing ChatGPT, for schoolwork,according to a new survey by the Pew Research Center.In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they\u2019ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it\u2019s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.\nOpenAI says that it might store chats and associated screenshots from customers who use Operator,the company\u2019s AI \u201cagent\u201d tool,for up to 90 days \u2014 even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days,which is 60 days shorter than Operator\u2019s.\nOpenAI is launching a research preview of Operator, a general-purpose AI agent that cantake control of a web browser and independently perform certain actions.Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.\nOperator,OpenAI\u2019s agent tool,could be released sooner rather than later. Changes to ChatGPT\u2019s code base suggest thatOperator will be available as an early research previewto users on the $200 Pro subscription plan. The changes aren\u2019t yet publicly visible, buta user on X who goes by Choispotted these updates in ChatGPT\u2019s client-side code. TechCrunch separately identified the same references to Operator on OpenAI\u2019s website.\nOpenAI has begun testing a feature that lets new ChatGPT userssign up with only a phone number\u2014 no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can\u2019t upgrade to one of OpenAI\u2019s paid plans without verifying their account via an email. Multi-factor authentication also isn\u2019t supported without a valid email.\nChatGPT\u2019s new beta feature, called tasks,allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.\nOpenAI is introducing a new way for users tocustomize their interactions with ChatGPT.Some users found they can specify a preferred name or nickname and \u201ctraits\u201d they\u2019d like the chatbot to have. OpenAI suggests traits like \u201cChatty,\u201d \u201cEncouraging,\u201d and \u201cGen Z.\u201d However,some users reportedthat the new options have disappeared, so it\u2019s possible they went live prematurely.\nChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startupOpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.\nNovember 30, 2022 is when ChatGPT was released for public use.\nBoth the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model isGPT-4o.\nThere is a free version ofChatGPTthat only requires a sign-in in addition to the paid version,ChatGPT Plus.\nAnyone can use ChatGPT! More and more tech companies andsearch enginesare utilizing the chatbot to automate text or quickly answer user questions/concerns.\nMultiple enterprises utilize ChatGPT, although others maylimit the use of the AI-powered tool.\nMost recently,Microsoft announcedat its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startupLooking Glass utilizes ChatGPTto produce holograms you can communicate with by using ChatGPT.\u00a0 And nonprofit organizationSolana officially integrated the chatbotinto its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.\nGPT stands for Generative Pre-Trained Transformer.\nA chatbot can be any software/system that holds dialogue with you/a person but doesn\u2019t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they\u2019ll give canned responses to questions.\nChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.\nYes.\nDue to the nature of how these models work, they don\u2019t know or care whether something is true, only that it looks true. That\u2019s a problem when you\u2019re using it to do your homework, sure, but when it accuses you of a crime you didn\u2019t commit, that may well at this point be libel.\nWe will see howhandling troubling statements produced by ChatGPTwill play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.\nYes,there is a free ChatGPT mobile appfor iOS and Android users.\nIt\u2019s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.\nYes, it wasreleasedMarch 1, 2023.\nEveryday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.\nAdvanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.\nIt depends on the nature of the program. While ChatGPT can write workable Python code, it can\u2019t necessarily program an entire app\u2019s worth of code. That\u2019s because ChatGPT lacks context awareness \u2014 in other words, the generated code isn\u2019t always appropriate for the specific context in which it\u2019s being used.\nYes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.\nYes. There aremultiple AI-powered chatbotcompetitors such asTogether, Google\u2019sGeminiand Anthropic\u2019sClaude, and developers arecreating open sourcealternatives.\nOpenAI has\u00a0said\u00a0that individuals in \u201ccertain jurisdictions\u201d (such as the EU) can object to the processing of their personal information by its AI models by filling outthis form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression \u201cin accordance with applicable laws\u201d.\nThe web form for making a deletion of data about you request is entitled \u201cOpenAI Personal Data Removal Request\u201d.\nIn its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on \u201clegitimate interest\u201d (LI), pointing users towards more information about requesting an opt out \u2014 when it writes: \u201cSeeherefor instructions on how you can opt out of our use of your information to train our models.\u201d\nRecently, Discord announced that it had integrated OpenAI\u2019s technology into its bot named Clyde wheretwo users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine(meth) and the incendiary mixture napalm.\nAn Australian mayor has publicly announcedhe may sue OpenAI for defamationdue to ChatGPT\u2019s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.\nCNET found itself in the midst of controversy afterFuturism reportedthe publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, wasaccusedof using ChatGPT for SEO farming, even if the information was incorrect.\nSeveral major school systems and colleges,including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim thatnot every educator agrees with.\nThere have also been cases of ChatGPTaccusing individuals of false crimes.\nSeveral marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One isPromptBase. Another isChatX. More launch every day.\nPoorly. Several tools claim to detect ChatGPT-generated text, but in ourtests, they\u2019re inconsistent at best.\nNo. But OpenAIrecentlydisclosed a bug, since fixed, that exposed the titles of some users\u2019 conversations to other people on the service.\nNone specifically targeting ChatGPT. But OpenAI isinvolvedin at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.\nYes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/11/openai-is-winding-down-its-gpt-4-ai-model-in-chatgpt/",
        "date_extracted": "2025-04-16T17:28:16.388392",
        "title": "OpenAI will soon phase out GPT-4 from ChatGPT",
        "author": null,
        "publication_date": null,
        "content": "OpenAI will soon retire GPT-4, an AI model it launched over two years ago, from ChatGPT, according toa changelog posted on Thursday.\nEffective April 30, GPT-4 will be \u201cfully replaced\u201d byGPT-4o, the current default model in ChatGPT, OpenAI said. GPT-4 will remain available for use via OpenAI\u2019s API.\n\u201cIn head\u2011to\u2011head evaluations, [GPT-4o] consistently surpasses GPT\u20114 in writing, coding, STEM, and more,\u201d wrote OpenAI in the changelog. \u201cRecent upgrades have further improved GPT\u20114o\u2019s instruction following, problem solving, and conversational flow, making it a natural successor to GPT\u20114.\u201d\nGPT-4was rolled out in March 2023 for ChatGPT and Microsoft\u2019s Copilot chatbot on the web. Several versions of GPT-4 had multimodal capabilities, allowing them to understand both images and text \u2014 the first for a widely deployed OpenAI model.\nOpenAI CEO Sam Altman has said that GPT-4, reportedly massive in size, cost more than $100 million to train. It was succeeded by GPT-4 Turbo in November 2023, a faster and cheaper model.\nGPT-4 is one of the models at the heart of copyright disputes between OpenAI and publishers thatinclude The New York Times. Publishers allege that OpenAI trained GPT-4 on their data without their knowledge or consent. OpenAI claims that fair use doctrine shields it from liability.\nGPT-4\u2019s coming retirement will likely follow the release of new models in ChatGPT.According to reverse engineer Tibor Blaho, OpenAI is readying a family of models called GPT-4.1 \u2014 GPT-4.1-mini, GPT-4.1-nano, and GPT-4.1 \u2014 as well as theo3\u201creasoning\u201d model the company announced in December, and a new reasoning model calledo4-mini.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/how-chef-robotics-found-success-by-turning-away-its-original-customers/",
        "date_extracted": "2025-04-16T17:28:18.853540",
        "title": "How Chef Robotics found success  by turning away its original customers",
        "author": null,
        "publication_date": null,
        "content": "A few years ago, Chef Robotics was facing potential death.\n\u201cThere were a lot of dark periods where I was thinking of giving up,\u201d founder Rajat Bhageria tells TechCrunch of his six-year-old company. But friends and investors encouraged him, so he persevered.\nToday, Chef Robotics has not only survived, it\u2019s one of the few food tech robotic companies that is thriving. The startup, which recently raised a $20.6 million Series A, has 40 employees and marquee customers like Amy\u2019s Kitchen and Chef Bombay. Dozens of robots installed across the U.S. have made 45 million meals to date, Bhageria says.\nThis compares to a graveyard of failed food tech robotics companies, includingChowbotics with its salad-making robot Sally;pizza delivery robot Zume; food kiosk robotKarakuri, and, more recently, agtechSmall Robot Company.\nBhageria says he saved his company by doing something that early-stage founders fear to do: turning away signed customers and millions of dollars in revenue.\nIt all began when Bhageria did his master\u2019s degree in robotics atUPenn\u2019s famed GRASP Lab. He dreamed of the sci-fi promised world where robots did our housework, mowed our lawns, and cooked us five-star dinners.\nSuch a world doesn\u2019t exist yet because engineers have yet to fully solve the roboticgrasping problem. Training the same robot to wash a wine glass without crushing it and a cast iron pan without dropping it is a difficult task.\nWhen it comes to robotic chefs, \u201cNobody\u2019s built a dataset of how do you pick up a blueberry and not squish it, or, how do you pick up cheese and not have it clump up?\u201d he describes.\nHis original idea with Chef Robotics was similar to the long-list of the robotics startups that died: a robotic line for fast casual restaurants. That\u2019s an enormous industrywith a chronic employee shortage.\n\u201cWe actually had signed contracts. Like we had multimillion-dollar signed contracts. Obviously, we\u2019re not doing this anymore. So what happened?\u201d he said. \u201cWe essentially could not solve the technical problem.\u201d\nIn those types of businesses, an employee completes an order by assembling all the varied ingredients necessary for each meal. These restaurants want robots to replicate that process because the alternative is to have dozens of robots dedicated to, and calibrated for, a single ingredient, some of which may only be used occasionally (we\u2019re looking at you, anchovies).\nBut Bhageria and team couldn\u2019t build a successful pick-up-anything robot because the training data doesn\u2019t exist. He asked his potential customers to let him install robots for one or two ingredients, gathering training data and building from there. They said no.\nThen Bhageria had an epiphany.\nInstead of going bust trying to give existing customers what they wanted, maybe he needed different customers. \u201cIt honestly sucked, because I spent the last year and a half of my life trying to convince these people, these fast casual companies, to work up with us,\u201d he recalled.\nIt didn\u2019t help that fundraising after 2021 was brutal. VCs were also looking at the graveyard. \u201cWe talked to dozens of different funds,\u201d Bhageria said. \u201cWe just got rejected over and over.\u201d\nBhageria was thinking of giving up. \u201cYou come home and are like, what am I doing in my life? Am I doing the wrong thing? Should I quit?\u201d he remembered.\nBut he dug in andin March, 2023, raised an $11.2 million seed roundled by Construct Capital, while also landing checks from Promus Ventures, Kleiner Perkins, and Gaingels.\nBhageria and team also found their perfect market, a part of the food industry known as \u201chigh mix manufacturing.\u201d\nThese are food makers that have many, many recipes, and make thousands of servings, but typically as meals or meal trays. For instance; salads and sandwiches or main courses and side dishes. These are meals used by airlines and hospitals, etc., or are frozen food meals for consumers.\nRather than one employee grabbing all the ingredients for each meal, \u201chigh mix\u201d employees form an assembly line. Each person adds their individual ingredient to the tray repeatedly until the order is complete. Then they assemble the next recipe.\n\u201cIt\u2019s actually hundreds of humans who are standing in a 34 Fahrenheit room, and they\u2019re essentially scooping food for eight hours a day,\u201d he describes. \u201cSo it\u2019s just a terrible job.\u201d\nConsequently, this industry has chronic labor shortages as well.\nRobotics wasn\u2019t economically feasible for them in the past\u00a0because of the variety of ingredients involved. But a startup building a flexible-ingredient bot, where the robots are built in partnership with the food maker, works.\nBetter still, \u201cas we learn how to do this chorizo, or we learn peas, or this sauce, or these zucchinis,\u201d the bots get the real-world training data they need to eventually serve fast-casual restaurants. Bhageria says this is still on his roadmap.\nBest of all, thanks to VC\u2019s reborn interest in all things AI, fundraising this time was \u201cweirdly\u201d easy, Bhageria says.\nAvataar Venture Partners, co-founded by former Norwest VC Mohan Kumar, was specifically looking to fund \u201cAI in the physical world\u201d startups and actually pursued Chef Robotics, Bhageria says. He closed this round in less than a month. Avataar led, with existing investors Construct Capital, Bloomberg Beta, and Promus Ventures piling in,among others.\nThe new funding brings Chef\u2019s total raised to $38.8 million. He also signed a  new $22.5 million loan from Silicon Valley Bank for equipment financing, bringing Chef\u2019s total debt raised to $26.76 million.\nAnd the process this time was \u201cexhilarating,\u201d he said.\nNote: This story was updated to reflect updated equity and debt totals.\n",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/Chef-Robotics-founder-Rajat-Bhageria.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/deepmind-ceo-demis-hassabis-says-google-will-eventually-combine-its-gemini-and-veo-ai-models/",
        "date_extracted": "2025-04-16T17:28:21.304032",
        "title": "DeepMind CEO Demis Hassabis says Google will eventually combine its Gemini and Veo AI models",
        "author": null,
        "publication_date": null,
        "content": "In a recent appearance onPossible, a podcast co-hosted by LinkedIn co-founder Reid Hoffman, Google DeepMind CEO Demis Hassabis said the search giant plans to eventually combine itsGeminiAI models with itsVeovideo-generating models to improve the former\u2019s understanding of the physical world.\n\u201cWe\u2019ve always built Gemini, our foundation model, to be multimodal from the beginning,\u201d Hassabis said, \u201cAnd the reason we did that [is because] we have a vision for this idea of a universal digital assistant, an assistant that\u00a0[\u2026] actually helps you in the real world.\u201d\nThe AI industry is moving gradually toward \u201comni\u201d models, if you will \u2014 models that can understand and synthesize many forms of media. Google\u2019s newest Gemini models cangenerate audioas well as images and text, while OpenAI\u2019s default model in ChatGPT can now create images \u2014 including, of course,Studio Ghibli-style art. Amazon hasalso announced plansto launch an \u201cany-to-any\u201d model later this year.\nThese omni models require a lot of training data \u2014 images, videos, audio, text, and so on. Hassabis implied that the video data for Veo is coming mostly from YouTube, a platform that Google owns.\n\u201cBasically, by watching YouTube videos \u2014 a lot of YouTube videos \u2014 [Veo 2] can figure out, you know, the physics of the world,\u201d Hassabis said.\nGoogle previously told TechCrunch its models \u201cmay be\u201d trained on \u201csome\u201d YouTube content in accordance with its agreement with YouTube creators. Reportedly,the company broadened its terms of servicelast year in part to tap more data to train its AI models.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/mira-muratis-ai-startup-is-reportedly-aiming-for-a-massive-2b-seed-round/",
        "date_extracted": "2025-04-16T17:28:23.753501",
        "title": "Mira Murati\u2019s AI startup is reportedly aiming for a massive $2B seed round",
        "author": null,
        "publication_date": null,
        "content": "Thinking Machines Lab, the new AI startup from ex-OpenAI CTO Mira Murati, is reportedly attempting to close one of the largest seed rounds in history.\nBusiness Insider reported on Thursday that Thinking Machines Labhas doubled the target for its seed funding roundto $2 billion. The round, should it close according to plan, would value the company at \u201cat least\u201d $10 billion, per Business Insider\u2019s reporting.\nThinking Machines Lab onlyrecently emerged from stealthand has no product or revenue to speak of. What itdoeshave \u2014 and what\u2019s likely convincing investors to fork over cash \u2014 is dozens of high-profile AI researchers in its ranks.\nJust recently, Bob McGrew, previously OpenAI\u2019s chief research officer, and Alec Radford, a former OpenAI researcher behind many of the company\u2019s more transformative innovations, joined Thinking Machines Lab as advisers.\nThinking Machines Lab previously said it intends to create AI systems that are \u201cmore widely understood, customizable, and generally capable\u201d than those currently available.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/ai-models-still-struggle-to-debug-software-microsoft-study-shows/",
        "date_extracted": "2025-04-16T17:28:26.586282",
        "title": "AI models still struggle to debug software, Microsoft study shows",
        "author": null,
        "publication_date": null,
        "content": "AI models from OpenAI, Anthropic, and other top AI labs are increasingly being used to assist with programming tasks. Google CEO Sundar Pichaisaid in Octoberthat 25% of new code at the company is generated by AI, and Meta CEO Mark Zuckerberghas expressed ambitionsto widely deploy AI coding models within the social media giant.\nYet even some of the best models today struggle to resolve software bugs that wouldn\u2019t trip up experienced devs.\nAnew studyfrom Microsoft Research, Microsoft\u2019s R&D division, reveals that models, including Anthropic\u2019sClaude 3.7 Sonnetand OpenAI\u2019so3-mini,fail to debug many issues in a software development benchmark called SWE-bench Lite. The results are a sobering reminder that, despiteboldpronouncementsfrom companies like OpenAI, AI is still no match for human experts in domains such as coding.\nThe study\u2019s co-authors tested nine different models as the backbone for a \u201csingle prompt-based agent\u201d that had access to a number of debugging tools, including a Python debugger. They tasked this agent with solving a curated set of 300 software debugging tasks from SWE-bench Lite.\nAccording to the co-authors, even when equipped with stronger and more recent models, their agent rarely completed more than half of the debugging tasks successfully. Claude 3.7 Sonnet had the highest average success rate (48.4%), followed by OpenAI\u2019s o1 (30.2%), and o3-mini (22.1%).\nWhy the underwhelming performance? Some models struggled to use the debugging tools available to them and understand how different tools might help with different issues. The bigger problem, though, was data scarcity, according to the co-authors. They speculate that there\u2019s not enough data representing \u201csequential decision-making processes\u201d \u2014 that is, human debugging traces \u2014 in current models\u2019 training data.\n\u201cWe strongly believe that training or fine-tuning [models] can make them better interactive debuggers,\u201d wrote the co-authors in their study. \u201cHowever, this will require specialized data to fulfill such model training, for example, trajectory data that records agents interacting with a debugger to collect necessary information before suggesting a bug fix.\u201d\nThe findings aren\u2019t exactly shocking. Many studies haveshownthat code-generating AI tends to introduce security vulnerabilities and errors,\u00a0owing to weaknesses in areas like the ability to understand programming logic.One recent evaluation of Devin, a popular AI coding tool, found that it could only complete three out of 20 programming tests.\nBut the Microsoft work is one of the more detailed looks yet at a persistent problem area for models. It likely won\u2019t dampeninvestor enthusiasmfor AI-powered assistive coding tools, but with any luck, it\u2019ll make developers \u2014 and their higher-ups \u2014 think twice about letting AI run the coding show.\nFor what it\u2019s worth, a growing number of tech leaders have disputed the notion that AI will automate away coding jobs. Microsoft co-founder Bill Gateshas said he thinks programming as a professionis here to stay. So hasReplit CEO Amjad Masad,Okta CEO Todd McKinnon, andIBM CEO Arvind Krishna.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/DeBug_froggy_bar_chart.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/the-us-secretary-of-education-referred-to-ai-as-a1-like-the-steak-sauce/",
        "date_extracted": "2025-04-16T17:28:29.419820",
        "title": "The US Secretary of Education referred to AI as \u2018A1,\u2019 like the steak sauce",
        "author": null,
        "publication_date": null,
        "content": "U.S. Secretary of Education Linda McMahon attended theASU+GSVSummit this week, where experts in education and technology gathered to discuss how AI will impact learning.\nWhile speaking on a panel about AI in the workforce, McMahon repeatedly referred to AI as \u201cA1,\u201d like thesteak sauce.\n\u201cYou know, AI development \u2014 I mean, how can we educate at the speed of light if we don\u2019t have the best technology around to do that?\u201d she said. \u201cI heard\u00a0\u2026 that there was a school system that\u2019s going to start making sure that first graders, or even pre-Ks, have A1 teaching in every year, starting that far down in the grades. That\u2019s a wonderful thing!\u201d\nIn McMahon\u2019s defense, it doesn\u2019t seem like she actually thinks that artificial intelligence is abbreviated \u201cA1.\u201d During the panel, she said \u201cAI\u201d at first, but became increasingly less consistent.\n\u201cIt wasn\u2019t all that long ago that it was, \u2018We\u2019re going to have internet in our schools!\u2019\u201d she continued. \u201cNow let\u2019s see A1, and how can that be helpful.\u201d\nAI is such a ubiquitous term that it seems hard to imagine how one could forget the correct acronym \u2014 it\u2019s like if a professional athlete referred to Major League Baseball as the \u201cNFL.\u201d\nSometimes people misspeak. Nobody\u2019s perfect. But this feels like a bigger whiff than usual, particularly coming from the Secretary of Education.\n",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/canva-is-adding-an-ai-assistant-coding-and-sheets-to-its-platform/",
        "date_extracted": "2025-04-16T17:28:31.865521",
        "title": "Canva is getting AI image generation, interactive coding, spreadsheets, and more",
        "author": null,
        "publication_date": null,
        "content": "Although there has been significant pushback from artists regarding the proliferation of AI design tools and the content used to train generative models, the companies making the software for creative work are nevertheless building AI into their toolkits. It\u2019s a signal of just how quickly AI has gained importance \u2014 regardless of what their customers say, graphic design software makers clearly seem to think they cannot survive without implementing some form of AI.\nThe latest to double down on that strategy is Canva. The company on Thursday said it is adding a suite of new AI features to its platform, including an AI assistant, the ability to create apps with prompts, support for spreadsheets, and AI-powered editing tools.\nCalled Canva AI, the company\u2019s AI assistant can perform a host of tasks, from creating images according to your instructions, to coming up with design ideas \u2014 say, collateral for social media or mock-ups for printing. It can even write copy and create documents.\nAnd by tapping into a new tool dubbed Canva Code, the assistant can also be prompted to create mini-apps, like interactive maps or custom calculators, that can then be integrated in designs. Canva has partnered with Anthropic for this feature, the Australian design company\u2019s co-founder and chief product officer Cameron Adams told TechCrunch.\n\u201cOver the years, we have encouraged our teams to make interactive prototypes because static mock-ups don\u2019t truly represent the experience we are trying to create with Canva for users. We started seeing teams inside Canva use AI a lot for prototyping. We thought of externalizing it and giving everyone the ability to code easily and create interactive experiences,\u201d Adams said.\nTo be clear, Canva is not the first to do this. Several startups such asCursor,Bolt.new,Lovable, andReplithave attracted lots of customers and attention for enabling users to prompt their way to creating applications. Still, Canva has an incentive to bake such a feature into its software, as it complements its broader selling point as a service used to design everything from marketing collateral to websites.\nCanva is also adding new AI features to its photo editor: One tool allows users to point and click to modify artifacts in photos, while another is a background generator that accounts for lighting and layout. This feature set seems aimed at helping the company compete with tools like Adobe Photoshop, Adobe Lightroom, and Pixelmator (acquired by Apple last year).\nLast year, Canva launched anenterprise-focused productto better serve larger teams with features like single sign-on and access management tools. Now it\u2019s adding spreadsheets to the mix with Canva Sheets.\nBesides the usual spreadsheet features, Canva Sheets comes with a tool called Magic Insights, which, as it says on the tin, surfaces insights gleaned from data on the sheet. There\u2019s also a feature called Magic Charts, which converts raw numbers into charts automatically, complete with brand-specific graphics and logos.\nThe company said Canva Sheets supports integrations with HubSpot, Statista, Google Analytics, and more to let users import data easily.\nCompanies like Adobe, Canva, and Pixlr may be looking to add more value to their offerings, but the fact remains that bringing AI into design tools is causing some tension. Not only are artists worried about their work being used to train AI models without permission, but there\u2019s also a real threat to creative design jobs.\nStill, Adams doesn\u2019t see this as a clash between AI and creativity; rather, he sees this as a moment of growth and opportunity in the field.\n\u201cI think all our jobs will change as AI comes, as different tools are integrated across every specialty, whether it be design, product management, engineering, marketing, or sales,\u201d he said. \u201cI think each job is going to change and adapt to the help they will get from AI tools. We just see a massive opportunity,\u201d Adams said.\nThose changes, it seems, will be here sooner than most expect. Earlier this month, the companylaid off some technical writing staff, nine months after its co-founders reportedly asked employees to use AI apps wherever they could. Adams, however, said that these layoffs were not related to AI tools the company is building, but were an effect of restructuring.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/Canva_AI_Conversation_Mobile_Still-1.jpeg?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/04/Canva_Code_Still.png?w=680",
            "https://techcrunch.com/wp-content/uploads/2025/04/Canva-Sheets.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/livekits-tools-help-power-real-time-communications/",
        "date_extracted": "2025-04-16T17:28:34.353188",
        "title": "LiveKit\u2019s tools power real-time communications, including OpenAI\u2019s Voice Mode",
        "author": null,
        "publication_date": null,
        "content": "A challenge for many tech companies is delivering high-bandwidth, multimodal data \u2014 for example, simultaneous audio and video \u2014 to users in real time without interruptions. Some firms build solutions in-house, but these often require a lot of upkeep and maintenance.\nTo ease the burden, Russ d\u2019Sa and David Zhao createdLiveKit, an open source software package for building apps that can transmit real-time audio and video. They launched the project in 2021 and soon suspected it had business potential.\nIt was a good hunch. LiveKit\u00a0now has \u201cmore than 500 paying customers and over 100,000 developers across its cloud platform and open source products,\u201d according to d\u2019Sa. He also says it\u2019s the \u201cbackbone for roughly 25% of 911 emergency calls in the U.S.\u201d and is \u201cused by large aerospace companies for launch and flight observation, Skydio for police drones teleoperation, and teams at Oracle and Adobe in various government applications.\u201d\nIt all started when \u201clarge companies like Spotify, Oracle, and Reddit were experimenting with\u00a0LiveKit\u00a0and asked us for a cloud-hosted version of it,\u201d d\u2019Sa told TechCrunch. \u201cThink Cloudflare, but for media streaming.\u201d So d\u2019Sa, an early Twitter engineer, and Zhao, former director of engineering at Motorola, decided to turn LiveKit into a startup and launch a managed version of the project: LiveKit Cloud.\nToday, LiveKit, which also powers OpenAI\u2019sChatGPT Voice Mode, offers SDKs, tools, and APIs that allow developers and companies to build streaming video and audio experiences. The startup\u2019s customers include tech giants Spotify, Meta, and Microsoft, as well as Character AI, Speak, and Fanatics.\nThe current focus of the San Jose, California, company is growing its engineering and product teams \u2014 it employs around 50 people \u2014 and expanding its core infrastructure. LiveKit is also developing what d\u2019Sa calls an \u201celastic agent compute service,\u201d meaning a product that can deploy and automatically scale up or down voice \u201cagents\u201d like chatbots.\n\u201cIt turns out what\u00a0LiveKit\u00a0is ultimately building is \u2018AIWS\u2019 \u2014 an AI-native cloud provider,\u201d d\u2019Sa said. \u201cWhat Stripe did for payments,\u00a0LiveKit\u00a0is doing for communications.\u201d\nLiveKit\u2019s financials are quite healthy in the meantime, d\u2019Sa claims. Last year, the company\u2019s run rate was over $10 million. Recently, LiveKit raised $45 million in a Series B round led by Altimeter, with participation from Redpoint Ventures and Hanabi Capital.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/analytics-v2-blog.png?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/openai-updates-chatgpt-to-reference-your-other-chats/",
        "date_extracted": "2025-04-16T17:28:36.804012",
        "title": "OpenAI updates ChatGPT to reference your past chats",
        "author": null,
        "publication_date": null,
        "content": "OpenAI announced on Thursday that it\u2019s starting to roll out a new memory feature in ChatGPT that allows the chatbot to tailor its answers to users based on the contents of their previous conversations.\nThe company says the feature, which appears in ChatGPT\u2019s settings as \u201creference saved memories,\u201d aims to make conversations with ChatGPT more relevant to users. The update will add conversational context to ChatGPT\u2019s text, voice, and image-generation features, the company added.\nThe new memory feature will roll out first to ChatGPT Pro and Plus subscribers, except for those based in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.\u00a0OpenAI says these regions require additional external reviews to comply with local regulations, but the company is committed to making its technology available there eventually.\nOpenAI didn\u2019t have news to share on a launch for free ChatGPT users. \u201cWe are focused on the rollout to paid tiers for now,\u201d a spokesperson told TechCrunch.\nThe aim of the new memory feature is to make ChatGPT more fluid and personal \u2014 you won\u2019t have to repeat information you\u2019ve already shared with ChatGPT. In February, Googlerolled out a similar memory featurein Gemini.\nNot every user will be thrilled with the notion of OpenAI vacuuming up more of their info, of course. Fortunately, there\u2019s an opt-out. In ChatGPT\u2019s settings, users can choose to turn off the new memory feature, as well as manage specific saved memories.\nOpenAI says you can also ask ChatGPT what it remembers, or switch to a Temporary Chat for conversations that won\u2019t get stored.\nLast year, OpenAI updated ChatGPTto forget or remember specific details upon request. However, that feature typically required explicit prompting from users to update ChatGPT\u2019s memory. Today\u2019s rollout makes the process more seamless, in theory.\nOpenAI says that the new memory feature will be enabled by default for users who previously had ChatGPT\u2019s memory capabilities turned on.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/youtube-rolls-out-a-free-ai-music-making-tool-for-creators/",
        "date_extracted": "2025-04-16T17:28:39.718966",
        "title": "YouTube rolls out a free AI music-making tool for creators",
        "author": null,
        "publication_date": null,
        "content": "YouTube is launching a new feature that will allow creators to use AI technology to generate custom instrumental backing music that can be added to their videos. In an update published to itsCreator Insider channelthis week, the company shared that it\u2019s beginning to roll out an update to its Creator Music marketplace that will allow creators to generate new tunes using AI prompts.\nYouTube says the feature is being \u201cgradually\u201d rolled out to creators who have access to Creator Music, the platform\u2019s commercial music licensing resourcelaunched in 2023. The marketplace was designed to make it easier for creators to find music to add to their videos and understand the costs involved in doing so. AI music, however, will give them another free option.\nCreators with access to the new AI feature will see a \u201cMusic Assistant\u201d tab appear in Creator Music. In the free text field, they can describe the type of music they want to create, including by specifying details like instruments, mood, the type of video they\u2019re making, and more. Some suggested prompts are also offered below the field to help users get started.\nAfter the tracks are generated, creators can download them and add them to their videos. YouTube notes that  the music is free to use, so creators will not have to worry about copyright claims.\nCreator Music isavailableto U.S. creators in the YouTube Partner Program.\nYouTube had earlier tested a similar generative AI featurecalled \u201cDream Track\u201d powered byDeepMind\u2019s Lyria, which allowed people to create 30-second music tracks in the style of a famous artist. Currently, the \u201cDream Track\u201d feature is only focused on instrumental music, YouTube\u2019shelp documentationsays.\nThe company clarified to TechCrunch that, as part of the Dream Track suite of experimental AI tools, YouTube introduced the ability to create instrumental soundtracks in both Shorts and YouTube Create last year. It\u2019s now starting to experiment with integrating Dream Track into Creator Music.",
        "tags": [],
        "images": [
            "https://techcrunch.com/wp-content/uploads/2025/04/creator-music-ai-feature.jpg?w=680"
        ]
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/amazon-ceo-andy-jassy-urges-companies-to-invest-heavily-in-ai/",
        "date_extracted": "2025-04-16T17:28:42.435560",
        "title": "Amazon CEO Andy Jassy urges companies to invest heavily in AI",
        "author": null,
        "publication_date": null,
        "content": "Amazon CEO Andy Jassy thinks companies should invest \u201caggressively\u201d in AI now to reap the full financial rewards in the future.\nIn hisannual letter to Amazon shareholderspublished Thursday, Jassy said \u201csubstantial capital\u201d is required to keep up with the pace of AI innovation and customer demand for AI products. He added that Amazon, too, needs to spend this money now if it hopes to see strong returns on its investment years down the line.\nJassy\u2019s comments come after Amazon announced plans during its fourth-quarter earnings call in February to spend more than$100 billion on capital expenditures in 2025. The \u201cvast majority\u201d of that sum will be put toward AWS AI capabilities, Jassy said at the time.\n\u201cWe continue to believe AI is a once-in-a-lifetime reinvention of everything we know,\u201d Jassy wrote in his shareholder letter. \u201cThe demand is unlike anything we\u2019ve seen before, and our customers, shareholders, and business will be well-served by our investing aggressively now.\u201d\nJassy said the biggest AI expenses are currently data centers and chips, but he added that, over time, this infrastructure will start to cost less.\n\u201cIn AWS, the faster demand grows, the more data centers, chips, and hardware we need to procure (and AI chips are much more expensive than CPU chips),\u201d Jassy wrote. \u201cWe spend this capital upfront, even though these assets are useful for many years.\u201d\nJassy offered Amazon\u2019s own Trainium2 chips as an example that prices will go down for AI infrastructure over time. He added that these chips offer 30%-40% better price-performance than the current GPU-powered computing instances generally available today. Trainium2was released in late 2024.\nJassy also said that AI price dynamics will change in the future as the training costs for AI come down and money is instead put toward inference, or actually serving AI models.\n\u201cWe feel strong urgency to make inference less expensive for customers,\u201d Jassy wrote. \u201cMore price-performant chips will help. But, inference will also get meaningfully more efficient in the next couple of years with improvements in model distillation, prompt caching, computing infrastructure, and model architectures.\u201d\nAmazon is currently building more than 1,000 generative AI applications, Jassy said in the shareholder letter. He added that Amazon\u2019s AI revenue is growing at \u201ctriple-digit\u201d year-over-year percentages\u00a0and represents a \u201cmulti-billion-dollar annual revenue run rate.\u201d\nAmazon declined to comment further.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/google-thinks-ai-can-untangle-the-electrical-grids-bureaucracy/",
        "date_extracted": "2025-04-16T17:28:45.140518",
        "title": "Google thinks AI can untangle the electrical grid\u2019s bureaucracy",
        "author": null,
        "publication_date": null,
        "content": "There has been a lot of angst among tech companies and policymakers about alooming power shortageon the grid due in no small part to the rise in AI. But what\u2019s less known is that there are terawatts of new capacity waiting to be approved for connection to the grid, and unknotting the bureaucracy could go a long way to solving the problem.\nAll grid operators in the U.S. face the similar backlogs, but few are as significant as that of PJM, which manages the flow of electricity in the mid-Atlantic states, Ohio, and eastern Kentucky.\nNow, Google and PJM are hoping that AI can help speed things along.\nThe two organizationsannouncedThursday a partnership, along with Alphabet \u201cmoonshot\u201d Tapestry, to develop AI models to streamline key parts of the application process on both sides of the transaction. They\u2019ll get assistance with data verification and submit projects through new, centralized planning tools, which will also help PJM analyze how best to integrate variable power sources like renewables.\nBecause of the surge in computing demand from AI, tech companies have been racing to secure generating capacity.Amazon,Google,Meta, andMicrosofthave all either invested in or pledged to buy significant amounts of nuclear power. But they\u2019ve also beensteadily snapping up solar powerin large quantities.\nThe interconnection problem is wonky, to be sure, but solving it could alleviate concerns aboutunderpowered data centers. Nationwide, 2.6 terawatts of generating capacity are waiting for approval,accordingto the Lawrence Berkeley Lab. That\u2019s double what every U.S. power plant combined is capable of generating today.\nPJM\u2019s queue is by far the longest. There are over 3,000 active requests to connect 286.7 gigawatts of capacity in the region,accordingto the Berkeley Lab. Overwhelmed, the organization stopped accepting applications for new connections in 2022 and won\u2019t review new requests untilmid-2026.\nRenewables have been penalized the most by the sclerotic process.\nNationwide, over 1 terawatt each of solar andstorageare waiting for permission to send electrons to the grid. Even the queue in the PJM region, which isn\u2019t typically considered a hotbed of renewable development, is dominated by the two clean power sources: Just 2.4% of applicants are natural gas power plants.\nThe PJM-managed grid has historically been dominated by fossil fuels. Over the last decade or so, natural gas-fired power plants have displaced coal as fracking drove gas costs down. The grid operator also recently developed anew approval processthat critics argue allows for fossil fuel plants to unfairly skip the line ahead of renewable projects.\nIn unveiling the partnership with Google, PJM Executive Vice President Aftab Khan said that the organization\u2019s grid will remain \u201cfuel agnostic,\u201daccordingto E&E News. Meanwhile, Google spokesperson Amanda Peterson Corio maintained that its was \u201ccommitted to our goals to decarbonize our electricity footprint.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/incident-io-raises-62m-at-a-400m-valuation-to-help-it-teams-move-fast-when-things-break/",
        "date_extracted": "2025-04-16T17:28:47.644576",
        "title": "Incident.io raises $62M at a $400M valuation to help IT teams move fast when things break",
        "author": null,
        "publication_date": null,
        "content": "In the world of tech, some might argue that the term of the decade is AI, but in the bigger scheme of things, beyond this single sector, the most important word may well be \u201cresilience.\u201d How well prepared are people, organizations, and countries for unforeseen, negative economic, geopolitical, social, and environmental developments? It\u2019s a question that\u2019s triggering a lot of scrambling in search of answers.\nThis existential crisis is also playing out in the world of tech. We\u2019re more reliant than ever before on services working \u2014 on uptime, in other words \u2014 and downtime may speak to bigger crises than your email not sending.\nSeizing on that demand in the market, on Thursday, the eponymous startupIncident.io, which has built an all-in-one, AI-based platform to help speed up incident management and response in the fragmented world of IT, announced $62 million in financing.\nIncident.io is based in London with operations also in San Francisco, and it plans to use the new money for hiring, sales, and marketing across both regions.\nInsight Partners is leading the Series B with previous backers Index and Point Nine also participating. (Index led the startup\u2019s $28.7 million Series A inJuly 2022.) With this latest round, Incident.io has now raisedjust over $96 million.\nThe startup is not disclosing valuation, but sources close to the deal tell me it\u2019s in the region of $400 million.\u00a0Incident.io had a valuation of around $300 million roughly three years ago, the sources say.\nStephen Whitworth (CEO), Pete Hamilton (CTO), and Chris Evans (CPO) co-foundedIncident.ioafter working together at fintech Monzo. There, the three helped build pipelines from the ground up, based on open source tooling, to track the performance of the company\u2019s internal and customer-facing services and to help Monzo better respond when something went wrong.\nThey could see that their pain points for identifying and tracking different incidents were similar to those other digital organizations faced, and they decided to strike out on their own to build a platform to address that for the wider industry.\n\u201cMove fast when you break things,\u201d is the company\u2019s tongue-in-cheek motto, and it\u2019s an apt one for any organization.\nThese days, the very smallest businesses use a wide array of digital tools across a variety of architectures, and even an incremental update across one of these tools can trigger glitches that take down entire systems.\nIncident.io\u2019s sweet spot is organizations of users numbering more than 200 people, which typically works out to many thousands of employees overall \u2014 plus, of course, potentially dozens or hundreds of different apps, microservices, and other functions that bind those employees and their work together.\n\u201cThe larger the organization, the more opportunity there is for things to go wrong, whether that\u2019s with technical systems, people, or processes,\u201d Whitworth told TechCrunch in an interview in 2022.\nIncident.io has grown substantially over the years. Netflix, Linear, Ramp, and Etsy are among its current customers. Whitworth told TechCrunch that about three-quarters of the clients it\u2019s adding are in the U.S., and it\u2019s tripled its customer base in the last 12 months. He also said that Incident.io has powered responses and alerts for some 250,000 incidents since it was founded in 2021.\nThe startup has also expanded its product offerings. Incident.io originally made a name for itself by building its primary user interface in Slack. This, Whitworth said, \u201cwas a great place to start, but Slack skews to mostly tech companies,\u201d so as the company has grown and aimed to target other sectors, it has also added support for Microsoft\u2019s Teams as well as its own customized dashboard \u2014 \u201ca compatriot to chat,\u201d Whitworth said.\nThis dashboard will have the most functionality and tracking for resolutions and more, but Incident.io will always keep a presence in third-party chat apps, Whitworth said. \u201cWhen things go wrong, people jump into chat, even more and more now,\u201d he said.\nThe company has also evolved the product in terms of functionality. \u201cReliability and resilience\u201d are still the primary use cases for Incident.io, and typically, infrastructure teams will bring the product in, and it\u2019ll be used by engineers or data specialists. More recently, Incident.io has also seen an influx from security teams adopting it, as well. (Incident.io does not currently have any remediation or other security products, nor does it specifically integrate with them: There are plans for both in the future, Whitworth said.)\nThe startup also added a product in March called On Call to manage how to alert team members in the process of triaging an incident. It directly competes with PagerDuty. Some 70% of Incident.io\u2019s customers are now using it, Whitworth said. There\u2019s an argument for less fragmentation at every level of IT, and\u00a0Incident.io\u00a0is vying to be the company to do it here, in incident response.\nMore recently, Incident.io has also started to weave more AI throughout the platform. It\u2019s doing this in a few areas.\nTypically, when an incident starts to unfold, many will \u201cjump on a Zoom call to discuss it,\u201d Whitworth said, leaving \u201ca poor human\u201d to transcribe that and come up with action items. The company is now offering an AI \u201ccopilot\u201d to handle that work as well as send out requests to services like Datadog to better understand what might be happening with the code.\nOver time, the idea will be to enhance that work to extend as far as remediation.\nThe existing business, plus the roadmap ahead, is what\u2019s brought about this latest investment in Incident.io.\n\u201cIncident.io is building a product that engineers love and organizations rely on to minimize downtime and maximize productivity,\u201d said Thomas Krane, managing director at Insight Partners, in a statement. \u201cBy pioneering AI agents that collaborate with engineers to resolve incidents, they\u2019re not just modernizing\u00a0incident\u00a0response but reinventing it for a world where AI isn\u2019t just writing code; it\u2019s keeping it running.\u201d\nOther high-profile investors in Incident.io include Instagram co-founder and Anthropic CPO Mike Krieger and The Chainsmokers\u2019 Mantis VC.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/the-rise-of-ai-reasoning-models-is-making-benchmarking-more-expensive/",
        "date_extracted": "2025-04-16T17:28:50.094356",
        "title": "The rise of AI \u2018reasoning\u2019 models is making benchmarking more expensive",
        "author": null,
        "publication_date": null,
        "content": "AI labs like OpenAI claim that theirso-called \u201creasoning\u201d AI models, which can \u201cthink\u201d through problems step by step, are more capable than their non-reasoning counterparts in specific domains, such as physics. But while this generally appears to be the case, reasoning models are also much more expensive to benchmark, making it difficult to independently verify these claims.\nAccording to data from Artificial Analysis, a third-party AI testing outfit, it costs $2,767.05 to evaluate OpenAI\u2019so1reasoning model across a suite of seven popular AI benchmarks: MMLU-Pro, GPQA Diamond, Humanity\u2019s Last Exam, LiveCodeBench, SciCode, AIME 2024, and MATH-500.\nBenchmarking Anthropic\u2019s recentClaude 3.7 Sonnet, a \u201chybrid\u201d reasoning model, on the same set of tests cost $1,485.35, while testing OpenAI\u2019so3-mini-highcost $344.59, per Artificial Analysis.\nSome reasoning models are cheaper to benchmark than others. Artificial Analysis spent $141.22 evaluating OpenAI\u2019s o1-mini, for example. But on average, they tend to be pricey. All told, Artificial Analysis has spent roughly $5,200 evaluating around a dozen reasoning models, close to twice the amount the firm spent analyzing over 80 non-reasoning models ($2,400).\nOpenAI\u2019s non-reasoningGPT-4omodel, released in May 2024, cost Artificial Analysis just $108.85 to evaluate, while Claude 3.6 Sonnet \u2014 Claude 3.7 Sonnet\u2019s non-reasoning predecessor \u2014 cost $81.41.\nArtificial Analysis co-founder George Cameron told TechCrunch that the organization plans to increase its benchmarking spend as more AI labs develop reasoning models.\n\u201cAt Artificial Analysis, we run hundreds of evaluations monthly and devote a significant budget to these,\u201d Cameron said. \u201cWe are planning for this spend to increase as models are more frequently released.\u201d\nArtificial Analysis isn\u2019t the only outfit of its kind that\u2019s dealing with rising AI benchmarking costs.\nRoss Taylor, the CEO of AI startup General Reasoning, said he recently spent $580 evaluating Claude 3.7 Sonnet on around 3,700 unique prompts. Taylor estimates a single run-through of MMLU Pro, a question set designed to benchmark a model\u2019s language comprehension skills, would have cost more than $1,800.\n\u201cWe\u2019re moving to a world where a lab reports x% on a benchmark where they spend y amount of compute, but where resources for academics are << y,\u201d said Taylor in arecent post on X. \u201c[N]o one is going to be able to reproduce the results.\u201d\nWhy are reasoning models so expensive to test? Mainly because they generate a lot of tokens. Tokens represent bits of raw text, such as the word \u201cfantastic\u201d split into the syllables \u201cfan,\u201d \u201ctas,\u201d and \u201ctic.\u201d According to Artificial Analysis, OpenAI\u2019s o1 generated over 44 million tokens during the firm\u2019s benchmarking tests, around eight times the amount GPT-4o generated.\nThe vast majority of AI companies charge for model usage by the token, so you can see how this cost can add up.\nModern benchmarks also tend to elicit a lot of tokens from models because they contain questions involving complex, multi-step tasks, according to Jean-Stanislas Denain, a senior researcher at Epoch AI, which develops its own model benchmarks.\n\u201c[Today\u2019s] benchmarks are more complex [even though] the number of questions per benchmark has overall decreased,\u201d Denain told TechCrunch. \u201cThey often attempt to evaluate models\u2019 ability to do real-world tasks, such as write and execute code, browse the internet, and use computers.\u201d\nDenain added that the most expensive models have gotten more expensiveper tokenover time. For example, Anthropic\u2019sClaude 3 Opuswas the priciest model when it was released in May 2024, costing $75 per million output tokens. OpenAI\u2019sGPT-4.5ando1-pro, both of which launched earlier this year, cost $150 per million output tokens and $600 per million output tokens, respectively.\n\u201c[S]ince models have gotten better over time, it\u2019s still true that the cost to reach a given level of performance has greatly decreased over time,\u201d Denain said. \u201cBut if you want to evaluate the best largest models at any point in time, you\u2019re still paying more.\u201d\nMany AI labs, including OpenAI, give benchmarking organizations free or subsidized access to their models for testing purposes. But this colors the results, some experts say \u2014 even if there\u2019s no evidence of manipulation, the mere suggestion of an AI lab\u2019s involvement threatens to harm the integrity of the evaluation scoring.\n\u201cFrom [a] scientific point of view, if you publish a result that no one can replicate with the same model, is it even science anymore?\u201d wrote Taylor in afollow-up post on X. \u201c(Was it ever science, lol)\u201d.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/10/ai-insurtech-ominimo-bags-its-first-investment-at-a-220m-valuation/",
        "date_extracted": "2025-04-16T17:28:52.718777",
        "title": "AI insurtech Ominimo bags its first investment at a $220M valuation",
        "author": null,
        "publication_date": null,
        "content": "How do you get talented engineers to work for a startup in a mundane field at a time when more exciting companies are paying well and hiring aggressively? Here\u2019s an answer from one insurance startup out of Poland calledOminimo: make pay competitive, but more importantly, give those engineers the license to apply their talent and reinvent how the field works.\nLaunched on a bootstrapped budget just 12 months ago, Ominimo believes it\u2019s found a different and better approach to understanding and pricing risk. The company says it\u2019s already profitable and growing fast, with 300,000 policies signed up in its first market of Hungary. Now, to fuel its next stage of life, it\u2019s taking its first outside investment from a strategic backer, Zurich Insurance Group.\nTechCrunch understands from sources that Zurich is making a \u20ac10 million (around $11 million) equity investment for 5% of the company, valuing Ominimo at \u20ac200 million ($220 million). Neither Ominimo nor Zurich commented on the amount invested, but both have confirmed the valuation.\nOminimo has raised funding at a time when one of the most well-known and well-capitalized insurance startups in Europe \u2014 theonce-unicornWeFox \u2014 isselling off parts of its businessand picking uplifeline financingtostay afloat.\nWeFox serves as both a cautionary tale about how to grow an insurance business, but also a clear opportunity. Arguably the reason WeFox grew so fast was because of demand in the market (both from consumers and investors) \u2014 a startup only had to surf that wave without wiping out.\nOminimo is already profitable, but it\u2019s arguably a modest effort. Today the startup is active in just one market, Hungary, and focuses only on one kind of insurance, car insurance for consumers. The plan is to replicate its model in more geographies and categories.\nThe company plans to expand into more than 10 new markets, starting with Poland, Sweden, and the Netherlands. Zurich Insurance will serve as its risk carrier, and Ominimo will operate as a broker, specifically amanaging general agent, for Zurich. The startup is focusing initially on automotive insurance, but intends to add property insurance over time as well.\nDusan Komar, Ominimo\u2019s CEO who co-founded the company with Dennis Weinbender (now chief pricing and data officer) and Laslo Horvath (CTO), saw the challenges the insurance industry faced firsthand when he worked for McKinsey. Major insurance firms, he said, were stuck because of three main issues: rigid legacy systems that were challenging, if not impossible, to use to launch new services quickly or work with newer innovations like AI-based pricing; slow decision-making processes at the corporate level; and talent.\n\u201cNo brilliant software engineer or data scientist dreams of working for an insurance company,\u201d he said.\nMcKinsey and others like it typically get called in to try to fix all three at once. Komar and his team would build new products from the ground up and \u201chand over the code\u201d to the insurance client. \u201cIt worked to some extent, but not as perfectly as we would have hoped,\u201d he said.\nTaking a cue from the worlds of fintech and other insurance startups, Komar and his two co-founders saw an opportunity to develop a product as their own company rather than for a client. They would use APIs to plug in features and functionality from other providers that they might not build themselves, and that is how Ominimo was born.\nOminimo is essentially applying some AI-based reasoning around big-data analytics. When building and pricing an insurance quote, a traditional insurance company might use five or six main parameters (age, economic bracket, type of vehicle, past driving history, or location of car) to determine a price. A newer insurer might add another 10 or 15 parameters to that.\n\u201cBut there are some not-so-obvious variables that are actually super important,\u201d Komar said. For instance, once you get the license plate of a vehicle, you can tap into a database, he said, which gives you 100 different variables about the vehicle, including the length, height, width, and weight of the vehicle. \u201cIt\u2019s interesting, for instance, to see that data shows a very strong correlation between the length of the car and the frequency of accidents during parking,\u201d he said.\nOminimo takes all of these details, plus population density and more, into account to perform its calculations.\nThere are, of course, a lot of insurance startups in the market already that tout the use of AI across their platforms, both for decision-making in the back-end and to improve customer experience at the front-end. Ditto the existence of dozens of startups in fintech that also lay claim to being built on AI.\nKomar\u2019s response to this is that Ominimo\u2019s track record speaks for itself. \u201cI think what really matters is actually performance in the market, so if you compare our performance to Lemonade\u2019s [a key competitor], you will actually see the difference,\u201d he said. He claimed that Ominimo\u2019s \u201closs ratio\u201d is below the market average, and it\u2019s already picked up a market share of 7% in Hungary, the only country where it operates.\nAs with a lot of the neobanks in the market \u2014 fintech and insurance really do have a lot in common \u2014 many \u201cnew\u201d insurance players are doing less disruption under the hood as they are creating a more modern user experience.\n\u201cThere is a difference between claiming to do data science in terms of risk assessment, and actually doing it,\u201d he said. Many of his startup competitors, he believes, \u201chave actually focused on superior customer experience, very nice front-ends, very lean and intuitive journeys. But there was not a lot under the hood.\u201d\nGiving talent a place to do the kind of work they want to be doing, he claimed, is how Ominimo has attracted and retained key people. \u201cWe have eight medalists from mathematics and physics Olympiads [prestigious competitions in these fields] among our data science team,\u201d he said. \u201cThese are really brilliant young minds who now, for the first time, get to deploy their full potential on a global scale. And this really shows in the KPIs that we see.\u201d\nThat is also what attracted Zurich Insurance, which is looking for more diversified ways to bring in new waves of customers.\n\u201cGrowing our retail business profitably is a key ambition in Zurich\u2019s 2025-2027 cycle. That is why I am delighted with DA Direkt\u2019s distribution partnership with\u00a0Ominimo, which will allow us to offer innovative motor insurance solutions and expand our retail customer base in Europe, beyond the markets in which Zurich is already present,\u201d said Alison Martin, CEO of Europe, Middle East and Africa at Zurich Insurance Group, in a statement. \u201cI am also pleased we are strengthening our relationship with a minority stake in\u00a0Ominimo.\u201d",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/09/elon-musks-ai-company-xai-launches-an-api-for-grok-3/",
        "date_extracted": "2025-04-16T17:28:55.435017",
        "title": "Elon Musk\u2019s AI company, xAI, launches an API for Grok 3",
        "author": null,
        "publication_date": null,
        "content": "Billionaire Elon Musk hasjust been countersued by OpenAI, but that isn\u2019t stopping his AI company, xAI, frommaking its flagship Grok 3 model available via an API.\nIt has been several months since xAI unveiledGrok 3, the company\u2019s answer to models like OpenAI\u2019sGPT-4oand Google\u2019sGemini. Grok 3 can analyze images and respond to questions, and it powers a number of features on Musk\u2019s social network X, whichnot so coincidentally was acquired by xAI in March.\nxAI is offering two flavors of its flagship model via its API: Grok 3 and Grok 3 Mini with \u201creasoning\u201d capabilities.\nGrok 3 is priced at $3 per million tokens (~750,000 words) fed into the model and $15 per million tokens generated by the model. Meanwhile, Grok 3 Mini will cost $0.30 per million input tokens and $0.50 per million output tokens.\nSpeedier versions of Grok 3 and Grok 3 Mini are available at a premium: $5 per million input tokens and $25 per million output tokens for Grok 3 and $0.60 per million input tokens and $4 per million output tokens for Grok 3 Mini.\nGrok 3 isn\u2019t cheap relative to the competition. xAI is matching the pricing of Anthropic\u2019sClaude 3.7 Sonnet, which also offers reasoning capabilities, but it is more expensive than Google\u2019s recently releasedGemini 2.5 Pro, which achieves generally higher scores than Grok 3 across popular AI benchmarks. (Notably, xAI has been accused ofbeing misleadingin its Grok 3 benchmark reports.)\nAsseveral users on X pointed out, Grok 3 via xAI\u2019s API also has a smaller context window than the model is supposedly capable of supporting. (\u201cContext window\u201d refers to how many tokens the model can process in one go.) The API maxes out at 131,072 tokens, or roughly 97,500 words \u2014 short of the 1 million tokens xAI claimed that Grok 3 supported in late February.\nWhen Musk announced Grok roughly two years ago, he pitched the AI model as edgy, unfiltered, and anti-\u201cwoke\u201d \u2014 in general, willing to answer controversial questions other AI systems won\u2019t. He delivered on some of that promise. Told to be vulgar, for example, Grok and Grok 2 would happily oblige, spewing colorful language you likely wouldn\u2019t hear fromChatGPT.\nBut Grok models prior to Grok 3hedgedon political subjects and wouldn\u2019t crosscertain boundaries. In fact,one studyfound that Grok leaned to the political left on topics like transgender rights, diversity programs, and inequality.\nMusk has blamed that behavior on Grok\u2019s training data \u2014 public web pages \u2014 andpledgedto \u201cshift Grok closer to politically neutral.\u201d Short of high-profile mistakes likebriefly censoring unflattering mentions of President Donald Trump and Musk, it\u2019s not yet clear whether xAI has achieved that goal at the model level and what the long-term consequences might be.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/09/google-says-itll-embrace-anthropics-standard-for-connecting-ai-models-to-data/",
        "date_extracted": "2025-04-16T17:28:57.922126",
        "title": "Google to embrace Anthropic\u2019s standard for connecting AI models to data",
        "author": null,
        "publication_date": null,
        "content": "Just a few weeksafter OpenAI said it would adopt rival Anthropic\u2019s standard for connecting AI models to the systems where data resides, Google is following suit.\nIn a post on X on Wednesday, Google DeepMind CEO Demis Hassabis said Google would add support forAnthropic\u2019s Model Context Protocol, or MCP, to its Gemini models and SDK. He did not specify a timeline for when this would be done.\n\u201cMCP is a good protocol and it\u2019s rapidly becoming an open standard for the AI agentic era,\u201d wrote Hassabis. \u201cLook forward to developing it further with the MCP team and others in the industry.\u201d\nMCP lets models draw data from sources like business tools and software to complete tasks, as well as from content repositories and app development environments. The protocol enables developers to build two-way connections between data sources and AI-powered applications, such as chatbots.\nDevelopers can expose data through \u201cMCP servers\u201d and build \u201cMCP clients\u201d \u2014 for instance, apps and workflows \u2014 that connect to those servers on command. In the months since Anthropic open sourced MCP, companies including Block, Apollo, Replit, Codeium, and Sourcegraph have added support for the protocol to their platforms.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/09/openai-attorneys-call-for-musk-to-be-enjoined-from-further-unlawful-and-unfair-action/",
        "date_extracted": "2025-04-16T17:29:00.394938",
        "title": "OpenAI countersues Elon Musk, calls for enjoinment from \u2018further unlawful and unfair action\u2019",
        "author": null,
        "publication_date": null,
        "content": "The dramatic tiff between OpenAI and its estranged co-founder, billionaire Elon Musk, shows no sign of letting up.\nIn a filing on Wednesday, attorneys for OpenAI and other defendants in the case, including CEO Sam Altman, called for Musk to be enjoined from \u201cfurther unlawful and unfair action\u201d and \u201cheld responsible for the damage he has already caused\u201d to the defendants.\n\u201cOpenAI is resilient,\u201d reads the filing for a countersuit. \u201cBut Musk\u2019s actions have taken a toll. Should his campaign persist, greater harm is threatened \u2014 to OpenAI\u2019s ability to govern in service of its mission, to the relationships that are essential to furthering that mission, and to the public interest [\u2026] Musk\u2019s continued attacks on OpenAI, culminating most recently in [a] fake takeover bid designed to disrupt OpenAI\u2019s future, must cease.\u201d\nIn an emailed statement, Marc Toberoff, an attorney for Musk, said, \u201cHad OpenAI\u2019s board genuinely\u00a0considered [Musk\u2019s bid for the company\u2019s nonprofit earlier this year] as they were obligated to do, they would have seen how serious it was. It\u2019s telling that having to pay fair market value for OpenAI\u2019s assets allegedly \u2018interferes\u2019 with their business plans.\u201d\nElon\u2019s nonstop actions against us are just bad-faith tactics to slow down OpenAI and seize control of the leading AI innovations for his personal benefit. Today, we counter-sued to stop him.\n\u2014 OpenAI Newsroom (@OpenAINewsroom)April 9, 2025\n\nMusk\u2019s suit against OpenAI accuses the startup of abandoning its non-profit mission, which aimed to ensure its AI research benefits all humanity. OpenAI was founded as a non-profit in 2015, but it was converted to a \u201ccapped-profit\u201d structure in 2019, and now its management is trying to restructure it once more into a public benefit corporation.\nMusk had sought a preliminary injunction tohalt OpenAI\u2019s transition to a for-profit corporation. In March, a federal judgedenied the request, but permitted the case to go to a jury trial in spring 2026.\nMusk, once a key supporter of OpenAI, is now perhaps itsgreatestadversary. The stakes are high for OpenAI, which reportedly needs to complete its for-profit conversion by 2025 orrelinquish some of the capitalit has raised in recent months.\nA group of organizations, including non-profits and labor groups like California Teamsters, petitioned California Attorney General Rob Bonta this week to stop OpenAI from becoming a for-profit entity. They claimed the company has \u201cfailed to protect its charitable assets\u201d and is actively \u201csubverting its charitable mission to advance safe artificial intelligence.\u201d\nEncode, a non-profit organization that co-sponsored California\u2019sill-fatedSB 1047AI safety legislation,voiced similar concerns in an amicus brieffiled in December.\nOpenAI has said that its conversionwould preserve its non-profit armand infuse it with resources to be spent on \u201ccharitable initiatives\u201d in sectors such as healthcare, education and science.\n\u201cWe\u2019re actually getting ready to build the best-equipped nonprofit the world has ever seen \u2014 we\u2019re not converting it away,\u201d the companywrote in a series of posts on Xon Wednesday. \u201cElon\u2019s never been about the mission. He\u2019s always had his own agenda.\u201d\nThis story was updated to add a comment from Musk\u2019s attorney.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/09/nvidias-h20-ai-chips-may-be-spared-from-export-controls-for-now/",
        "date_extracted": "2025-04-16T17:29:02.912942",
        "title": "Nvidia\u2019s H20 AI chips may be spared from export controls \u2014\u00a0for now",
        "author": null,
        "publication_date": null,
        "content": "Nvidia CEO Jensen Huangappears to have struck a deal with the Trump administrationto avoid export restrictions on the company\u2019s H20 AI chips.\nThe H20, the most advanced Nvidia-produced AI chip that can still be exported from the U.S. to China, was reportedly spared thanks to a promise from Huang to invest in new AI data centers in the U.S.According to NPR, Huang made the proposal during a dinner at Trump\u2019s Mar-a-Lago resort sometime last week.\nNvidia declined to comment.\nMany in the semiconductor industry feared H20s, which are modified to have lower performance than other Nvidia chips, were headed for restrictions because they were reportedly one of the chipsChina-based DeepSeek used to train its R1 open AI model. Released in January, R1 made headlines for its strong performance relative to models from U.S.-based AI labs, including OpenAI.\nSenators from both sides of the aislehave called for restrictions on the H20. Even the Trump administration was said to have been preparing H20 export controls prior to its reversal in course, according to NPR.\nWhile it isn\u2019t totally surprising that Trump allegedly agreed to shelve some potential chip restrictions in exchange for a commitment from Nvidia to invest in U.S. AI infrastructure, allowing Nvidia to continue exporting H20s to China would appear to counter the administration\u2019s goal of securing U.S. dominance in AI.\nMaking the move even more perplexing is the Trump administration\u2019s decision to keep in place theset of AI chip exportrules introduced by outgoing President Joe Biden in January. Those rules layer chip export limits on nearly every country outside the U.S. \u2014\u00a0including U.S. allies \u2014 with harsher restrictions on China and Russia.\nNvidia has called those guidelines \u201cunprecedented and misguided\u201d and said that they\u2019re likely to stifle global innovation.\nMany AI companies besides Nvidia have leaned into Trump\u2019s \u201cAmerica-first\u201d approach to AI in bids to curry favor with the administration. OpenAI teamed up with SoftBank and Oracle for a $500 billion U.S. data center initiative dubbedthe Stargate Projectin January.Microsoft pledged $80 billionto build AI data centers in its 2025 fiscal year, with 50% of that earmarked for the U.S.\nTrump has strong-armed certain partners to get his desired outcome. Hereportedlytold Taiwanese semiconductor company TSMC that it would have to pay a tax up to 100% if the company didn\u2019t build new chip factories in the U.S.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/09/ilya-sutskever-taps-google-cloud-to-power-his-ai-startups-research/",
        "date_extracted": "2025-04-16T17:29:05.784470",
        "title": "Ilya Sutskever taps Google Cloud to power his AI startup\u2019s research",
        "author": null,
        "publication_date": null,
        "content": "OpenAI co-founder and former chief scientist Ilya Sutskever\u2019s new AI startup, Safe Superintelligence (SSI), is using Google Cloud\u2019s TPU chips to power its AI research, part of a new partnership the companies announced on Wednesday in apress release.\nGoogle Cloud says SSI is using TPUs to \u201caccelerate its research and development efforts toward building a safe, superintelligent AI.\u201d\nCloud providers are chasing a handful of unicorn AI startups that spend hundreds of millions of dollars on computing power every year to train AI foundation models. SSI\u2019s deal with Google Cloud suggests the former will spend a large chunk of its computing budget with Google Cloud; a source familiar tells TechCrunch that Google Cloud is SSI\u2019s primary computing provider.\nGoogle Cloud has a history of striking computing deals with its former AI researchers, many of whom are now running billion-dollar AI startups. (Sutskever once worked at Google.) In October, Google Cloud said it would be theprimary computing provider for World Labs, founded by ex-Google Cloud AI chief scientist Fei-Fei Li.\nIt\u2019s unclear if SSI has struck partnerships with other cloud or computing providers. A Google Cloud spokesperson declined to comment. A Safe Superintelligence spokesperson did not immediately respond to a request for comment.\nSSI came out of stealth in June 2024, months after Sutskeverdeparted from his roleas OpenAI\u2019s chief scientist. The company has $1 billion in backing from Andreessen Horowitz, Sequoia Capital, DST Global, SV Angel, and others.\nSince SSI\u2019s launch, we\u2019ve heard relatively little about the startup\u2019s activities. On itswebsite, SSI says that developing safe, superintelligent AI systems is \u201cour mission, our name, and our entire product roadmap, because it is our sole focus.\u201d Sutskeverpreviously saidthat he had identified \u201ca new mountain to climb\u201d and is investigating new ways to improve the performance of frontier AI models.\nBefore co-founding OpenAI, Sutskever spent several years at Google Brain researching neural networks. After leading OpenAI\u2019s AI safety work for years, Sutskever played a key role in the ousting of OpenAI CEO Sam Altman in November 2023. Sutskever later joined an employee movement to reinstate Altman as CEO.\nAfter the ordeal, Sutskever reportedly wasn\u2019t seen at OpenAI\u2019s offices for months, and ultimately left the startup to start SSI.",
        "tags": [],
        "images": []
    },
    {
        "category": "AI",
        "url": "https://techcrunch.com/2025/04/09/openai-launches-program-to-design-new-domain-specific-ai-benchmarks/",
        "date_extracted": "2025-04-16T17:29:08.206115",
        "title": "OpenAI launches program to design new \u2018domain-specific\u2019 AI benchmarks",
        "author": null,
        "publication_date": null,
        "content": "OpenAI thinks AI benchmarks are broken. Now the company is launching a program to fix how AI models are scored.\nThe new OpenAI Pioneers Program will focus on creating evaluations for AI models that \u201cset the bar for what good looks like,\u201d as OpenAI phrased it in ablog post.\n\u201cAs the pace of AI adoption accelerates across industries, there is a need to understand and improve its impact in the world,\u201d the company continued in its post. \u201cCreating domain-specific evals are one way to better reflect real-world use cases, helping teams assess model performance in practical, high-stakes environments.\u201d\nAs therecentcontroversywith the crowdsourced benchmark LM Arena and Meta\u2019s Maverick model illustrate, it\u2019s tough to know, these days, precisely what differentiates one model from another. Many widely used AI benchmarks measure performance on esoteric tasks, like solving doctorate-level math problems. Others can be gamed, or don\u2019t align well with most people\u2019s preferences.\nThrough the Pioneers Program, OpenAI hopes to create benchmarks for specific domains like legal, finance, insurance, healthcare, and accounting. The lab says that, in the coming months, it\u2019ll work with \u201cmultiple companies\u201d to design tailored benchmarks and eventually share those benchmarks publicly, along with \u201cindustry-specific\u201d evaluations.\n\u201cThe first cohort will focus on startups who will help lay the foundations of the OpenAI Pioneers Program,\u201d OpenAI wrote in the blog post. \u201cWe\u2019re selecting a handful of startups for this initial cohort, each working on high-value, applied use cases where AI can drive real-world impact.\u201d\nCompanies in the program will also have the opportunity to work with OpenAI\u2019s team to create model improvements via reinforcement fine tuning, a technique that optimizes models for a narrow set of tasks, OpenAI says.\nThe big question is whether the AI community will embrace benchmarks whose creation was funded by OpenAI. OpenAI has supported benchmarking efforts financially before, and designed its own evaluations. But partnering with customers to release AI tests may be seen as an ethical bridge too far.",
        "tags": [],
        "images": []
    }
]